[
    {
        "id_": "415ede2a-f2f2-46c3-9e7b-445cae4e133e",
        "embedding": null,
        "metadata": {
            "page_label": "1",
            "file_name": "Adaptive-RAG.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
            "file_type": "application/pdf",
            "file_size": 577416,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "d1d66a49-b6d6-4da7-a7d9-d8ea570436df",
                "node_type": "4",
                "metadata": {
                    "page_label": "1",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "645538e3502d87f5553ab8868101351ad94f45b741fffc3b7f85343e2be3f54b",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "022a882a-7216-4b50-aa95-acc89ae30580",
                "node_type": "1",
                "metadata": {},
                "hash": "dfd75c73d9286aa3788c1adda5ffaf655e698a53bdf9da3fac6ef5b5b1f70365",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "adaptiverag learning to adapt retrievalaugmented large language models through question complexity soyeong jeong1jinheon baek2sukmin cho1sung ju hwang12jong c park1 school of computing1graduate school of ai2 korea advanced institute of science and technology12 starsuzijinheonbaeknelllpicsjhwang82jongparkkaistackr abstract retrievalaugmented large language models llms which incorporate the nonparametric knowledge from external knowledge bases into llms have emerged as a promising approach to enhancing response accuracy in several tasks such as questionanswering qa however even though there are various approaches deal ing with queries of different complexities they either handle simple queries with unnecessary computational overhead or fail to adequately address complex multistep queries yet not all user requests fall into only one of the sim ple or complex categories in this work we propose a novel adaptive qa framework that can dynamically select the most suitable strat egy for retrievalaugmented llms from the simplest to the most sophisticated ones based on the query complexity also this selec tion process is operationalized with a classi fier which is a smaller lm trained to predict the complexity level of incoming queries with automatically collected labels obtained from actual predicted outcomes of models and in herent inductive biases in datasets this ap proach offers a balanced strategy seamlessly adapting between the iterative and singlestep retrievalaugmented llms as well as the no retrieval methods in response to a range of query complexities we validate our model on a set of opendomain qa datasets cov ering multiple query complexities and show that ours enhances the overall efficiency and accuracy of qa systems compared to rele vant baselines including the adaptive retrieval approaches code is available at https githubcomstarsuziadaptiverag  1 introduction recent large language models llms brown et al 2020 openai 2023 touvron et al 2023 anil et al 2023 have shown overwhelming per formances across diverse tasks including question corresponding author 05 10 15 20 25 30 35 time per query4748495051performance f1 no retrieval singlestep approach adaptive retrieval multistep approach adaptiverag oursperformance vs time with gpt35figure 1 qa performance f1 and efficiency timequery for different retrievalaugmented generation approaches we use the gpt35turboinstruct as the base llm answering qa yang et al 2018 kwiatkowski et al 2019 however they still generate factu ally incorrect answers since their knowledge solely relies on their parametric memory kasai et al 2022 mallen et al 2023 meanwhile memoriz ing all the everchanging world knowledge may not be possible to address this problem retrieval augmented llms borgeaud et al 2022 izacard et al 2023 shi et al 2023 which incorporate nonparametric knowledge into llms with addi tional retrieval modules have gained much increas ing attention specifically these models access a knowledge base which serves as an extensive repository of information across various subjects and disciplines to retrieve information relevant to the given input and then incorporate the retrieved information into llms which enables them to stay accurate and current with the world knowledge a particularly salient application of retrieval augmented llms is to handling qa tasks whose goal is to provide correct answers in response to user queries especially those of high complexity early work on retrievalaugmented llms focuses primarily on singlehop queries lazaridou et al 2022 ram et al 2023 whose answers are typ ically found",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 3607,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "022a882a-7216-4b50-aa95-acc89ae30580",
        "embedding": null,
        "metadata": {
            "page_label": "1",
            "file_name": "Adaptive-RAG.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
            "file_type": "application/pdf",
            "file_size": 577416,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "d1d66a49-b6d6-4da7-a7d9-d8ea570436df",
                "node_type": "4",
                "metadata": {
                    "page_label": "1",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "645538e3502d87f5553ab8868101351ad94f45b741fffc3b7f85343e2be3f54b",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "415ede2a-f2f2-46c3-9e7b-445cae4e133e",
                "node_type": "1",
                "metadata": {
                    "page_label": "1",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "cb1f2d53efcba0b401257acedc9f32fae4d658f38773aee6a90548e872ab9bb5",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "to provide correct answers in response to user queries especially those of high complexity early work on retrievalaugmented llms focuses primarily on singlehop queries lazaridou et al 2022 ram et al 2023 whose answers are typ ically found within a single document therefore this approach involves retrieving a relevant doc ument based on the query and subsequently inte grating this information into qa models to formu late a response however unlike this singlehop qa some queries require connecting and aggregat ing multiple documents which are furthermorearxiv240314403v2 cscl 28 mar 2024",
        "mimetype": "text/plain",
        "start_char_idx": 3369,
        "end_char_idx": 3959,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "523d731c-95e5-4d8c-9793-7efd76108bd1",
        "embedding": null,
        "metadata": {
            "page_label": "2",
            "file_name": "Adaptive-RAG.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
            "file_type": "application/pdf",
            "file_size": 577416,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "1bbd217b-8573-4c97-957b-8b50634ea092",
                "node_type": "4",
                "metadata": {
                    "page_label": "2",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "96be05b2562603fdb56a1d3fa08f8bf0c7450ff5bfbd12e42ab55b2ddb5a79af",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "a31100ed-2ee2-44bb-a7b1-3052528fd590",
                "node_type": "1",
                "metadata": {},
                "hash": "f6781274eadff421d3e8ee6c79cb5fdbd78d1f08c7229a033fc472b68d0411e6",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "retrievalcomplex query what currency is in billy giles birthplacesimple query when is the birthday of michael f phelpsdocuments answer documents answer a single step approach inaccurate retrieval retrievalsimple query when is the birthday of michael f phelpsdocuments intermediate answers b multi step approach inefficient k times complex query what currency is in billy giles birthplacedocuments intermediate answers k timesstraightforward query paris is the capital of whatc our adaptive approach answer simple query when is the birthday of michael f phelpsdocuments answer complex query what currency is in billy giles birthplacedocuments intermediate answers k times classifier figure 2 a conceptual comparison of different retrievalaugmented llm approaches to question answering a in response to a query this singlestep approach retrieves relevant documents and then generates an answer however it may not be sufficient for complex queries that require multistep reasoning b this multistep approach iteratively retrieves documents and generates intermediate answers which is powerful yet largely inefficient for the simple query since it requires multiple accesses to both llms and retrievers c our adaptive approach can select the most suitable strategy for retrievalaugmented llms ranging from iterative to single to even no retrieval approaches based on the complexity of given queries determined by our classifier often not answerable through a singlestep pro cess of retrievalandresponse an example query is when did the people who captured malakoff come to the region where philipsburg is located which requires four reasoning steps to solve there fore to effectively handle such complex queries recent studies have concentrated largely on multi step and multireasoning qa which requires itera tive accesses to both llms and retrievers multiple times press et al 2023 trivedi et al 2023 at the cost of heavy computational overheads yet we should rethink in a realworld scenario are all the requests from users complex instead users might often ask simple and straightforward questions while only occasionally asking complex ones specifically a query such as paris is the capital of what is likely to be asked more fre quently compared to the aforementioned multi step query and this simpler query might also be easily answered by the llms themselves without accessing external knowledge in other words a multistep qa approach could give rise to unnec essary computational overhead for simple queries even though it would be vital for complex queries see figure 2 a on the other hand handling complex queries with singlestepretrieval or even nonretrieval strategies would be largely insuffi cient figure 2 b this suggests the need for an adaptive qa system which can dynamically adjust the operational strategies of retrievalaugmented llms based on the query complexity while some recent approaches are capable of doing this based on the frequency of entities in queries mallen et al 2023 or on the generated outputs from models for multistep qa trivedi et al 2023 they are still suboptimal the former methods are overly simplistic failing to consider multihop queries meanwhile the latter are excessively complex ter minating answer solving steps after several rounds of module accessin this work considering diverse complexity lev els of realworld queries we argue that previous onesizefitsall approaches might be inadequate to cover all of them instead we propose to select the most suitable strategy from a range of retrieval augmented llms each of which is tailored to the specific complexity of the input query notably a critical step in this process is predefining the query complexity which is instrumental in deter mining the most fitting model to it in this work we operationalize this process with a novel classi fier which is a smaller model trained to predict the complexity level of incoming",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 3915,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "a31100ed-2ee2-44bb-a7b1-3052528fd590",
        "embedding": null,
        "metadata": {
            "page_label": "2",
            "file_name": "Adaptive-RAG.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
            "file_type": "application/pdf",
            "file_size": 577416,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "1bbd217b-8573-4c97-957b-8b50634ea092",
                "node_type": "4",
                "metadata": {
                    "page_label": "2",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "96be05b2562603fdb56a1d3fa08f8bf0c7450ff5bfbd12e42ab55b2ddb5a79af",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "523d731c-95e5-4d8c-9793-7efd76108bd1",
                "node_type": "1",
                "metadata": {
                    "page_label": "2",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "24c72a9b25c2ecdb5be25e916f89f1f2a6ed7d7f8f3490b8c1e7f892a10ac4de",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "step in this process is predefining the query complexity which is instrumental in deter mining the most fitting model to it in this work we operationalize this process with a novel classi fier which is a smaller model trained to predict the complexity level of incoming queries see figure 2 c moreover we automatically collect its training datasets without human labeling by leveraging the predicted outcomes ie which models accurately respond to which queries as well as by capitalizing on the inherent biases in existing datasets ie sam ples in the datasets are designed either for single step or for multistep qa scenarios this proposed method can offer a robust middle ground among the iterative llm augmentation methods for complex queries singlestep methods for simpler queries and even noretrievalaugmented methods for the most straightforward queries answerable by llms themselves thus significantly enhancing the over all efficiency and accuracy as shown in figure 1 we refer to our framework as adaptive retrieval augmented generation adaptiverag we validate adaptiverag using benchmark opendomain qa datasets covering a wide range of query complexity from singlehop rajpurkar et al 2016 joshi et al 2017 kwiatkowski et al 2019 to multihop yang et al 2018 ho et al 2020 trivedi et al 2022b queries the exper imental results show that ours significantly im proves the overall accuracy and efficiency com pared to the prior adaptive strategies on multiple llms such as gpt35 brown et al 2020 and flant5 series chung et al 2022",
        "mimetype": "text/plain",
        "start_char_idx": 3646,
        "end_char_idx": 5180,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "539483ab-6525-45a8-b34d-52d27ec802c8",
        "embedding": null,
        "metadata": {
            "page_label": "3",
            "file_name": "Adaptive-RAG.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
            "file_type": "application/pdf",
            "file_size": 577416,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "6e5785d1-4ee6-42bd-87c8-7c389368daf1",
                "node_type": "4",
                "metadata": {
                    "page_label": "3",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "a4e42df0cd74e66b71afec38f5adb9b23a7ceff714ded5d1f9de24e49771c6d2",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "ed5901a8-a575-46c2-aa07-dd53a3bf0c4d",
                "node_type": "1",
                "metadata": {},
                "hash": "91a1e4b6dc8a2c5815ab620f36a4781fc0d1a4bbd12c636d4c24e62aded6a487",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "our contributions and findings are threefold we point out the realistic scenario of queries of varying complexities and find out that existing retrievalaugmented generation approaches tend to be overly simple or complex we adapt retrievalaugmented llms to the query complexity assessed by the classifier which en ables the utilization of the most suitable approach tailored to each query we show that our adaptiverag is highly effec tive and efficient balancing between the com plexity and the simplicity for diverse queries 2 related work opendomain qa opendomain qa is the task of accurately answering a query by sourcing for queryrelevant documents and then interpreting them to provide answers chen et al 2017 zhu et al 2021 which thus generally involves two modules a retriever karpukhin et al 2020 xiong et al 2021 and a reader yang et al 2019 izac ard and grave 2021 jeong et al 2023 along with the emergence of llms with superior rea soning capabilities thanks to their billionsized pa rameters wei et al 2022a a synergy between llms and retrievers has led to significant advance ments lazaridou et al 2022 ram et al 2023 specifically this integration has been shown to enhance opendomain qa by mitigating the hallu cination problem from llms through strengthened reasoning abilities of the reader as well as utiliz ing the retrieved external documents cho et al 2023 despite these advancements for singlehop retrievalaugmented llms however the complex ity of some queries needs a more complex strategy multihop qa multihop qa is an extension of conventional opendomain qa which addition ally requires the system to comprehensively gather and contextualize information from multiple docu ments often iteratively to answer more complex queries trivedi et al 2022a yang et al 2018 in the realm of multihop qa the approach to itera tively access both llms and the retrieval module is generally employed specifically khattab et al 2022 press et al 2023 pereira et al 2023 and khot et al 2023 proposed to first decom pose the multihop queries into simpler singlehop queries repeatedly access the llms and retriever to solve these subqueries and merge their solu tions to formulate a complete answer in contrastto this decompositionbased approach other re cent studies such as yao et al 2023 and trivedi et al 2023 explored the interleaving of chainof thought reasoning wei et al 2022b  a method where a logical sequence of thoughts is generated  with document retrieval repeatedly applying this process until the reasoning chain generates the an swer in addition jiang et al 2023 introduced an approach to repeatedly retrieving new documents if the tokens within generated sentences have low confidence however the aforementioned methods overlooked the fact that in realworld scenarios queries are of a wide variety of complexities there fore it would be largely inefficient to iteratively access llms and retrievers for every query which might be simple enough with a single retrieval step or even only with an llm itself adaptive retrieval to handle queries of varying complexities the adaptive retrieval strategy aims to dynamically decide whether to retrieve documents or not based on each querys complexity in this vein mallen et al 2023 proposed to decide the querys complexity level based on the frequency of its entities and suggested using the retrieval mod ules only when the frequency falls below a cer tain threshold however this approach focusing solely on the binary",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 3483,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "ed5901a8-a575-46c2-aa07-dd53a3bf0c4d",
        "embedding": null,
        "metadata": {
            "page_label": "3",
            "file_name": "Adaptive-RAG.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
            "file_type": "application/pdf",
            "file_size": 577416,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "6e5785d1-4ee6-42bd-87c8-7c389368daf1",
                "node_type": "4",
                "metadata": {
                    "page_label": "3",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "a4e42df0cd74e66b71afec38f5adb9b23a7ceff714ded5d1f9de24e49771c6d2",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "539483ab-6525-45a8-b34d-52d27ec802c8",
                "node_type": "1",
                "metadata": {
                    "page_label": "3",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "a999155019c85e974ac1a2de2a61431b78821c77537dcb513f4985ad890c1122",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "vein mallen et al 2023 proposed to decide the querys complexity level based on the frequency of its entities and suggested using the retrieval mod ules only when the frequency falls below a cer tain threshold however this approach focusing solely on the binary decision of whether to retrieve or not may not be sufficient for more complex queries that require multiple reasoning steps ad ditionally qi et al 2021 proposed an approach that performs a fixed set of operations retrieving reading and reranking multiple times until the an swer is derived for the given query which is built upon traditional bertlike lms however unlike our adaptiverag which predetermines the query complexity and adapts the operational behavior of any offtheshelf llms accordingly this approach applies the same fixed operations to every query regardless of its complexity but also necessitates additional specific training to lms concurrent to our work asai et al 2024 suggested training a so phisticated model to dynamically retrieve critique and generate the text nevertheless we argue that all the aforementioned adaptive retrieval methods that rely on a single model might be suboptimal in handling a variety of queries of a range of differ ent complexities since they tend to be either overly simple or complex for all the input queries which demands a new approach that can select the most suitable strategy of retrievalaugmented llms tai lored to the query complexity",
        "mimetype": "text/plain",
        "start_char_idx": 3223,
        "end_char_idx": 4677,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "77f8afa5-dbf0-4e73-bbcf-652e723b33bf",
        "embedding": null,
        "metadata": {
            "page_label": "4",
            "file_name": "Adaptive-RAG.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
            "file_type": "application/pdf",
            "file_size": 577416,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "ab675418-f1c3-426c-904b-21ec477bfb79",
                "node_type": "4",
                "metadata": {
                    "page_label": "4",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "c74e3e372f3a7d5294bbcd0d4a1534d4aee097136ee98db2972603426d3bac73",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "ae7cbf38-bace-4488-96ea-207e81a9733e",
                "node_type": "1",
                "metadata": {},
                "hash": "cf5a526bfb471e80d2b1d83c41656234bc9da52100873f9339fe4353e1d9c951",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "3 method in this section we describe our approach to adapt ing retrievalaugmented llms by predetermining the query complexity and then selecting the most fitting strategies for retrievalaugmented llms 31 preliminaries we begin with preliminaries formally introducing different strategies of retrievalaugmented llms non retrieval for qa let us first define an llm as a model llm which takes a sequence of tokens x x1 x2  x nas an input and then generates a sequence of tokens y y1 y2  y nas an out put which is formalized as follows yllmx then in our problem setup for qa xandybe come the input query  q from the user and the generated answer  a from the llm respectively qxanday also subsequently the most na\u00efve llmpowered qa model can be represented as follows allmq ideally ashould match the actual correct answer a this nonretrieval based qa method is highly efficient and could be a somewhat promising approach to handling easy queries as the size of llms becomes extremely large with its effect on storing a large amount of knowledge however this approach is largely prob lematic on queries that require precise or concur rent knowledge of specific people events or any subjects beyond the llms internal knowledge singlestep approach for qa to address the aforementioned scenarios where llmmay struggle with queries that are not answerable by llmitself we can utilize the external knowledge d which includes useful information for queries retrieved from the external knowledge source dthat could be an encyclopedia eg wikipedia consisting of millions of documents specifically to obtain suchdfromd a specific retrieval model is nec essary which returns documents based on their relevance with the given query this process can be formulated as follows dretriever qd where retriever is the retrieval model with d d  here we can use any offtheshelf re triever robertson et al 1994 karpukhin et al 2020 after the retrieval step is done we now have a pair of query qand its relevant documents d then in order to augment llms with this retrieved exter nal knowledge we can incorporate it into the input of llms represented as follows allmqdthis process allows llms to gain access to exter nal information contained in d which can provide the supplementary context that the internal knowl edge of llmlacks which can subsequently improve the accuracy and concurrency of llms for qa multistep approach for qa even though the aforementioned singlestep approach offers signif icant improvements over nonretrieval for qthat requires external knowledge it encounters notable limitations particularly when dealing with com plex queries that necessitate synthesizing informa tion from multiple source documents and reasoning over them this is where a multistep approach and reasoning for qa become essential in this multistep approach llminteracts with retriever in several rounds progressively refin ing its understanding of q until it formulates the fi nal answer from findings accumulated across these multiple steps specifically the process begins with the initial query q and at every retrieval step i new documents diare retrieved from dand then incorporated into the input of llms as follows aillmqdici where the additional context cican be composed of previous documents and outcomes d1d2 di1a1a2 ai1 and diretriever qcid1 we would like to note that this iterative multistep process enables llmto construct a more comprehensive and exten sive foundation to solve queries effectively specif ically adept at complex multihop queries where answers depend on interconnected pieces of infor mation however it is important",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 3614,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "ae7cbf38-bace-4488-96ea-207e81a9733e",
        "embedding": null,
        "metadata": {
            "page_label": "4",
            "file_name": "Adaptive-RAG.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
            "file_type": "application/pdf",
            "file_size": 577416,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "ab675418-f1c3-426c-904b-21ec477bfb79",
                "node_type": "4",
                "metadata": {
                    "page_label": "4",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "c74e3e372f3a7d5294bbcd0d4a1534d4aee097136ee98db2972603426d3bac73",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "77f8afa5-dbf0-4e73-bbcf-652e723b33bf",
                "node_type": "1",
                "metadata": {
                    "page_label": "4",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "49fdaf4d03b4ad85928bd76833bdfeda0e5557665d10cd7534317cb517953541",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "this iterative multistep process enables llmto construct a more comprehensive and exten sive foundation to solve queries effectively specif ically adept at complex multihop queries where answers depend on interconnected pieces of infor mation however it is important to recognize that this multistep approach can be resourceintensive due to the repeated accesses to retriever andllm which entail substantial computational costs 32 adaptiverag adaptive retrievalaugmented generation we now introduce our adaptive retrievalaugmented llms which are built upon three different strate gies described in the previous section and which are designed to select the most suitable strategy according to the complexity of queries adapting retrievalaugmented llms note that in realworld scenarios not all qfrom users have the same level of complexity necessitating 1it is worth noting that implementations of the llm and retriever vary across different multistep retrievalaugmented llm approaches trivedi et al 2023 press et al 2023 yao et al 2023 therefore the context cimay incorporate none some or all of the previous documents and answers",
        "mimetype": "text/plain",
        "start_char_idx": 3348,
        "end_char_idx": 4477,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "34effcf5-532b-4134-ab75-dc9424461f0e",
        "embedding": null,
        "metadata": {
            "page_label": "5",
            "file_name": "Adaptive-RAG.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
            "file_type": "application/pdf",
            "file_size": 577416,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "c0942558-b2ce-4fe8-9b4d-4165bad54a61",
                "node_type": "4",
                "metadata": {
                    "page_label": "5",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "86d7c0412a7c27ed3dbe454a674cabf6867c0fbe8ffe1774d32e60086d9235e2",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "d635f636-977c-4118-98b7-974c5bea8fe2",
                "node_type": "1",
                "metadata": {},
                "hash": "082cdab7bdc7d97601f79b798cfdcf1b3386482d235e1a9a1e0bb75f80800420",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "tailored strategies for handling each query in other words employing the most basic nonretrieval based approach llmqto respond to the complex query qwould be also ineffective figure 2 a conversely using a more elaborate multistep ap proach llmqdcfor simple qwould be ineffi cient figure 2 b therefore our adaptive frame work is designed to dynamically adjust the query handling strategy of retrievalaugmented llms which is achieved by determining the complexity of each query before attempting a solution notably this framework can offer a robust middle ground with a range of solutions from the simplest ap proach for the most straightforward queries to the onestep approach for moderate queries and up to the most comprehensive and rigorous approach for complex queries in addition since the operations ofllmandretriever remain consistent regard less of inputs to them our method can seeming lessly go back and forth across queries of different complexities without changing the internal model architecture or parameters during adaption query complexity assessment to operational ize our adaptive retrievalaugmented llm frame work we should determine the query complexity and to achieve this we propose to model a com plexity classifier whose goal is to return the appro priate complexity level of the given query specif ically given the query q our classifier can be for mulated as follows oclassifier q where classifier is a smaller language model that is trained to classify one of three different complexity levels and ois its corresponding class label in our classifier design there are three class labels a b and c where a indicates that qis straight forward and answerable by llmqitself b in dicates that qhas the moderate complexity where at least a singlestep approach llmqdis needed and c indicates that qis complex requiring the most extensive solution llmqdc2 training strategy the remaining step is to train the smaller language model for classifier  to accurately predict its complexity oin response to the given query q yet there is no annotated dataset available for querycomplexity pairs hence we propose to automatically construct the training dataset with two particular strategies to be specific we first aim at labeling the query 2we consider three levels of query complexity and leave the exploration of more finegrained complexities as future workcomplexity based on the results from three different retrievalaugmented llm strategies in order to determine the label by its needs for example if the simplest nonretrievalbased approach correctly generates the answer the label for its corresponding query is assigned a also to break the tie between different models in providing the label to the query we provide a higher priority to a simpler model in other words if both singlestep and multistep approaches produce the same correct answer while the nonretrievalbased approach fails we assign label b to its corresponding query however this labeling strategy has a limita tion in that not all the queries are assigned labels since the three retrievalaugmented approaches may all fail to generate the correct answer on the other hand the benchmark datasets may al ready have meaningful inductive biases about the most appropriate retrievalaugmented llm strate gies for their queries considering the ways they are created eg qa datasets that require sequen tial reasoning usually necessitate a multistep ap proach while queries of those with labeled sin gle documents can be ideally answerable with the singlestep approach therefore for those queries that remain unlabeled after the first labeling step we assign b to queries in singlehop datasets and c to queries in multihop datasets finally we train classifier with these automatically collected querycomplexity pairs3 by using a cross entropy loss then at inference we can deter mine the complexity of the",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 3881,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "d635f636-977c-4118-98b7-974c5bea8fe2",
        "embedding": null,
        "metadata": {
            "page_label": "5",
            "file_name": "Adaptive-RAG.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
            "file_type": "application/pdf",
            "file_size": 577416,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "c0942558-b2ce-4fe8-9b4d-4165bad54a61",
                "node_type": "4",
                "metadata": {
                    "page_label": "5",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "86d7c0412a7c27ed3dbe454a674cabf6867c0fbe8ffe1774d32e60086d9235e2",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "34effcf5-532b-4134-ab75-dc9424461f0e",
                "node_type": "1",
                "metadata": {
                    "page_label": "5",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "b4f335bfa9d0fccc75c9bc856dec8426bda6be9b0993873ea5b7e86a6871c32e",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "labeling step we assign b to queries in singlehop datasets and c to queries in multihop datasets finally we train classifier with these automatically collected querycomplexity pairs3 by using a cross entropy loss then at inference we can deter mine the complexity of the query which is one of a b c by forwarding it to classifier  oclassifier q 4 experimental setups in this section we explain datasets models met rics and implementation details we provide addi tional details in appendix a 41 datasets in order to simulate a realistic scenario where dif ferent queries have varying complexities we use both the singlehop and multihop qa datasets si multaneously in the unified experimental setting singlehop qa for simpler queries we use three benchmark singlehop qa datasets which consist 3as we automatically assign classifier labels there might be errors in labeling and might be more advanced strategies to automatically assign labels which we leave as future work",
        "mimetype": "text/plain",
        "start_char_idx": 3611,
        "end_char_idx": 4580,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "9973e8fb-f592-427a-83af-34fd8a5c224e",
        "embedding": null,
        "metadata": {
            "page_label": "6",
            "file_name": "Adaptive-RAG.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
            "file_type": "application/pdf",
            "file_size": 577416,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "f428bcf4-0e24-40f9-9c10-6f6e0f2f52e9",
                "node_type": "4",
                "metadata": {
                    "page_label": "6",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "b01654ceb6e67b27e6d1a96853e0bf3d47d1621ab0999f4c8ca0c0fb5401aad1",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "53534ed4-2e1c-4dfb-b03d-c3e1780fd5ef",
                "node_type": "1",
                "metadata": {},
                "hash": "4d9e30cf48b67fa0b5948666afc89721a61a7a6ec8cc8d6360de46354568b039",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "table 1 averaged results on a collection of benchmark datasets for opendomain question answering including the singlehop and multihop queries with different llms selfragis trained with a different base llm namely llama2 touvron et al 2023 therefore we compare the results of flant5xl 3b with the results from selfrag with llama2 7b and the results of others with the results from selfrag with llama2 13b we emphasize our results in bold for easy comparisons flant5xl 3b flant5xxl 11b gpt35 turbo types methods em f1 acc step time em f1 acc step time em f1 acc step time simpleno retrieval 1487 2112 1597 000 011 1783 2514 1933 000 008 3577 4856 4427 000 071 singlestep approach 3483 4431 3887 100 100 3787 4763 4190 100 100 3473 4699 4527 100 100 adaptiveadaptive retrieval 2387 3224 2673 050 056 2693 3567 2973 050 054 3590 4820 4530 050 086 selfrag990 2079 3157 072 043 1087 2298 3413 074 023 1087 2298 3413 074 150 adaptiverag ours 3717 4694 4210 217 360 3890 4862 4377 135 200 3797 5091 4897 103 146 complex multistep approach 3900 4885 4370 469 881 4013 5009 4520 213 380 3813 5087 4970 281 333 oracle adaptiverag w oracle 4500 5628 4990 128 211 4717 5860 5220 084 110 4770 6280 5857 050 103 of queries and their associated documents contain ing answers namely 1 squad v11 rajpurkar et al 2016 2 natural questions kwiatkowski et al 2019 and 3 triviaqa joshi et al 2017 multihop qa to consider more complex query scenarios we use three benchmark multihop qa datasets which require sequential reasoning over multiple documents namely 1 musique trivedi et al 2022a 2 hotpotqa yang et al 2018 and3 2wikimultihopqa ho et al 2020 42 models we compare our adaptiverag against relevant models including three retrievalaugmented llm strategies in section 31 and the adaptive re trieval approaches mallen et al 2023 asai et al 2024 which can be grouped into one of three cat egories simple adaptive and complex specif ically simple approaches include the 1 no re trieval and2 singlestep approach based meth ods adaptive approaches include the 3 adaptive retrieval mallen et al 2023 4 selfrag asai et al 2024 and our 5 adaptiverag  which can adaptively perform retrieval based on the question complexity for the 6 multistep ap proach  we use the most sophisticated stateof theart method trivedi et al 2023 iteratively accessing both the",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 2330,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "53534ed4-2e1c-4dfb-b03d-c3e1780fd5ef",
        "embedding": null,
        "metadata": {
            "page_label": "6",
            "file_name": "Adaptive-RAG.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
            "file_type": "application/pdf",
            "file_size": 577416,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "f428bcf4-0e24-40f9-9c10-6f6e0f2f52e9",
                "node_type": "4",
                "metadata": {
                    "page_label": "6",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "b01654ceb6e67b27e6d1a96853e0bf3d47d1621ab0999f4c8ca0c0fb5401aad1",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "9973e8fb-f592-427a-83af-34fd8a5c224e",
                "node_type": "1",
                "metadata": {
                    "page_label": "6",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "ce5e405b2f728b1a42ccaad9ae215d173c67cca1930484882a32b469b923f10c",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "adaptiverag  which can adaptively perform retrieval based on the question complexity for the 6 multistep ap proach  we use the most sophisticated stateof theart method trivedi et al 2023 iteratively accessing both the retriever and llm with chain ofthought reasoning wei et al 2022b for every query note that models across different categories are not directly comparable yet in the ideal set ting adaptive approaches should be more effective than those in the simple category while simultane ously being more efficient than the complex one therefore we also report the performance in an ideal scenario 7 adaptiverag w oracle  using the oracle classifier with our adaptiverag 43 evaluation metrics when it comes to evaluating adaptive models it is essential to simultaneously consider both thetask performance and efficiency along with their tradeoffs thus we report the results with five metrics where three of them measure the effective ness and the other two measure the efficiency in particular for effectiveness we use f1 em and accuracy acc following the standard evaluation protocol mallen et al 2023 baek et al 2023 asai et al 2024 where f1 measures the number of overlapping words between the predicted an swer and the ground truth em measures whether they are the same and acc measures whether the predicted answer contains the groundtruth answer for efficiency we measure the number of retrieval andgenerate steps and the average time for answer ing each query relative to the onestep approach 44 implementation details for a fair comparison and following mallen et al 2023 and trivedi et al 2023 we use the same re triever a termbased sparse retrieval model known as bm25 robertson et al 1994 across all differ ent models for the external document corpus we use different sources depending on the dataset type the wikipedia corpus preprocessed by karpukhin et al 2020 for singlehop datasets and the pre processed corpus by trivedi et al 2023 for multi hop datasets regarding the llms that are used to generate answers we use the flant5 series models chung et al 2022 of xl with 3b pa rameters and xxl with 11b parameters and the gpt35 model gpt35turboinstruct for the retrievalaugmented llm design we follow the implementation details from trivedi et al 2023 which include input prompts instructions and the number of test samples for evaluation eg 500 samples per dataset in our adaptiverag for the querycomplexity classifier we use and train the t5large model raffel et al 2020 specifically the classifier is trained using the epoch that shows the best performance until 100 training iterations from the validation set with the learning rate of 3e",
        "mimetype": "text/plain",
        "start_char_idx": 2113,
        "end_char_idx": 4774,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "636e0e83-105a-412d-befc-af502f8462f4",
        "embedding": null,
        "metadata": {
            "page_label": "7",
            "file_name": "Adaptive-RAG.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
            "file_type": "application/pdf",
            "file_size": 577416,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "101762ad-a436-4fec-aed9-7a18b8e2a733",
                "node_type": "4",
                "metadata": {
                    "page_label": "7",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "e31d213d67b6953a6ae56617a59bf4f2d4517c7bc5f28414ff6092beccfde0db",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "69a18664-a0a3-4386-b590-dd189b48dbc4",
                "node_type": "1",
                "metadata": {},
                "hash": "6260a8cf854e7512852ad95783f2ba689a14598d2121cd7054b2387e22495348",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "table 2 results on each of a collection of datasets with flant5xl 3b as the llm we emphasize our results in bold squad natural questions triviaqa data types methods em f1 acc step time em f1 acc step time em f1 acc step time singlestepsimpleno retrieval 360 1050 500 000 011 1420 1900 1560 000 013 2500 3180 2700 000 013 singlestep approach 2780 3930 3400 100 100 3780 4730 4460 100 100 5360 6240 6020 100 100 adaptiveadaptive retrieval 1340 2310 1760 050 055 2820 3600 3300 050 056 3840 4690 4260 050 056 selfrag220 1120 1840 063 050 3140 3900 3360 063 017 1280 2930 5700 068 045 adaptiverag ours 2680 3830 3300 137 202 3780 4730 4460 100 100 5220 6070 5820 123 154 complex multistep approach 2440 3560 2960 452 903 3860 4780 4420 504 1018 5380 6240 6020 528 922 oracle adaptiverag w oracle 3200 4560 3820 124 160 4740 5710 5360 110 155 6160 7020 6640 079 110 musique hotpotqa 2wikimultihopqa data types methods em f1 acc step time em f1 acc step time em f1 acc step time multistepsimpleno retrieval 240 1070 320 000 011 1660 2271 1720 000 011 2740 3204 2780 000 010 singlestep approach 1380 2280 1520 100 100 3440 4615 3640 100 100 4160 4790 4280 100 100 adaptiveadaptive retrieval 640 1580 800 050 055 2360 3222 2500 050 055 3320 3944 3420 050 055 selfrag160 810 1200 073 051 680 1753 2960 073 045 460 1959 3880 093 049 adaptiverag ours 2360 3180 2600 322 661 4200 5382 4440 355 599 4060 4975 4640 263 468 complex multistep approach 2300 3190 2580 360 758 4460 5654 4700 553 938 4960 5885 5540 417 737 oracle adaptiverag w oracle 2480 3850 2700 198 399 5120 6400 5480 159 277 5300 6230 5940 101 169 f1102030405060adaptive retrieval selfrag adaptiverag ours classifier acc3540455055flant5xl f1102030405060adaptive retrieval",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 1725,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "69a18664-a0a3-4386-b590-dd189b48dbc4",
        "embedding": null,
        "metadata": {
            "page_label": "7",
            "file_name": "Adaptive-RAG.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
            "file_type": "application/pdf",
            "file_size": 577416,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "101762ad-a436-4fec-aed9-7a18b8e2a733",
                "node_type": "4",
                "metadata": {
                    "page_label": "7",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "e31d213d67b6953a6ae56617a59bf4f2d4517c7bc5f28414ff6092beccfde0db",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "636e0e83-105a-412d-befc-af502f8462f4",
                "node_type": "1",
                "metadata": {
                    "page_label": "7",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "4d510e3c500ab2daa581b2994bcad03a3ee2ae4b385eefb0f7faceecded0fce4",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "159 277 5300 6230 5940 101 169 f1102030405060adaptive retrieval selfrag adaptiverag ours classifier acc3540455055flant5xl f1102030405060adaptive retrieval selfrag adaptiverag ours classifier acc3540455055flant5xxl no one multino one multi031 047 022 01 066 023 003 031 065 020406confusion matrix figure 3 performance on qa and querycomplexity assessment of different adaptive approaches for retrievalaugmented llms with flant5 xl left and xxl center for labeling the complexity of queries we use the silver data annotated from the prediction outcomes of models described in section 32 we also provide the confusion matrix across three labels right 5 and the adamw loshchilov and hutter 2019 as an optimizer regarding its training data we sample and annotate 400 queries from 6 datasets based on its inductive bias singlehop for onestep approach and multihop for multistep in addition we use predicted outcomes of three different strate gies over 400 queries sampled from each dataset note that those queries used for classifier training do not overlap with the testing queries for qa 5 experimental results and analyses in this section we show the overall experimental results and offer indepth analyses of our method main results first of all table 1 shows our main results averaged over all considered datasets which corroborate our hypothesis that simple retrieval augmented strategies are less effective than the complex strategy while the complex one is sig nificantly more expensive than the simple ones in addition we report the more granular results with flant5xl on each of the singlehop and multi hop datasets in table 2 and more with different llms in table 7 and table 8 of appendix which are consistent with the results observed in table 1 however in a realworld scenario not all users ask queries with the same level of complexity which emphasizes the importance of the need for adaptive strategies note that among the adaptive strategies our adaptiverag shows remarkableeffectiveness over the competitors table 1 this indicates that merely focusing on the decision of whether to retrieve or not is suboptimal also as shown in table 2 such simple adaptive strategies are particularly inadequate for handling complex queries in multihop datasets which require ag gregated information and reasoning over multiple documents meanwhile our approach can consider a more finegrained query handling strategy by fur ther incorporating an iterative module for complex queries furthermore in a realistic setting we should take into account not only effectiveness but also efficiency as shown in table 1 compared to the complex multistep strategy our proposed adap tive strategy is significantly more efficient across all model sizes this is meaningful in this era of llms where the cost of accessing them is a critical factor for practical applications and scalability fi nally to see the upper bound of our adaptiverag we report its performances with the oracle classifier where the classification performance is perfect as shown in table 1 and table 2 we observe that it achieves the best performance while being much more efficient than our adaptiverag without the oracle classifier these results support the valid ity and significance of our proposal for adapting retrievalaugmented llm strategies based on query complexity and further suggest the direction to de velop more improved classifiers to achieve optimal performance",
        "mimetype": "text/plain",
        "start_char_idx": 1571,
        "end_char_idx": 5004,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "78dafdaa-3751-4565-a7a5-7d0872de7420",
        "embedding": null,
        "metadata": {
            "page_label": "8",
            "file_name": "Adaptive-RAG.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
            "file_type": "application/pdf",
            "file_size": 577416,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "9b535783-0f59-4622-8bce-50ed5e037e35",
                "node_type": "4",
                "metadata": {
                    "page_label": "8",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "8c74be189d44c0b51932ffedfcc16a170cb4ad992198fe3207f99fdc3a5d79a1",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "b1f7616f-1495-4005-95ee-1ac275aacd21",
                "node_type": "1",
                "metadata": {},
                "hash": "f603a231d76762475edbebc8a18fd0081f2e2f2eaa475c966ff81aa5ebdbee0c",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "table 3 the exact elapsed time per query and the percentage of the predicted labels from the classifier over all samples labels timequery sec percentage  no a 035 860 one b 308 5333 multi c 2718 3807 classifier performance to understand how the proposed classifier works we analyze its perfor mance across different complexity labels as fig ure 3 left and center shows the classification accuracy of our adaptiverag is better than those of the other adaptive retrieval baselines which leads to overall qa performance improvements in other words this result indicates that our adaptive rag is capable of more accurately classifying the complexity levels with various granularities which include not performing retrieval performing re trieval only once and performing retrieval multiple times in addition to the true positive performance of our classifier averaged over all those three la bels in figure 3 left and center we further re port its confusion matrix in figure 3 right we note that the confusion matrix reveals some notable trends c multi is sometimes misclassified as b one about 31 and b one as c multi about 23 a no is misclassified often as b one about 47 and less frequently as c multi about 22 while the overall results in figure 3 show that our classifier effectively cate gorizes the three labels further refining it based on such misclassification would be a meaningful direction for future work analyses on efficiency for classifier while ta ble 1 shows the relative elapsed time for each of the three different rag strategies we further provide the exact elapsed time per query for our adaptive rag and the distribution for predicted labels from our querycomplexity classifier in table 3 similar to the results of the elapsed time in table 1 relative time table 3 exact time shows that efficiency can be substantially improved by identifying sim ple or straightforward queries analyses on training data for classifier we have shown that the classifier plays an important role in adaptive retrieval here we further analyze the different strategies for training the classifier by ablating our full training strategy which includes two approaches generating silver data from pre dicted outcomes of models and utilizing inductivetable 4 results on qa and complexity classification with varying the data annotation strategies for training the classifier qa classifier accuracy training strategies f1 step all no one multi adaptiverag ours 4694 1084 5452 3052 6628 6545 wo binary 4343 640 6030 6219 6570 3955 wo silver 4879 1464 4000 000 5398 7591 bias in datasets see section 32 as table 4 shows compared to the training strategy relying solely on the data derived from inductive bias ours is sig nificantly more efficient this efficiency is partly because ours also takes into account the case that does not consider any documents at all as also implied by the classification accuracy meanwhile queries in the existing datasets do not capture the information on whether the retrieval is required or not on the other hand in the case of only using the silver data annotated from the correct predictions while its overall classification accuracy is high the overall qa performance implies that relying on the silver data may not be optimal this may be because this silver data does not cover complex ity labels over incorrectly predicted queries which leads to lower generalization effect on queries rel evant to them meanwhile by also incorporating complexity labels from dataset bias singlehop vs multihop the classifier becomes more accurate in predicting multihop queries leading to the better performance it is worth noting that our automatic labeling strategies are two particular instantiations for training the classifier and that there could be other instantiations which we leave",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 3803,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "b1f7616f-1495-4005-95ee-1ac275aacd21",
        "embedding": null,
        "metadata": {
            "page_label": "8",
            "file_name": "Adaptive-RAG.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
            "file_type": "application/pdf",
            "file_size": 577416,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "9b535783-0f59-4622-8bce-50ed5e037e35",
                "node_type": "4",
                "metadata": {
                    "page_label": "8",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "8c74be189d44c0b51932ffedfcc16a170cb4ad992198fe3207f99fdc3a5d79a1",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "78dafdaa-3751-4565-a7a5-7d0872de7420",
                "node_type": "1",
                "metadata": {
                    "page_label": "8",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "a0fbf8e70e337e7e9f62989541346de2635e189519b8b2893005135e5ee2d8db",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "vs multihop the classifier becomes more accurate in predicting multihop queries leading to the better performance it is worth noting that our automatic labeling strategies are two particular instantiations for training the classifier and that there could be other instantiations which we leave as future work analyses on classifier size to investigate the sensitivity of our classifier according to its varying sizes we conducted further experiments as shown in table 6 we observe no significant performance differences among classifiers of various sizes even with reduced complexity and fewer parameters in smaller classifiers this indicates that our proposed classifier can contribute to resourceefficient set tings in realuse cases with smaller sizes without compromising the performance case study we conduct a case study to qualita tively compare our adaptiverag against adap tive retrieval table 5 shows the classified com plexity and the query handling patterns for both simple and complex questions first for the simple singlehop question our adaptiverag identifies that it is answerable by only using the llms para metric knowledge about google by contrast",
        "mimetype": "text/plain",
        "start_char_idx": 3510,
        "end_char_idx": 4675,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "4c879754-47b4-408b-a680-291368c9e37b",
        "embedding": null,
        "metadata": {
            "page_label": "9",
            "file_name": "Adaptive-RAG.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
            "file_type": "application/pdf",
            "file_size": 577416,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "dd6e49a5-9711-4099-8d8b-e130f1b997db",
                "node_type": "4",
                "metadata": {
                    "page_label": "9",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "aefd33ea565cdfe55c3319ab934d0b5676c74bdd5b8cf86f273d33c2fed89e1f",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "cb221418-1116-4b9b-b551-73e12ff12cb7",
                "node_type": "1",
                "metadata": {},
                "hash": "1a330ceebba217f77ca38b661f4ca5884c08f0eacd83d08cb7554966e3b2b058",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "table 5 case study with gpt35 turbo where we represent the factual error in red and the accurate information in blue dataset question adaptive retrieval adaptiverag ours nq singlehopwhich famous corpo rate logo changed to a flat colourcolor sans serif font in its first ma jor change since 1999query type b singlestep approach reasoning the famous corporate logo that changed to a flat color sansserif font in its first major change since 1999 is microsoft microsoft changed its logo in 2012 replacing the italicized multicolored font with a simple flat grey font so the answer is microsoftquery type a non retrieval reasoning the famous corporate logo that changed to a flat color sans serif font in its first ma jor change since 1999 is google google changed its logo in 2015 so the answer is google musique multihopwho is the child of the italian navigator who explored the eastern coast of the continent c\u00e9sar gaytan was born in for the englishquery type a non retrieval reasoning c\u00e9sar gaytan was born in the conti nent of north america the italian navigator who explored the eastern coast of north america for the english was giovanni caboto also known as john cabot so the answer is giovanni cabotojohn cabotquery type c multistep approach reasoning c\u00e9sarr gaytan was born in guadalajara jalisco mexico the italian navigator who explored the eastern coast of the continent for the english is john cabot john cabots son is sebastian cabot so the answer is sebastian cabot table 6 results with varying model sizes for classifiers qa classifier accuracy sizes f1 step all no one multi small 60m 4583 964 5348 2665 7062 5318 base 223m 4597 983 5341 2642 6946 5682 large 770m 4694 1084 5452 3052 6628 6545 adaptive retrieval fetches additional documents leading to longer processing times and occasion ally producing incorrect responses due to the inclu sion of partially irrelevant information about mi crosoft meanwhile faced with a complex ques tion adaptiverag seeks out relevant information including details like a son of john cabot which may not have been stored in llms while adaptive retrieval fails to request such information from external sources resulting in inaccurate answers 6 conclusion in this work we proposed the adaptive retrieval augmented generation framework referred to as adaptiverag to handle queries of various complexities specifically adaptiverag is de signed to dynamically adjust its query handling strategies in the unified retrievalaugmented llm based on the complexity of queries that they en counter which spans across a spectrum of the non retrievalbased approach for the most straightfor ward queries to the singlestep approach for the queries of moderate complexity and finally to the multistep approach for the complex queries the core step of our adaptiverag lies in determin ing the complexity of the given query which is instrumental in selecting the most suitable strat egy for its answer to operationalize this process we trained a smaller language model with query complexity pairs which are automatically anno tated from the predicted outcomes and the inductive biases in datasets we validated our adaptiveragon a collection of opendomain qa datasets cover ing the multiple query complexities including both the single and multihop questions the results demonstrate that our adaptiverag enhances the overall accuracy and efficiency of qa systems al locating more resources to handle complex queries while efficiently handling simpler queries com pared to the existing onesizefitsall approaches that tend to be either",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 3565,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "cb221418-1116-4b9b-b551-73e12ff12cb7",
        "embedding": null,
        "metadata": {
            "page_label": "9",
            "file_name": "Adaptive-RAG.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
            "file_type": "application/pdf",
            "file_size": 577416,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "dd6e49a5-9711-4099-8d8b-e130f1b997db",
                "node_type": "4",
                "metadata": {
                    "page_label": "9",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "aefd33ea565cdfe55c3319ab934d0b5676c74bdd5b8cf86f273d33c2fed89e1f",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "4c879754-47b4-408b-a680-291368c9e37b",
                "node_type": "1",
                "metadata": {
                    "page_label": "9",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "99841e9b38e5dc2430da1a4dc86baea453a9779df622504013890487bba55e8a",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "and multihop questions the results demonstrate that our adaptiverag enhances the overall accuracy and efficiency of qa systems al locating more resources to handle complex queries while efficiently handling simpler queries com pared to the existing onesizefitsall approaches that tend to be either minimalist or maximalist over varying query complexities limitations while our adaptiverag shows clear advantages in effectiveness and efficiency by determining the query complexity and then leveraging the most suitable approach for tackling it it is important to recognize that there still exist potential avenues for improving the classifier from the perspectives of its training datasets and architecture specifi cally as there are no available datasets for training the querycomplexity classifier we automatically create new data based on the model prediction out comes and the inductive dataset biases however our labeling process is one specific instantiation of labeling the query complexity and it may have the potential to label queries incorrectly despite its effectiveness therefore future work may create new datasets that are annotated with a diverse range of query complexities in addition to the labels of questionanswer pairs also as the performance gap between the ideal classifier in table 1 and the current classifier in figure 3 indicates there is still room to improve the effectiveness of the classifier in other words our classifier design based on the smaller lm is the initial simplest instantiation for classifying the query complexity and based upon it future work may improve the classifier archi tecture and its performance which will positively contribute to the overall qa performance",
        "mimetype": "text/plain",
        "start_char_idx": 3268,
        "end_char_idx": 4981,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "dc4accb9-69b2-44a4-b177-5821f8ac4a92",
        "embedding": null,
        "metadata": {
            "page_label": "10",
            "file_name": "Adaptive-RAG.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
            "file_type": "application/pdf",
            "file_size": 577416,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "21831d2e-b203-4f13-907d-1f67c94718d7",
                "node_type": "4",
                "metadata": {
                    "page_label": "10",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "ff14540c479a957ac1d9b4abe9fe6fe86b588fb0b596e1a2f2ab7d5da834c4bf",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "89df67c6-6315-47e9-8c29-62bc68f71f5a",
                "node_type": "1",
                "metadata": {},
                "hash": "1173a365fb07b52219975e720ca035e22eed490fc58d53d882613ed51fad44e3",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "ethics statement the experimental results on adaptiverag vali date its applicability in realistic scenarios where a wide range of diverse user queries exist nonethe less given the potential diversity of realworld user inputs it is crucial to also consider scenarios where these inputs might be offensive or harmful we should be aware that such inputs could lead to the retrieval of offensive documents and the genera tion of inappropriate responses by the retrieval augmented llms to address this challenge de veloping methods to detect and manage offensive or inappropriate content in both user inputs and re trieved documents within the retrievalaugmented framework is essential we believe that this is a critical area for future work acknowledgements this work was supported by institute for informa tion and communications technology promotion iitp grant funded by the korea government no 2018000582 prediction and augmentation of the credibility distribution via linguistic analysis and automated evidence document collection basic science research program through the national research foundation of korea nrf funded by the ministry of education rs202300275747 and the artificial intelligence industrial convergence cluster development project funded by the ministry of science and ict msit korea  gwangju metropolitan city references rohan anil andrew m dai orhan firat melvin john son dmitry lepikhin alexandre passos siamak shakeri emanuel taropa paige bailey zhifeng chen eric chu jonathan h clark laurent el shafey yanping huang kathy meierhellstern gau rav mishra erica moreira mark omernick kevin robinson sebastian ruder yi tay kefan xiao yuanzhong xu yujing zhang gustavo hern\u00e1ndez \u00e1brego junwhan ahn jacob austin paul barham jan a botha james bradbury siddhartha brahma kevin brooks michele catasta yong cheng colin cherry christopher a choquettechoo aakanksha chowdhery cl\u00e9ment crepy shachi dave mostafa dehghani sunipa dev jacob devlin mark d\u00edaz nan du ethan dyer vladimir feinberg fangxi aoyu feng vlad fienber markus freitag xavier garcia sebastian gehrmann lucas gonzalez and et al 2023 palm 2 technical report arxiv preprint arxiv230510403  akari asai zeqiu wu yizhong wang avirup sil andhannaneh hajishirzi 2024 selfrag learning to retrieve generate and critique through selfreflection inthe twelfth international conference on learning representations  jinheon baek soyeong jeong minki kang jong park and sung ju hwang 2023 knowledgeaugmented language model verification in proceedings of the 2023 conference on empirical methods in natural language processing emnlp 2023 singapore de cember 610 2023  pages 17201736 association for computational linguistics sebastian borgeaud arthur mensch jordan hoffmann trevor cai eliza rutherford katie millican george van den driessche jeanbaptiste lespiau bogdan damoc aidan clark diego de las casas aurelia guy jacob menick roman ring tom hennigan saffron huang loren maggiore chris jones albin cassirer andy brock michela paganini geoffrey",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 3006,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "89df67c6-6315-47e9-8c29-62bc68f71f5a",
        "embedding": null,
        "metadata": {
            "page_label": "10",
            "file_name": "Adaptive-RAG.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
            "file_type": "application/pdf",
            "file_size": 577416,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "21831d2e-b203-4f13-907d-1f67c94718d7",
                "node_type": "4",
                "metadata": {
                    "page_label": "10",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "ff14540c479a957ac1d9b4abe9fe6fe86b588fb0b596e1a2f2ab7d5da834c4bf",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "dc4accb9-69b2-44a4-b177-5821f8ac4a92",
                "node_type": "1",
                "metadata": {
                    "page_label": "10",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "516c7f38cf7dd7d08f5bb9f0309fa640046b9dd00df961c13dd0f1cd2b9518be",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "diego de las casas aurelia guy jacob menick roman ring tom hennigan saffron huang loren maggiore chris jones albin cassirer andy brock michela paganini geoffrey irving oriol vinyals simon osindero karen si monyan jack w rae erich elsen and laurent sifre 2022 improving language models by retrieving from trillions of tokens in international conference on machine learning icml 2022 1723 july 2022 bal timore maryland usa  volume 162 of proceedings of machine learning research  pages 22062240 pmlr tom b brown benjamin mann nick ryder melanie subbiah jared kaplan prafulla dhariwal arvind neelakantan pranav shyam girish sastry amanda askell sandhini agarwal ariel herbertv oss gretchen krueger tom henighan rewon child aditya ramesh daniel m ziegler jeffrey wu clemens winter christopher hesse mark chen eric sigler mateusz litwin scott gray benjamin chess jack clark christopher berner sam mccandlish alec radford ilya sutskever and dario amodei 2020 language models are fewshot learners in ad vances in neural information processing systems 33 annual conference on neural information process ing systems 2020 neurips 2020 december 612 2020 virtual  danqi chen adam fisch jason weston and antoine bordes 2017 reading wikipedia to answer open domain questions in proceedings of the 55th annual meeting of the association for computational lin guistics acl 2017 vancouver canada july 30  august 4 volume 1 long papers  pages 18701879 association for computational linguistics sukmin cho jeongyeon seo soyeong jeong and jong c park 2023 improving zeroshot reader by reducing distractions from irrelevant documents in opendomain question answering in findings of the association for computational linguistics emnlp 2023 singapore december 610 2023  pages 3145 3157 association for computational linguistics hyung won chung le hou shayne longpre barret zoph yi tay william fedus eric li xuezhi wang mostafa dehghani siddhartha brahma albert web son shixiang shane gu zhuyun dai mirac suz gun xinyun chen aakanksha chowdhery sharan",
        "mimetype": "text/plain",
        "start_char_idx": 2846,
        "end_char_idx": 4873,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "38e317f8-4a9a-4657-b091-b4665ea83cd5",
        "embedding": null,
        "metadata": {
            "page_label": "11",
            "file_name": "Adaptive-RAG.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
            "file_type": "application/pdf",
            "file_size": 577416,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "fd45a91a-baf7-4f7f-9c4f-f2097938533b",
                "node_type": "4",
                "metadata": {
                    "page_label": "11",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "e4010287de509fa3fcd6d8154d63f66727272600dece0d450a45f9a791e9a93a",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "e09ff9f8-1604-4611-9ca1-46e0b109723a",
                "node_type": "1",
                "metadata": {},
                "hash": "8243443eebc8987b87c799cd5200e3fb500994db3d81af5c4e312825db3da433",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "narang gaurav mishra adams yu vincent y  zhao yanping huang andrew m dai hongkun yu slav petrov ed h chi jeff dean jacob devlin adam roberts denny zhou quoc v  le and jason wei 2022 scaling instructionfinetuned language models arxiv preprint arxiv221011416  xanh ho anhkhoa duong nguyen saku sugawara and akiko aizawa 2020 constructing a multihop qa dataset for comprehensive evaluation of reason ing steps in proceedings of the 28th international conference on computational linguistics coling 2020 barcelona spain online december 813 2020  pages 66096625 international committee on computational linguistics gautier izacard and edouard grave 2021 leveraging passage retrieval with generative models for open do main question answering in proceedings of the 16th conference of the european chapter of the associ ation for computational linguistics main volume eacl 2021 online april 19  23 2021  pages 874 880 association for computational linguistics gautier izacard patrick s h lewis maria lomeli lucas hosseini fabio petroni timo schick jane dwivediyu armand joulin sebastian riedel and edouard grave 2023 atlas fewshot learning with retrieval augmented language models j mach learn res  24251125143 soyeong jeong jinheon baek sukmin cho sung ju hwang and jong park 2023 testtime selfadaptive small language models for question answering in findings of the association for computational lin guistics emnlp 2023 singapore december 610 2023  pages 1545915469 association for computa tional linguistics zhengbao jiang frank f xu luyu gao zhiqing sun qian liu jane dwivediyu yiming yang jamie callan and graham neubig 2023 active retrieval augmented generation in emnlp 2023  mandar joshi eunsol choi daniel s weld and luke zettlemoyer 2017 triviaqa a large scale distantly supervised challenge dataset for reading comprehen sion in proceedings of the 55th annual meeting of the association for computational linguistics acl 2017 vancouver canada july 30  august 4 volume 1 long papers  pages 16011611 association for computational linguistics vladimir karpukhin barlas oguz sewon min patrick s h lewis ledell wu sergey edunov danqi chen and wentau yih 2020 dense passage retrieval for opendomain question answering in proceedings of the 2020 conference on empirical methods in natu ral language processing emnlp 2020 november 1620 2020  association for computational linguis tics jungo kasai keisuke sakaguchi yoichi takahashi ro nan le bras akari asai xinyan yu dragomir r radev noah a smith yejin choi and kentaro inui2022 realtime qa whats the answer right now arxiv preprint arxiv220713332  omar khattab keshav santhanam xiang lisa li david hall percy liang christopher potts and matei zaharia 2022",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 2703,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "e09ff9f8-1604-4611-9ca1-46e0b109723a",
        "embedding": null,
        "metadata": {
            "page_label": "11",
            "file_name": "Adaptive-RAG.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
            "file_type": "application/pdf",
            "file_size": 577416,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "fd45a91a-baf7-4f7f-9c4f-f2097938533b",
                "node_type": "4",
                "metadata": {
                    "page_label": "11",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "e4010287de509fa3fcd6d8154d63f66727272600dece0d450a45f9a791e9a93a",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "38e317f8-4a9a-4657-b091-b4665ea83cd5",
                "node_type": "1",
                "metadata": {
                    "page_label": "11",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "92923e23c190e82877e13b34d51adbe13ab54007ec42c5509dd5c8d6c5238cba",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "whats the answer right now arxiv preprint arxiv220713332  omar khattab keshav santhanam xiang lisa li david hall percy liang christopher potts and matei zaharia 2022 demonstratesearch predict composing retrieval and language mod els for knowledgeintensive nlp arxiv preprint arxiv221214024  abs221214024 tushar khot harsh trivedi matthew finlayson yao fu kyle richardson peter clark and ashish sab harwal 2023 decomposed prompting a modular approach for solving complex tasks in the eleventh international conference on learning representa tions iclr 2023 kigali rwanda may 15 2023  openreviewnet tom kwiatkowski jennimaria palomaki olivia red field michael collins ankur parikh chris alberti danielle epstein illia polosukhin jacob devlin ken ton lee kristina toutanova llion jones matthew kelcey mingwei chang andrew m dai jakob uszkoreit quoc le and slav petrov 2019 natu ral questions a benchmark for question answering research transactions of the association for compu tational linguistics  7452466 angeliki lazaridou elena gribovskaya wojciech stokowiec and nikolai grigorev 2022 internet augmented language models through fewshot prompting for opendomain question answering arxiv preprint arxiv220305115  belinda z li sewon min srinivasan iyer yashar mehdad and wentau yih 2020 efficient onepass endtoend entity linking for questions in proceed ings of the 2020 conference on empirical methods in natural language processing emnlp 2020 online november 1620 2020  pages 64336441 associa tion for computational linguistics ilya loshchilov and frank hutter 2019 decoupled weight decay regularization in 7th international conference on learning representations iclr 2019 new orleans la usa may 69 2019  openre viewnet alex mallen akari asai victor zhong rajarshi das daniel khashabi and hannaneh hajishirzi 2023 when not to trust language models investigating effectiveness of parametric and nonparametric mem ories in proceedings of the 61st annual meeting of the association for computational linguistics vol ume 1 long papers acl 2023 toronto canada july 914 2023  pages 98029822 association for computational linguistics openai 2023 gpt4 technical report arxiv preprint arxiv230308774  adam paszke sam gross francisco massa adam lerer james bradbury gregory chanan trevor killeen zeming lin natalia gimelshein luca antiga alban desmaison andreas k\u00f6pf edward z",
        "mimetype": "text/plain",
        "start_char_idx": 2538,
        "end_char_idx": 4905,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "35cf0b93-8260-43b4-9dd5-9f43ef110edb",
        "embedding": null,
        "metadata": {
            "page_label": "12",
            "file_name": "Adaptive-RAG.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
            "file_type": "application/pdf",
            "file_size": 577416,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "06b4d39c-7cd1-445e-958b-90ba193a877b",
                "node_type": "4",
                "metadata": {
                    "page_label": "12",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "1aa8d17eb20c0dfb8dfb4e6b1e848e4c26273621c5cd4e4582b97aa16460c6f8",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "705858b5-e0dc-4ec6-8a08-90dafa7858d6",
                "node_type": "1",
                "metadata": {},
                "hash": "6837633070ac4b79b90232244ff94e14103b492d5e2c90fb77c056e94475d59c",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "yang zachary devito martin raison alykhan te jani sasank chilamkurthy benoit steiner lu fang junjie bai and soumith chintala 2019 pytorch an imperative style highperformance deep learning li brary in advances in neural information processing systems 32 annual conference on neural informa tion processing systems 2019  pages 80248035 jayr alencar pereira robson do nascimento fidalgo roberto de alencar lotufo and rodrigo frassetto nogueira 2023 visconde multidocument qa with gpt3 and neural reranking in advances in informa tion retrieval  45th european conference on infor mation retrieval ecir 2023 dublin ireland april 26 2023 proceedings part ii  volume 13981 of lecture notes in computer science  pages 534543 springer ofir press muru zhang sewon min ludwig schmidt noah a smith and mike lewis 2023 measuring and narrowing the compositionality gap in language models in findings of the association for computa tional linguistics emnlp 2023  peng qi haejun lee tg sido and christopher d man ning 2021 answering opendomain questions of varying reasoning steps from text in proceedings of the 2021 conference on empirical methods in natural language processing emnlp 2021 vir tual event  punta cana dominican republic 711 november 2021  pages 35993614 association for computational linguistics colin raffel noam shazeer adam roberts katherine lee sharan narang michael matena yanqi zhou wei li and peter j liu 2020 exploring the limits of transfer learning with a unified texttotext trans former j mach learn res  21140114067 pranav rajpurkar jian zhang konstantin lopyrev and percy liang 2016 squad 100 000 questions for machine comprehension of text in proceedings of the 2016 conference on empirical methods in natural language processing emnlp 2016 austin texas usa november 14 2016  pages 23832392 the association for computational linguistics ori ram yoav levine itay dalmedigos dor muhlgay amnon shashua kevin leytonbrown and yoav shoham 2023 incontext retrievalaugmented lan guage models transactions of the association for computational linguistics  stephen e robertson steve walker susan jones micheline hancockbeaulieu and mike gatford 1994 okapi at trec3 in proceedings of the third text retrieval conference trec 1994 gaithers burg maryland usa november 24 1994  volume 500225 of nist special publication  pages 109 126 national institute of standards and technology nist weijia shi sewon min michihiro yasunaga min joon seo rich james mike lewis luke zettle moyer and wentau yih 2023 replug retrievalaugmented blackbox language models arxiv preprint arxiv230112652  hugo touvron louis martin kevin stone peter al bert amjad almahairi yasmine babaei nikolay bashlykov soumya batra prajjwal bhargava shruti bhosale dan bikel lukas blecher cristian canton ferrer",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 2777,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "705858b5-e0dc-4ec6-8a08-90dafa7858d6",
        "embedding": null,
        "metadata": {
            "page_label": "12",
            "file_name": "Adaptive-RAG.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
            "file_type": "application/pdf",
            "file_size": 577416,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "06b4d39c-7cd1-445e-958b-90ba193a877b",
                "node_type": "4",
                "metadata": {
                    "page_label": "12",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "1aa8d17eb20c0dfb8dfb4e6b1e848e4c26273621c5cd4e4582b97aa16460c6f8",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "35cf0b93-8260-43b4-9dd5-9f43ef110edb",
                "node_type": "1",
                "metadata": {
                    "page_label": "12",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "906607dbff4ae321f4feb44955240a09301d7298db44310cc2d11948ceeaa038",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "peter al bert amjad almahairi yasmine babaei nikolay bashlykov soumya batra prajjwal bhargava shruti bhosale dan bikel lukas blecher cristian canton ferrer moya chen guillem cucurull david esiobu jude fernandes jeremy fu wenyin fu brian fuller cynthia gao vedanuj goswami naman goyal an thony hartshorn saghar hosseini rui hou hakan inan marcin kardas viktor kerkez madian khabsa isabel kloumann artem korenev punit singh koura marieanne lachaux thibaut lavril jenya lee di ana liskovich yinghai lu yuning mao xavier mar tinet todor mihaylov pushkar mishra igor moly bog yixin nie andrew poulton jeremy reizen stein rashi rungta kalyan saladi alan schelten ruan silva eric michael smith ranjan subrama nian xiaoqing ellen tan binh tang ross tay lor adina williams jian xiang kuan puxin xu zheng yan iliyan zarov yuchen zhang angela fan melanie kambadur sharan narang aur\u00e9lien ro driguez robert stojnic sergey edunov and thomas scialom 2023 llama 2 open foundation and fine tuned chat models arxiv preprint arxiv230709288  harsh trivedi niranjan balasubramanian tushar khot and ashish sabharwal 2022a musique multi hop questions via singlehop question composition trans assoc comput linguistics  10539554 harsh trivedi niranjan balasubramanian tushar khot and ashish sabharwal 2022b musique multi hop questions via singlehop question composition transactions of the association for computational linguistics  10539554 harsh trivedi niranjan balasubramanian tushar khot and ashish sabharwal 2023 interleaving retrieval with chainofthought reasoning for knowledge intensive multistep questions in proceedings of the 61st annual meeting of the association for com putational linguistics volume 1 long papers acl 2023 toronto canada july 914 2023  pages 1001410037 association for computational lin guistics jason wei yi tay rishi bommasani colin raffel barret zoph sebastian borgeaud dani yogatama maarten bosma denny zhou donald metzler ed h chi tatsunori hashimoto oriol vinyals percy liang jeff dean and william fedus 2022a emer gent abilities of large language models trans mach learn res  2022 jason wei xuezhi wang dale schuurmans maarten bosma brian ichter fei xia ed h chi quoc v  le and denny zhou 2022b chainofthought prompt ing elicits reasoning in large language models in neurips  thomas wolf lysandre debut victor sanh julien chaumond clement delangue anthony moi pier ric cistac tim rault r\u00e9mi louf morgan funtowicz",
        "mimetype": "text/plain",
        "start_char_idx": 2622,
        "end_char_idx": 5048,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "6271fef9-4686-4a68-995a-2cf5936f4021",
        "embedding": null,
        "metadata": {
            "page_label": "13",
            "file_name": "Adaptive-RAG.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
            "file_type": "application/pdf",
            "file_size": 577416,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "e94f17ec-f7e9-4151-a309-4c4d0354f23c",
                "node_type": "4",
                "metadata": {
                    "page_label": "13",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "dedf1388ea9caff06959df009a59657cfdac6325428d98f1f2ca624b61bcef36",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "joe davison sam shleifer patrick von platen clara ma yacine jernite julien plu canwen xu teven le scao sylvain gugger mariama drame quentin lhoest and alexander m rush 2020 transform ers stateoftheart natural language processing in proceedings of the 2020 conference on empirical methods in natural language processing system demonstrations emnlp 2020  demos  pages 38 45 association for computational linguistics lee xiong chenyan xiong ye li kwokfung tang jialin liu paul n bennett junaid ahmed and arnold overwijk 2021 approximate nearest neigh bor negative contrastive learning for dense text re trieval in 9th international conference on learning representations iclr 2021 virtual event austria may 37 2021  openreviewnet wei yang yuqing xie aileen lin xingyu li luchen tan kun xiong ming li and jimmy lin 2019 endtoend opendomain question answering with bertserini in proceedings of the 2019 conference of the north american chapter of the association for computational linguistics human language technologies naaclhlt 2019 minneapolis mn usa june 27 2019 demonstrations  pages 7277 association for computational linguistics zhilin yang peng qi saizheng zhang yoshua bengio william cohen ruslan salakhutdinov and christo pher d manning 2018 hotpotqa a dataset for diverse explainable multihop question answering inproceedings of the 2018 conference on empiri cal methods in natural language processing  pages 23692380 brussels belgium association for com putational linguistics shunyu yao jeffrey zhao dian yu nan du izhak shafran karthik r narasimhan and yuan cao 2023 react synergizing reasoning and acting in language models in the eleventh international conference on learning representations iclr 2023 kigali rwanda may 15 2023  openreviewnet fengbin zhu wenqiang lei chao wang jianming zheng soujanya poria and tatseng chua 2021 retrieving and reading a comprehensive survey on opendomain question answering arxiv preprint arxiv210100774",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 1949,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "65dba927-5e38-40da-abee-bc02cf370151",
        "embedding": null,
        "metadata": {
            "page_label": "14",
            "file_name": "Adaptive-RAG.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
            "file_type": "application/pdf",
            "file_size": 577416,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "796d1901-26a9-4e27-a67b-760a1b3c061e",
                "node_type": "4",
                "metadata": {
                    "page_label": "14",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "923f424689cb42448651cbd7ef42231ea66d413a578d06e9b6731d1361ea69e6",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "ae63ddf5-ef2e-4bf7-b73b-c2ca89331987",
                "node_type": "1",
                "metadata": {},
                "hash": "fc800518bcc41efa0143a4e25e9a6e50810358c0aa6901e9c5961d677b568fbd",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "0 2 4 6 8 10 time per query20304050performance f1 no retrieval singlestep approach adaptive retrieval multistep approach adaptiverag oursperformance vs time with flant5xlfigure 4 qa performance f1 and efficiency timequery for different retrievalaugmented generation approaches we use the flant5xl 3b as the base llm a additional experimental setups a1 datasets we use publicly open datasets for both single hop and multihop qa datasets referring to as karpukhin et al 2020 and trivedi et al 2023 respectively we describe the characteristics of each dataset 1 squad v11 rajpurkar et al 2016 is created through a process where annotators write questions based on the documents they read 2 natural questions kwiatkowski et al 2019 is constructed by real user queries on google search 3 triviaqa joshi et al 2017 comprises trivia questions sourced from various quiz websites 4 musique trivedi et al 2022a is collected by compositing multiple singlehop queries to form queries spanning 24 hops 5 hotpotqa yang et al 2018 is constructed by having annotators create questions that link multi ple wikipedia articles 6 2wikimultihopqa ho et al 2020 is derived from wikipedia and its associated knowledge graph path needing 2hops a2 models we describe the details of models as follows 1 no retrieval this approach uses only the llm itself to generate the answer to the given query 2 singlestep approach this approach first re trieves the relevant knowledge with the given query from the external knowledge sources and then aug ments the llm with this retrieved knowledge to generate the answer which iterates only once 3 adaptive retrieval this baseline mallen et al 2023 adaptively augments the llm with the re trieval module only when the entities appearing in queries are less popular to extract entities we use the available entitylinking method li et al 2020 namely blink for questions 4 selfrag this baseline asai et al 2024 00 05 10 15 20 25 30 35 40 time per query304050performance f1 no retrieval singlestep approach adaptive retrieval multistep approach adaptiverag oursperformance vs time with flant5xxlfigure 5 qa performance f1 and efficiency timequery for different retrievalaugmented generation approaches we use the flant5xxl 11b as the base llm trains the llm to adaptively perform retrieval and generation where the retrieval is conducted once it predicts the special retrieval token above a certain threshold and the answer generation follows 5 adaptiverag this is our model that adap tively selects the retrievalaugmented generation strategy smoothly oscillating between the non retrieval singlestep approach and multistep ap proaches4without architectural changes based on the query complexity assessed by the classifier 6 multistep approach this approach trivedi et al 2023 is the multistep retrievalaugmented llm which iteratively accesses both the retriever and llm with interleaved chainofthought rea soning wei et al 2022b repeatedly until it derives the solution or reaches the maximum step number 7 adaptiverag w oracle this is an ideal sce nario of our adaptiverag equipped with an or acle classifier that perfectly categorizes the query complexity a3 implementation details for computing resources we use a100 gpus with 80gb memory in addition due",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 3267,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "ae63ddf5-ef2e-4bf7-b73b-c2ca89331987",
        "embedding": null,
        "metadata": {
            "page_label": "14",
            "file_name": "Adaptive-RAG.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
            "file_type": "application/pdf",
            "file_size": 577416,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "796d1901-26a9-4e27-a67b-760a1b3c061e",
                "node_type": "4",
                "metadata": {
                    "page_label": "14",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "923f424689cb42448651cbd7ef42231ea66d413a578d06e9b6731d1361ea69e6",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "65dba927-5e38-40da-abee-bc02cf370151",
                "node_type": "1",
                "metadata": {
                    "page_label": "14",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "7df3641f41d69f13965ae7a7aaedda2d58e160b4e88cd1441aaf027a8805414d",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "w oracle this is an ideal sce nario of our adaptiverag equipped with an or acle classifier that perfectly categorizes the query complexity a3 implementation details for computing resources we use a100 gpus with 80gb memory in addition due to the sig nificant costs associated with evaluating retrieval augmented generation models we perform experi ments with a single run finally we implemented models using pytorch paszke et al 2019 and transformers library wolf et al 2020 b additional experimental results performance vs time we further provide a com parison of different retrievalaugmented genera tion approaches with flant5xl and flant5 xxl models in figure 4 and figure 5 respectively in the context of performance and efficiency trade offs similar to the observation made from the gpt 35 model in figure 1 our proposed adaptiverag is significantly more effective as well as efficient 4for the multistep approach we use the stateoftheart question answering strategy from ircot trivedi et al 2023",
        "mimetype": "text/plain",
        "start_char_idx": 3029,
        "end_char_idx": 4030,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "03f98119-9be2-4cb9-976a-f1981d70476c",
        "embedding": null,
        "metadata": {
            "page_label": "15",
            "file_name": "Adaptive-RAG.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
            "file_type": "application/pdf",
            "file_size": 577416,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "278e6d11-0a79-4b3f-a90a-703fe98a94fd",
                "node_type": "4",
                "metadata": {
                    "page_label": "15",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "3c61f9256bfb3e4a4fa369ef4dccb672903f9cbefbbcda5f2b9d731d24dcff3b",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "15983818-2cb2-4900-bd2e-223ec72b5936",
                "node_type": "1",
                "metadata": {},
                "hash": "248b9db2c8c0d1a99d710abc31b4584ae59bef150473c72dab4cdca1bf0e4193",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "table 7 results on each of a collection of datasets with flant5xxl 11b as the llm we emphasize our results in bold squad natural questions triviaqa data types methods em f1 acc step time em f1 acc step time em f1 acc step time singlestepsimpleno retrieval 700 1440 840 000 008 1880 2550 2040 000 008 3280 3920 3540 000 008 singlestep approach 2880 4080 3500 100 100 4140 5120 4760 100 100 5600 6470 6180 100 100 adaptiveadaptive retrieval 1560 2560 2000 050 054 3100 3970 3500 050 054 4480 5220 4860 050 054 selfrag160 1190 2080 059 031 3920 4710 4240 075 009 1460 3370 6020 076 022 adaptiverag ours 2780 3980 3400 117 150 4120 5100 4740 100 100 5200 6030 5720 103 133 complex multistep approach 2460 3690 3020 213 383 3960 4960 4640 216 394 5260 6110 5940 217 403 oracle adaptiverag w oracle 3280 4690 3820 085 094 5120 6100 5700 071 091 6340 7130 6820 051 060 musique hotpotqa 2wikimultihopqa data types methods em f1 acc step time em f1 acc step time em f1 acc step time multistepsimpleno retrieval 420 1340 540 000 008 1740 2544 1840 000 009 2680 3293 2800 000 008 singlestep approach 1680 2570 1920 100 100 3760 4927 3960 100 100 4660 5413 4820 100 100 adaptiveadaptive retrieval 840 1780 1020 050 054 2660 3601 2780 050 054 3520 4268 3680 050 054 selfrag120 820 1180 068 027 560 1786 3060 076 026 300 1914 3900 090 025 adaptiverag ours 2060 2850 2320 189 312 4420 5478 4680 158 253 4760 5736 5400 146 255 complex multistep approach 1940 2750 2180 209 366 4700 5781 4940 208 373 5760 6765 6400 217 363 oracle adaptiverag w oracle 2420 3720 2660 122 171 5220 6480 5460 092 133 5920 7040 6860 082 114 table 8 results on each of a collection of datasets with gpt35 turbo as the llm we emphasize our results in bold squad natural questions triviaqa data",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 1754,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "15983818-2cb2-4900-bd2e-223ec72b5936",
        "embedding": null,
        "metadata": {
            "page_label": "15",
            "file_name": "Adaptive-RAG.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
            "file_type": "application/pdf",
            "file_size": 577416,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "278e6d11-0a79-4b3f-a90a-703fe98a94fd",
                "node_type": "4",
                "metadata": {
                    "page_label": "15",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "3c61f9256bfb3e4a4fa369ef4dccb672903f9cbefbbcda5f2b9d731d24dcff3b",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "03f98119-9be2-4cb9-976a-f1981d70476c",
                "node_type": "1",
                "metadata": {
                    "page_label": "15",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "d6f8d00e1a63711c409b400605296f1866e34b35e36228019a5c5b7f6abbe1d2",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "b9ace35a-8274-4934-8b9c-1225347e18cf",
                "node_type": "1",
                "metadata": {},
                "hash": "83bb00a1dfc4594aa5bdbd29c4d081e05b8a3747d8766b779272ead5815113b7",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "092 133 5920 7040 6860 082 114 table 8 results on each of a collection of datasets with gpt35 turbo as the llm we emphasize our results in bold squad natural questions triviaqa data types methods em f1 acc step time em f1 acc step time em f1 acc step time singlestepsimpleno retrieval 1600 2920 2380 000 062 3980 5570 5500 000 056 6400 7560 7580 000 068 singlestep approach 1800 3380 2920 100 100 3240 4680 5480 100 100 5520 6650 6580 100 100 adaptiveadaptive retrieval 1540 3000 2440 050 081 3640 5120 5660 050 078 6200 7190 7220 050 084 selfrag160 1190 2080 059 191 3920 4710 4240 075 052 1460 3370 6020 076 159 adaptiverag ours 1980 3440 3000 087 121 3680 5200 5660 068 086 6240 7380 7380 022 079 complex multistep approach 1740 3150 2620 250 324 3560 4970 5780 258 379 5480 6710 6800 230 265 oracle adaptiverag w oracle 2800 4590 3940 054 093 5000 6540 6700 028 08 7080 8100 8000 011 073 musique hotpotqa 2wikimultihopqa data types methods em f1 acc step time em f1 acc step time em f1 acc step time multistepsimpleno retrieval 2040 3130 2440 000 081 3740 5104 4320 000 074 3700 4850 4340 000 090 singlestep approach 1640 2670 2360 100 100 3960 5044 4560 100 100 4680 5769 5260 100 100 adaptiveadaptive retrieval 1880 3030 2480 050 090 3860 5070 4320 050 087 4420 5511 5060 050 095 selfrag120 820 1180 068 166 560 1786 3060 076 167 300 1914 3900 090 181 adaptiverag ours 2180 3260 2960 190 229 4040 5256 4700 093 148 4660 6009 5680 159 223 complex multistep approach 2300 3250 3160 341 361 4580 5836 5220 273 318 5220 6608 6240 336 335 oracle adaptiverag w oracle 2960 4470 3560 090 145 5560 6990 6280 054 108 5220 6990 6660 065 121 performance per dataset in addition to detail ing the performance of each dataset with",
        "mimetype": "text/plain",
        "start_char_idx": 1573,
        "end_char_idx": 3296,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "b9ace35a-8274-4934-8b9c-1225347e18cf",
        "embedding": null,
        "metadata": {
            "page_label": "15",
            "file_name": "Adaptive-RAG.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
            "file_type": "application/pdf",
            "file_size": 577416,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "278e6d11-0a79-4b3f-a90a-703fe98a94fd",
                "node_type": "4",
                "metadata": {
                    "page_label": "15",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "3c61f9256bfb3e4a4fa369ef4dccb672903f9cbefbbcda5f2b9d731d24dcff3b",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "15983818-2cb2-4900-bd2e-223ec72b5936",
                "node_type": "1",
                "metadata": {
                    "page_label": "15",
                    "file_name": "Adaptive-RAG.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Adaptive-RAG.pdf",
                    "file_type": "application/pdf",
                    "file_size": 577416,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "8d1858dbdbde68c86f9dea6f0b5f5c3e907e5e144cb901bd0840ae12fb07d068",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "4470 3560 090 145 5560 6990 6280 054 108 5220 6990 6660 065 121 performance per dataset in addition to detail ing the performance of each dataset with the flan t5xl model as shown in table 2 we also present the results for each dataset with the flant5 xxl and gpt35 models in table 2 and table 8 respectively the experimental results show that our adaptiverag consistently balances between efficiency and accuracy it is worth noting that while the gpt35 model performs effectively in addressing straightforward queries even without document retrieval it benefits significantly from our adaptiverag in terms of effectiveness when solving complex multihop queries",
        "mimetype": "text/plain",
        "start_char_idx": 3146,
        "end_char_idx": 3807,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "f34cc168-ff8e-41a5-b7f8-67ef957272e0",
        "embedding": null,
        "metadata": {
            "page_label": "1",
            "file_name": "RAFT.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAFT.pdf",
            "file_type": "application/pdf",
            "file_size": 784351,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "8a635e9f-18b7-41d5-a94b-515bc6475ccf",
                "node_type": "4",
                "metadata": {
                    "page_label": "1",
                    "file_name": "RAFT.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAFT.pdf",
                    "file_type": "application/pdf",
                    "file_size": 784351,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "15aad394e7c3cc06f67386d4cec3b1974f9d4dada4c5c110952e40f503671c94",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "preprint under review raft adapting language model to domain specific rag tianjun zhang department of computer science uc berkeley berkeley ca 94720 usa tianjunzberkeleyedushishir g patil naman jain sheng shen department of computer science uc berkeley berkeley ca 94720 usa shishirpatilnaman_jainshengsberkeleyedu matei zaharia ion stoica joseph e gonzalez department of computer science uc berkeley berkeley ca 94720 usa mateiistoicajegonzalberkeleyedu abstract pretraining large language models llms on large corpora of textual data is now a standard paradigm when using these llms for many downstream applications it is common to additionally incorporate new in formation into the pretrained model either through ragbasedprompting or finetuning however the best methodology to incorporate information remains an open question in this paper we present retrieval augmented fine tuning raft a training recipe which improves the models ability to answer questions in openbook indomain settings in training raft given a question and a set of retrieved documents we train the model to ignore those documents that dont help in answering the question which we call distractor documents raft accomplishes this by citing verbatim the right sequence from the relevant document to help answer the question this coupled with rafts chainofthoughtstyle response helps improve the models ability to reason in domain specific rag raft consistently improves the models performance across pubmed hotpotqa and gorilla datasets presenting a posttraining recipe to improve pretrained llms to indomain rag 1 introduction trained on vast quantities of public data large language models llms have achieved significant advances in a wide range of general knowledge reasoning tasks brown et al 2020 wei et al 2022 however increasingly llms are being employed in specialized domains to support tasks ranging from code completion for specific software frameworks to question answering on specific document collections eg legal or medical documents in these settings general knowledge reasoning is less critical and instead the primary goal is to maximize accuracy based on a given set of documents indeed adapting llms to the specialized domains eg recent news enterprise private documents or program resources constructed after the training cutoff is essential to many emerging applications vu et al 2023 lazaridou et al 2022 and is the focus of this work this paper studies the following question  how do we adapt pretrained llms for retrieval augmented generation rag in specialized domains when it comes to adapting llms to specialized domains we consider the following two candidates incontext learning through retrievalaugmented generation rag and super vised finetuning rag based methods allow the llm to reference the documents when corresponding author personal website tianjunzgithubio 1arxiv240310131v2 cscl 5 jun 2024",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 2904,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "31104b72-4976-4cdd-9693-23a6901a8868",
        "embedding": null,
        "metadata": {
            "page_label": "2",
            "file_name": "RAFT.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAFT.pdf",
            "file_type": "application/pdf",
            "file_size": 784351,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "a43fc164-3f83-4ae2-95f2-6b44094620c7",
                "node_type": "4",
                "metadata": {
                    "page_label": "2",
                    "file_name": "RAFT.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAFT.pdf",
                    "file_type": "application/pdf",
                    "file_size": 784351,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "995fea9eb73a3baffa6ea3e44c6f2a6bc5bea457a2f2a248de92170d56e5de33",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "preprint under review open book query answerclosed book query answerbake in knowledge at train timemodel can use external docs at test raft proposed query answerteach model to use external docs at test figure 1 how best to prepare for an exam a finetuning based approaches implement studying by either directly memorizing the input documents or answering practice qa without referencing the documents b alternatively incontext retrieval methods fail to leverage the learning opportunity afforded by the fixed domain and are equivalent to taking an openbook exam without studying in contrast our approach c raft leverages finetuning with questionanswer pairs while referencing the documents in a simulated imperfect retrieval setting  thereby effectively preparing for the openbook exam setting answering questions however rag based incontext learning methods fail to leverage the learning opportunity afforded by the fixed domain setting and early access to the test documents alternatively supervised finetuning offers the opportunity to learn more general patterns in the documents and better align to end tasks and user preferences zhou et al 2023 however existing finetuning based approaches either fail to leverage the documents at test time dont incorporate rag or fail to account for the imperfections in retrieval process during training we can draw an analogy to an openbook exam existing incontext retrieval methods are equivalent to taking an openbook exam without studying alternatively existing fine tuning based approaches implement studying by either directly memorizing xiong et al 2023 the input documents or answering practice questions wang et al 2022 without referencing the documents while these approaches leverage indomain learning they fail to prepare for the openbook nature of the test setting in this paper we study how to combine instruction finetuning ift with retrieval aug mented generation rag we propose a novel adaptation strategy  retrievalaugmented fine tuning raft raft specifically addresses the challenge of finetuning llms to both incorporate domain knowledge while also improving indomain rag performance raft aims to not only enable models to learn domainspecific knowledge through finetuning but also to ensure robustness against distracting retrieved information this is achieved by training the models to understand the dynamics between the question prompt the domainspecific documents retrieved and the right answer going back to our analogy to the open book exam our approach is analogous to studying for an openbook exam by recognizing relevant and irrelevant retrieved documents in raft we train the model to answer the question q from documents d to generate answer a where a includes chainofthought reasoning wei et al 2022 anthropic 2023 and in the presence of distractor documents  dk we explain the methodology in section 3 and analyze the sensitivity to the number of distractor documents  k at train and test time in section 5 raft consistently outperforms supervisedfinetuning both with and without rag across pubmed dernoncourt  lee 2017 hotpot qa yang et al 2018 and huggingface hub torch hub and tensorflow hub gorilla datasets patil et al 2023 presenting a novel yet simple technique to improve pretrained llms for indomain rag our code is available at httpsgithubcomshishirpatilgorilla  2 llms for openbook exam to understand our goal better we expand on our analogy between training an llm with the realworld setting of prepararing for an exam closedbook exam a closed book exam often refers to the scenario where the llms do not have access to any additional documents or references to answer the questions during 2",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 3679,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "fc65aa12-da34-4207-9ce8-e277538b9403",
        "embedding": null,
        "metadata": {
            "page_label": "3",
            "file_name": "RAFT.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAFT.pdf",
            "file_type": "application/pdf",
            "file_size": 784351,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "e02a216e-9ce1-4df2-b08d-c3905be6e697",
                "node_type": "4",
                "metadata": {
                    "page_label": "3",
                    "file_name": "RAFT.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAFT.pdf",
                    "file_type": "application/pdf",
                    "file_size": 784351,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "f4e7e2e2f147d22cf726549d5335b88789409b19ecac0d07f7dafdfc523a65e0",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "preprint under review figure 2 overview of our raft method the topleft figure depicts our approach of adapting llms to reading solution from a set of positive and distractor documents in contrast to standard rag setup where models are trained based on the retriever outputs which is a mixture of both memorization and reading at test time all methods follow the standard rag setting provided with a topk retrieved documents in the context the exam for llms this is equivalent to the scenario for example in which the llm is used as a chatbot in this scenario the llm draws from the knowledge baked in during pretraining and supervisedfinetuning to respond to the users prompt open book exam in contrast we liken the openbook exam setting to the scenario in which the llm can refer to external sources of information eg a website or a book chapter in such scenarios typically the llm is paired with retriever which retrieves k documents or specific segments of the document which are appended to the users prompt it is only through these documents retrieved that the llm gains access to domainspecific information as a result we argue that the llms performance in these settings where it is trained as a generalpurpose llm is largely dependent on the quality of the retriever and how accurately the retriever can identify the most relevant piece of information domainspecific openbook exam in this paper we focus on the narrower but increas ingly popular domain than the general open book exam which we call the domainspecific openbook exam here we know apriori the domain in which the llm will be tested the llm can respond to the users prompt using use any and all information from this specific domain which it has been finetuned on examples of domain specific examples include enterprise documents code repositories belonging to an organization etc in all these scenarios the llm will be used to respond to the questions whose answers can be found within a collection of documents the retrieval technique itself has little to noimpact on the mechanism though it may impact the accuracy this paper studies the domainspecific openbook setting and how to adapt a pretrained llm to this specific domain including how to make it more robust to a varying number of retrieved documents and distractors 3 raft in this section we present raft a novel way of training llms for domainspecific open book exams we first introduce the classical technique of supervised finetuning followed with the key takeaways from our experiments then we introduce raft  a modified version of general instruction tuning lastly we provide an overview of the experiments to expect in the later sections supervised finetuning consider the supervised finetuning sft setting for a questionanswer dataset the formulation consists of the dataset  d from which a set of question  q and corresponding answer  a pairs are derived or already available in the classical sft setting the model is trained to improve its ability to answer the questions based on its knowledge  obtained either during pretraining or during the sft training phase the model so trained can also 3",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 3136,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "ea8360c6-f730-4a12-8860-ccd6c351c00e",
        "embedding": null,
        "metadata": {
            "page_label": "4",
            "file_name": "RAFT.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAFT.pdf",
            "file_type": "application/pdf",
            "file_size": 784351,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "6d090670-41ec-4ba1-bc7f-b60bb4a9baf7",
                "node_type": "4",
                "metadata": {
                    "page_label": "4",
                    "file_name": "RAFT.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAFT.pdf",
                    "file_type": "application/pdf",
                    "file_size": 784351,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "5a2eac64027431a897d8788098f6a9230002f367b6794fc68dba856f3c467c2a",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "preprint under review be used at testtime with retrieval augmented generation rag setting where additional documents can be introduced in the prompt to help the model answer the question this can be represented as follows train qa 0shot inference qa rag inference qda raft retrieval augmented finetuning raft presents a novel recipe to prepare fine tuning data to tailor the models for domainspecific openbook setting equivalent to in domain rag in raft we prepare the training data such that each data point contains a question  q a set of documents  dk and a corresponding chainofthough style answer a generated from one of the document  d we differentiate between two types of documents golden documents  d ie the documents from which the answer to the question can be deduced and distractor documents  di that do not contain answer relevant information as an implementation detail the golden document doesnt need to be a single document but can be more than one document as is the case in hotpotqa yang et al 2018 then for pfraction of the questions  qi in the dataset we retain the golden document  d i along with distractor documents  dk1 for 1pfraction of the questions qi in the dataset we include no golden document and only include distractor documents dk we then finetune the language model using standard supervised training sft technique training it to generate answers from the provided documents and question fig 2 illustrates the highlevel design principal for raft  we demonstrate that our rag approach trains the model to perform better rag on the set of documents it is trained on ie indomain  by removing the golden documents in some instances we are compelling the model to memorize answers instead of deriving them from the context the training data for raft is as follows and an example training data can be seen in fig 3 p of data qdd1d2     dka 1p  of data qd1d2     dka subsequently for the test scenario the model is provided with the q and topk documents retrieved by the rag pipeline note that raft is independent of the retriever used a key factor in enhancing training quality is the generation of a reasoning process such as chainofthought to explain the provided answers raft approach is similar we demonstrate that creating a full reasoning chain and inaddition clearly citing sources enhances the models accuracy in answering questions in fig 3 we illustrate this set up generating the training data in this fashion involves presenting the model with a question context and verified answers and then requesting it to form a reasoning chain that appropriately references the original context for all the datasets in our experiments we generate the answers using the technique described above note that the gorilla apibench dataset already includes reasoning in the answers we provide an example of the generation step in fig 3 the detailed reasoning answer includes a citation from the original context inside begin_quote and end_quote as well as the detailed explanation on how to reach the conclusion based on the citations we demonstrate that adding detailed reasoning paragraphs can help boost the models performance in our experiment section 4 evaluation we design our experiments to study how well raft performs compared to various base lines we find that the raft7b model a finetuned version of llama2 is better at reading and extracting information from indomain documents than domainspecific finetuned model and generalpurpose model with rag as an ablation we also demonstrate how important it is for the model to learn with chainofthought responses in this section we will first introduce all the datasets we used in the experiments then all the baseline modelfinetuning techniques that we benchmark against 4",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 3753,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "97c943a9-8794-4ff4-b65c-44ccb7b4bda3",
        "embedding": null,
        "metadata": {
            "page_label": "5",
            "file_name": "RAFT.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAFT.pdf",
            "file_type": "application/pdf",
            "file_size": 784351,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "60852b12-eeae-4ea4-a87c-6f824fcd1d97",
                "node_type": "4",
                "metadata": {
                    "page_label": "5",
                    "file_name": "RAFT.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAFT.pdf",
                    "file_type": "application/pdf",
                    "file_size": 784351,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "f3cdfa39451820042725b22cf798b7101908667e80de20659cd5f6ca05dd4cf1",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "preprint under review question the oberoi family is part of a hotel company that has a head office in what city context the oberoi family is an indian family that is famous for its involvement in hotels namely through the oberoi groupit is located in city center of jakarta near mega kuningan adjacent to the sister jw marriott hotel it is operated by the ritzcarlton hotel company the complex has two towers that comprises a hotel and the airlangga apartment respectivelythe oberoi group is a hotel company with its head office in delhi instruction given the question context and answer above provide a logical reasoning for that answer please use the format of reason reason answer answer  cot answer reason the document begin_quote the oberoi family is an indian family that is famous for its involvement in hotels namely through the oberoi group end_quote establishes that the oberoi family is involved in the oberoi group and the document begin_quote the oberoi group is a hotel company with its head office in delhi end_quote establishes the head office of the oberoi group therefore the oberoi family is part of a hotel company whose head office is in delhi answer delhi figure 3 raft prompt to help llm evaluate its own generated reasoning and answers contrasting them with the correct reasoning and answers the llm is prompted to identify errors in its reasoning and extract key insights for improvement this figure specifically represents the generateexplanation step in the raft algorithm section 3 table 1 raft improves rag performance for all specialized domains  across pubmed hotpot huggingface torch hub and tensorflow hub we see that domainspecific fine tuning improves significantly of the performance of the base model raft consistently outperforms the existing domainspecific finetuning method with or without rag this suggests the need to train the model with context we compare our model with llama finetuning receipes and provide gpt35 for reference pubmed hotpot huggingface torch hub tensorflow gpt35  rag 7160 415 2908 6021 6559 llama27b 565 054 022 0 0 llama27b  rag 588 003 2643 0860 4306 dsf 597 638 6106 8494 8656 dsf  rag 716 441 4259 8280 6029 raft llama27b 7330 3528 7400 8495 8686 datasets in our experiments we use the following datasets to evaluate our model and all baselines we selected these datasets to represent both popular and diverse domains including wikipedia codingapi documents and questionanswering on medical docu ments natural questions nq kwiatkowski et al 2019 trivia qa joshi et al 2017 and hotpotqa yang et al 2018 are the opendomain questionanswers based on wikipedia mainly focused on common knowledge eg movies sports etc huggingface torch hub and tensorflow hub are from the apibench patil et al 2023 proposed in the gorilla paper these benchmarks measure how to generate the correct functional and executable api calls based on the documentation pubmed qa jin et al 2019 is a questionanswering dataset tailored only for biomedicalresearch questionanswering it mainly focuses on answering medical and biology questions based on a given set of documents we would 5",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 3122,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "84c3986a-7ad6-4a6e-9a81-c991e229c843",
        "embedding": null,
        "metadata": {
            "page_label": "6",
            "file_name": "RAFT.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAFT.pdf",
            "file_type": "application/pdf",
            "file_size": 784351,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "e93ccf79-e35a-47c8-ad90-acf3eff97231",
                "node_type": "4",
                "metadata": {
                    "page_label": "6",
                    "file_name": "RAFT.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAFT.pdf",
                    "file_type": "application/pdf",
                    "file_size": 784351,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "9bb024aa8dbaaa7ae9e998f2905691d89b2769e3c4c839ec91d2a4352dda9e68",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "preprint under review like to highlight that nq trivia qa and hotpotqa are relatively general domain whereas the latter two domains are on domainspecific documents baselines we consider the following baselines for our experiments llama27bchat model with 0shot prompting this is the commonly used instructionfinetuned model for qa tasks where we provide clearly written instruc tions but no reference documentation llama27bchat model with rag llama2  rag similar to the previous setting except here we include reference documents this is a popular technique when dealing with domainspecific qa tasks domainspecific finetuning with 0shot prompting dsf standard supervised finetuning without documents in context we find that its mostly useful to align the answering style of the model as well as get familiar with the domain context domainspecific finetuning with rag dsf  rag equip a domainspecific finetunedmodel with external knowledge using rag so for the knowledge the model does not know it can still refer to the context 41 results using the above datasets and baselines we evaluate our model raft and demonstrate the effectiveness of raft in tab 1 we see that raft consistently and significantly outperforms the baselines compared with the base llama2 instructiontuned model raft with rag does much better in terms of extracting information as well as being robust towards distractors the gain can be as big as 3525 on hotpot qa and 7635 on torch hub evaluation compared with dsf on the specific dataset our model does better at relying on the provided context to solve the problem raft does much better on the tasks like hotpot and huggingface datasets 3087 on hotpot and 3141 on huggingface note that for pubmed qa since it is a binary yesno question we dont observe significant gains when we compare our model with dsf  rag even compared with a much larger and better model gpt35 raft demonstrates significant advantages overall the llama7b model both with and without the rag performs poorly due to its answering style not aligning with the ground truth by applying domainspecific tuning we significantly enhance its performance this process enables the model to learn and adopt the appropriate style of answering however introducing rag to a domainspecifically finetuned dsf model doesnt invariably lead to better outcomes this might indicate that the model lacks training in context processing and extracting useful information from it by incorporating our method raft  we train the model not only to match its answering style with that required but also to improve its document processing capabilities consequently our approach outperforms all others 42 effect of cot we also conduct an analysis to evaluate the effectiveness of the chainofthought approach in enhancing the models performance as indicated in table 2 simply providing the answer to a question may not always be adequate this approach can lead to a rapid decrease in loss resulting in the model beginning to overfit incorporating a reasoning chain that not only guides the model to the answer but also enriches the models understanding can improve the overall accuracy and prevent overfitting to concise answers in our experiments integrating the chainofthought significantly enhances training robustness we employ gpt41106 to generate our chainofthought prompts and include an example of the prompt we used in figure 3 43 qualitative analysis to illustrate the potential advantages of raft over the domainspecifically finetuned dsf approach we present a comparative example in figure 4 this example qualitatively 6",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 3593,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "6759c202-72b6-4a5f-ad7b-1f6ad771ccb7",
        "embedding": null,
        "metadata": {
            "page_label": "7",
            "file_name": "RAFT.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAFT.pdf",
            "file_type": "application/pdf",
            "file_size": 784351,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "80ea2aba-4fcc-4011-8333-e4f27abf45cd",
                "node_type": "4",
                "metadata": {
                    "page_label": "7",
                    "file_name": "RAFT.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAFT.pdf",
                    "file_type": "application/pdf",
                    "file_size": 784351,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "fc13c617f3dc7974643f77a435faa61d98f2b5d73b6c0896a95a6b3667e1faff",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "preprint under review table 2 ablation on chainofthought  the numbers of raft and raft without cot results on various datasets show that adding cot can significantly improve the performance of the finetuned model with a gains of 966 and 1493 in the hotpot qa and huggingface datasets respectively pubmed hotpotqa huggingface torch hub tensorflow raft wo cot 6830 2562 5907 8656 8321 raft 7330 3528 7400 8495 8686 demonstrates a scenario where the dsf model becomes confused by a question asking for the identity of a screenwriter instead of providing the correct name it mistakenly cites one of the films written by the screenwriter in contrast the raft model accurately answers the question this discrepancy suggests that training a model solely with questionanswer pairs may impair its ability to derive relevant context from provided documents the comparison underscores the importance of incorporating both standard instructional tuning and context comprehension into the training dataset to preserve and enhance the models ability to process text effectively hotpot qa question what screenwriter with credits for evolution01879e a film starring nicolas cage and t\u00e9a leoni documents   david weiss man is a screen writer and director his film credits include the family man 2000 evo lution 2001 and when in rome 2010    the family man is a 2000 american romantic comedydrama film directed by brett ratner written by david diamond and david weissman and starring nico lascage and t\u00e9aleoni      raft reason the screenwriter with credits for the film evolution starring nicolas cage and t\u00e9a leoni is david weissman this information is provided in the reference documents where it mentions david weissman as a screenwriter with film credits including the family man 2000 evolution 2001 and when in rome 2010 therefore the screenwriter for evolution is david weissman answer david weiss man dsf the fam ilyman figure 4 comparison of raft and dsf  on the hotpot qa dataset we can see that dsf model extracts the wrong information from the context when the question is asking who is the screen writer and it answers a film name raft manages to get the accurate results  44 should we train the llm always with the golden context for rag in our exploration of whether large language models llms should always be trained with the golden context for retrievalaugmented generation rag we address a key question what proportion p of the training data should include golden documents intuitively one might assume that for effective training in reading and extracting information from context eg rag tasks the golden document should always be included during training p  100 however our findings challenge this assumption incorporating a portion of the training data without the golden document in the context p  80 appears to enhance the models performance on rag tasks 7",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 2860,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "77422ea2-a0f7-40fc-9af5-356f2154eb7d",
        "embedding": null,
        "metadata": {
            "page_label": "8",
            "file_name": "RAFT.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAFT.pdf",
            "file_type": "application/pdf",
            "file_size": 784351,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "2be5bb2a-8729-4114-afe7-caa93fc43ef4",
                "node_type": "4",
                "metadata": {
                    "page_label": "8",
                    "file_name": "RAFT.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAFT.pdf",
                    "file_type": "application/pdf",
                    "file_size": 784351,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "c7c885bbd1674bbfa47ccf92a3711e2691bd8ba349bacd8518c6260bd64fbfc9",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "preprint under review 0 20 40 60 80 100 p  golden retrieved context at training025030035040045final accuracy t est domain nq 0 20 40 60 80 100  golden retrieved context at training050055060065final accuracy t est domain tqa 0 20 40 60 80 100 p  golden retrieved context at training040045050055060final accuracy t est domain hopo figure 5 how many golden documents to involve we study the hyperparameter p where it indicates how much portion of training data is with golden document results on nq tqa and hotpotqa suggest that mixing some amount of data that the golden document is not put in the context is helpful for indomain rag figure 5 presents our investigation into the hyperparameter p which represents the percentage of training instances that should include golden documents we find that the optimal proportion varies across datasets with p ranging from 40 60 and 100 this indicates that training your llm without the correct corresponding context at times can be beneficial for the downstream task of answering questions related to the documents in our training setup we include four distractor documents alongside the golden document and at test time we maintain this format by providing the golden document with four distractors our findings suggest that for domainspecific rag tasks including a certain percentage of training data without the golden documents in the context proves to be advantageous 5 raft generalizes to topk rag we now study another important problem how does the number of distractor documents in raft affect the models performance when augmented with topk rag results during evaluation previous research has highlighted the vulnerability of llms to irrelevant text see studies shi et al 2023a weston  sukhbaatar 2023 liu et al 2023 this issue is particularly critical for llms  rag since topk rag is frequently employed at test time to ensure high recall such a scenario necessitates the model to have the ability to discern and disregard irrelevant content focusing solely on pertinent information 51 making model robust to topk rag to tackle the challenge of enhancing large language models llms ability to sift through irrelevant text within the retrieval pipeline our analysis revealed that training solely with golden highly relevant documents can inadvertently diminish the models ability to dis cern and disregard irrelevant information to address this our algorithm raft  adopts a strategy that integrates golden documents with a mix of irrelevant ones this method ology prompts us to investigate the ideal fraction of distractor irrelevant documents to incorporate throughout the training process and to assess how well this training approach adapts to different volumes of documents encountered by the retrievalaugmented gen eration rag during the test phase our aim is to refine the balance between relevant and irrelevant information to strenghten the models efficiency in identifying and utilizing pertinent content notice that sec 44 looked what what p of training data should include distractors while in this section we study testtime scenarios training with distractor documents to enhance the robustness of llms against irrelevant text in retrieved documents we adopted a finetuning approach that incorporates both golden highly relevant documents and distractor irrelevant documents the model was trained with varying numbers of distractor documents but consistently evaluated using the top3 documents obtained from the retriever  not to be confused with p our findings detailed in fig 6 reveal that finetuning with only the golden document frequently results in inferior performance compared to configurations that include a greater number of distractor documents as we can see in the figure the better performance for natural questions is 8",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 3797,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "94961e37-a3e2-4580-8d21-56dd8f29eb98",
        "embedding": null,
        "metadata": {
            "page_label": "9",
            "file_name": "RAFT.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAFT.pdf",
            "file_type": "application/pdf",
            "file_size": 784351,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "c97c1d51-2b9a-4220-a9b8-19204665254b",
                "node_type": "4",
                "metadata": {
                    "page_label": "9",
                    "file_name": "RAFT.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAFT.pdf",
                    "file_type": "application/pdf",
                    "file_size": 784351,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "f00f6518e0bfa10ecffb4e5ccf59d95eda79f7215f17f80d72f411665ad591ff",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "d7bafda2-1f66-4a22-bdc4-3a13db06980a",
                "node_type": "1",
                "metadata": {},
                "hash": "df49cd4f0ad9341863cae0e7cddfa72ae54383a2f77879d24ce1162ec65f1969",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "preprint under review 2 4 6 8 10  t est documents t opk022024026028030032final accuracy natural questions train d train d  1d train d  2d train d  3d 2 4 6 8 10  t est documents t opk012501500175020002250250final accuracy hotpot qa train d train d  1d train d  2d train d  3d figure 6 testtime documents varying  to analyze how robust raft is to varying number of testtime documents we study three domains  nq trivia qa and hotpot qa in nq we find that training with 4 documents leads to optimal performance and this changes to 3 and 2 for for trivia qa and hotpot qa respectively however we see that training with only golden documents leads to poor performance training with d3dand it is d1ddocuments with hotpot qa this insight has been particularly beneficial for our algorithm raft  in our experiments we consistently employ a training setup consisting of one golden document alongside four distractor documents generalization to a variable number of testtime documents we extended our research to examine the impact of different quantities of testtime documents on the models per formance specifically our experiments focused on assessing how models trained with varying numbers of distractor documents respond to changes in the number of documents presented at test time the results illustrated in fig 6 confirm that the inclusion of distrac tor documents during training indeed makes the model more resilient to fluctuations in the number of documents encountered during testing this ability to maintain consistent perfor mance despite variations in testtime document numbers further validates the robustness of our approach raft  this finding underscores the importance of a wellcalibrated training environment to prepare the model for a range of scenarios it may encounter in realworld 6 related works retrievalaugmented language models retrievalaugmented language models ralms enhance llms by integrating a retrieval module that sources relevant information from external knowledge bases significantly improving performance across various nlp tasks including language modeling guu et al 2020 borgeaud et al 2022 khandelwal et al 2019 shi et al 2023d lin et al 2023b shi et al 2023c asai et al 2023 xu et al 2023 wang et al 2023 and opendomain question answering izacard et al 2023 lewis et al 2020 for instance atlas izacard et al 2023 finetunes t5 models with the retriever treating documents as latent variables while retro borgeaud et al 2022 modifies the decoderonly architecture to include retrieved texts and conducts pretraining from scratch knnlm khandelwal et al 2019 interpolates between the lms next token distribution and distributions computed from retrieved tokens at inference shi et al 2023d ram et al 2023 assume blackbox access to an llm combining it with either offtheshelf or finetuned retriever memorization a key question around large neural language models is whether they truly understand text feldman 2020 power et al 2022 or simply rely on surface pattern memorization carlini et al 2019 t\u00e4nzer et al 2022 feldman 2020 carlini et al 2019 2022 develop methodologies to quantify the extent of memorization in neural models brown et al 2020 power et al 2022 liu et",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 3198,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "d7bafda2-1f66-4a22-bdc4-3a13db06980a",
        "embedding": null,
        "metadata": {
            "page_label": "9",
            "file_name": "RAFT.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAFT.pdf",
            "file_type": "application/pdf",
            "file_size": 784351,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "c97c1d51-2b9a-4220-a9b8-19204665254b",
                "node_type": "4",
                "metadata": {
                    "page_label": "9",
                    "file_name": "RAFT.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAFT.pdf",
                    "file_type": "application/pdf",
                    "file_size": 784351,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "f00f6518e0bfa10ecffb4e5ccf59d95eda79f7215f17f80d72f411665ad591ff",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "94961e37-a3e2-4580-8d21-56dd8f29eb98",
                "node_type": "1",
                "metadata": {
                    "page_label": "9",
                    "file_name": "RAFT.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAFT.pdf",
                    "file_type": "application/pdf",
                    "file_size": 784351,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "eeda7d6cddda6cde94f4fd52186c8414aafdde4c4c5a2919062ee2e8e85101d2",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "et al 2022 feldman 2020 carlini et al 2019 2022 develop methodologies to quantify the extent of memorization in neural models brown et al 2020 power et al 2022 liu et al 2022 further explored how memorization impacts the models generalization capabilities carlini et al 2021 shi et al 2023b demonstrated the ability of language models to memorize and regurgitate training data raising significant privacy concerns kandpal et al 2022 pan et al 2020 finetuning for rag more recently several papers have been exploring the idea of fine tuning a pretrained llm to be better at rag tasks lin et al 2023a wang et al 2023 xu 9",
        "mimetype": "text/plain",
        "start_char_idx": 3032,
        "end_char_idx": 3651,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "9f7f543f-2e26-4490-b204-fd072509f27e",
        "embedding": null,
        "metadata": {
            "page_label": "10",
            "file_name": "RAFT.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAFT.pdf",
            "file_type": "application/pdf",
            "file_size": 784351,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "0799cab4-f911-4421-ab06-55ea3bb5110c",
                "node_type": "4",
                "metadata": {
                    "page_label": "10",
                    "file_name": "RAFT.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAFT.pdf",
                    "file_type": "application/pdf",
                    "file_size": 784351,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "5a0f49774b9d4a2a38a8d3efe83883aaace11ae582ffc0fd6ae48bef09a61fe0",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "5c642d61-ff92-43c5-987c-afd8b5235d30",
                "node_type": "1",
                "metadata": {},
                "hash": "d3d8fe39124cb594fbde616f61e51662c207f1f654b9c55d614a49186bfc8a1d",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "preprint under review et al 2023 liu et al 2024 these works focus on constructing a combination of finetuning dataset for rag and train a model to perform well on these tasks in particular in their settings at test time the domain or documents can be different than the training time whereas our paper studies a slightly opposite scenario where we only care about testing the llm on the same set of documents 7 conclusion raft is a training strategy designed to enhance the models performance in answering questions within a specific domain in openbook settings we highlight several crucial design decisions such as training the model alongside distractor documents organizing the dataset so a portion lacks golden documents in their context and formulating answers in a chainofthought manner with direct quotations from the relevant text our evaluations on pubmed hotpotqa and gorilla api bench underline rafts significant potential references anthropic prompt engineering for claudes long context window 2023 asai a wu z wang y sil a and hajishirzi h selfrag learning to retrieve generate and critique through selfreflection arxiv preprint arxiv231011511  2023 borgeaud s mensch a hoffmann j cai t rutherford e millican k van den driess che g b lespiau jb damoc b clark a et al improving language models by retrieving from trillions of tokens in international conference on machine learning  pp 22062240 pmlr 2022 brown t mann b ryder n subbiah m kaplan j d dhariwal p  neelakantan a shyam p  sastry g askell a et al language models are fewshot learners advances in neural information processing systems  3318771901 2020 carlini n liu c erlingsson \u00fa kos j and song d the secret sharer evaluating and testing unintended memorization in neural networks in 28th usenix security symposium usenix security 19  pp 267284 2019 carlini n tramer f wallace e jagielski m herbertvoss a lee k roberts a brown t song d erlingsson u et al extracting training data from large language models in 30th usenix security symposium usenix security 21  pp 26332650 2021 carlini n ippolito d jagielski m lee k tramer f and zhang c quantifying memorization across neural language models in the eleventh international conference on learning representations  2022 dernoncourt f and lee j y pubmed 200k rct a dataset for sequential sentence classification in medical abstracts arxiv preprint arxiv171006071  2017 feldman v  does learning require memorization a short tale about a long tail in proceedings of the 52nd annual acm sigact symposium on theory of computing  pp 954959 2020 guu k lee k tung z pasupat p  and chang m retrieval augmented language model pretraining in international conference on machine learning  pp 39293938 pmlr 2020 izacard g lewis p  lomeli m hosseini l petroni f schick t dwivediyu j joulin a riedel s and grave e atlas fewshot learning with retrieval augmented language models journal of machine learning research  24251143 2023 url http jmlrorgpapersv24230037html  jin q dhingra b",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 2987,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "5c642d61-ff92-43c5-987c-afd8b5235d30",
        "embedding": null,
        "metadata": {
            "page_label": "10",
            "file_name": "RAFT.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAFT.pdf",
            "file_type": "application/pdf",
            "file_size": 784351,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "0799cab4-f911-4421-ab06-55ea3bb5110c",
                "node_type": "4",
                "metadata": {
                    "page_label": "10",
                    "file_name": "RAFT.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAFT.pdf",
                    "file_type": "application/pdf",
                    "file_size": 784351,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "5a0f49774b9d4a2a38a8d3efe83883aaace11ae582ffc0fd6ae48bef09a61fe0",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "9f7f543f-2e26-4490-b204-fd072509f27e",
                "node_type": "1",
                "metadata": {
                    "page_label": "10",
                    "file_name": "RAFT.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAFT.pdf",
                    "file_type": "application/pdf",
                    "file_size": 784351,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "d115a0e47b3bec7c867746defca83bf0235da8dc493a35cbdb4dc00f85a93ad8",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "a riedel s and grave e atlas fewshot learning with retrieval augmented language models journal of machine learning research  24251143 2023 url http jmlrorgpapersv24230037html  jin q dhingra b liu z cohen w w and lu x pubmedqa a dataset for biomedical research question answering arxiv preprint arxiv190906146  2019 10",
        "mimetype": "text/plain",
        "start_char_idx": 2796,
        "end_char_idx": 3113,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "d73821ae-0f94-4028-9726-3052e08b80da",
        "embedding": null,
        "metadata": {
            "page_label": "11",
            "file_name": "RAFT.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAFT.pdf",
            "file_type": "application/pdf",
            "file_size": 784351,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "bfba83e8-a715-480b-a526-d04813d9ebd9",
                "node_type": "4",
                "metadata": {
                    "page_label": "11",
                    "file_name": "RAFT.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAFT.pdf",
                    "file_type": "application/pdf",
                    "file_size": 784351,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "ce26ddb7975be5efbc28bdaa85f509431a3cacf2db8cefc77b6d98242ccb7a07",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "5dbc12b6-c02c-4e27-8613-48834e83794d",
                "node_type": "1",
                "metadata": {},
                "hash": "7e892437bbe1fcbf2820e63f61e95b876e5be9d0611b670b29528748ea41393c",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "preprint under review joshi m choi e weld d s and zettlemoyer l triviaqa a large scale distantly supervised challenge dataset for reading comprehension arxiv preprint arxiv170503551  2017 kandpal n wallace e and raffel c deduplicating training data mitigates privacy risks in language models in international conference on machine learning  pp 1069710707 pmlr 2022 khandelwal u levy o jurafsky d zettlemoyer l and lewis m general ization through memorization nearest neighbor language models arxiv preprint arxiv191100172  2019 kwiatkowski t palomaki j redfield o collins m parikh a alberti c epstein d polosukhin i devlin j lee k et al natural questions a benchmark for question answering research transactions of the association for computational linguistics  7453466 2019 lazaridou a gribovskaya e stokowiec w and grigorev n internetaugmented language models through fewshot prompting for opendomain question answering arxiv preprint arxiv220305115  2022 lewis p  perez e piktus a petroni f karpukhin v  goyal n k\u00fcttler h lewis m yih wt rockt\u00e4schel t et al retrievalaugmented generation for knowledgeintensive nlp tasks advances in neural information processing systems  3394599474 2020 lin x v  chen x chen m shi w lomeli m james r rodriguez p  kahn j szilvasy g lewis m et al radit retrievalaugmented dual instruction tuning arxiv preprint arxiv231001352  2023a lin x v  chen x chen m shi w lomeli m james r rodriguez p  kahn j szilvasy g lewis m et al radit retrievalaugmented dual instruction tuning arxiv preprint arxiv231001352  2023b liu n f lin k hewitt j paranjape a bevilacqua m petroni f and liang p  lost in the middle how language models use long contexts arxiv preprint arxiv230703172  2023 liu z kitouni o nolte n s michaud e tegmark m and williams m towards understanding grokking an effective theory of representation learning advances in neural information processing systems  353465134663 2022 liu z ping w roy r xu p  shoeybi m and catanzaro b chatqa building gpt4 level conversational qa models arxiv preprint arxiv240110225  2024 pan x zhang m ji s and yang m privacy risks of generalpurpose language models in2020 ieee symposium on security and privacy sp  pp 13141331 ieee 2020 patil s g zhang t wang x and gonzalez j e gorilla large language model connected with massive apis arxiv preprint arxiv230515334  2023 power a burda y edwards h babuschkin i and misra v  grokking generalization beyond overfitting on small algorithmic datasets arxiv preprint arxiv220102177  2022 ram o levine y dalmedigos i muhlgay d shashua a leytonbrown k and",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 2566,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "5dbc12b6-c02c-4e27-8613-48834e83794d",
        "embedding": null,
        "metadata": {
            "page_label": "11",
            "file_name": "RAFT.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAFT.pdf",
            "file_type": "application/pdf",
            "file_size": 784351,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "bfba83e8-a715-480b-a526-d04813d9ebd9",
                "node_type": "4",
                "metadata": {
                    "page_label": "11",
                    "file_name": "RAFT.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAFT.pdf",
                    "file_type": "application/pdf",
                    "file_size": 784351,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "ce26ddb7975be5efbc28bdaa85f509431a3cacf2db8cefc77b6d98242ccb7a07",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "d73821ae-0f94-4028-9726-3052e08b80da",
                "node_type": "1",
                "metadata": {
                    "page_label": "11",
                    "file_name": "RAFT.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAFT.pdf",
                    "file_type": "application/pdf",
                    "file_size": 784351,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "30e791cb2c69809da335631a243643044b1741fd8efb13e120f51590c82731eb",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "grokking generalization beyond overfitting on small algorithmic datasets arxiv preprint arxiv220102177  2022 ram o levine y dalmedigos i muhlgay d shashua a leytonbrown k and shoham y incontext retrievalaugmented language models arxiv preprint arxiv230200083  2023 shi f chen x misra k scales n dohan d chi e h sch\u00e4rli n and zhou d large language models can be easily distracted by irrelevant context in international conference on machine learning  pp 3121031227 pmlr 2023a shi w ajith a xia m huang y liu d blevins t chen d and zettlemoyer l detecting pretraining data from large language models arxiv preprint arxiv231016789  2023b 11",
        "mimetype": "text/plain",
        "start_char_idx": 2392,
        "end_char_idx": 3029,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "0b327192-fd41-498d-83bc-18cd415654b5",
        "embedding": null,
        "metadata": {
            "page_label": "12",
            "file_name": "RAFT.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAFT.pdf",
            "file_type": "application/pdf",
            "file_size": 784351,
            "creation_date": "2024-07-29",
            "last_modified_date": "2024-07-08"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "a9724da0-44e5-4448-8b98-ebf124063adf",
                "node_type": "4",
                "metadata": {
                    "page_label": "12",
                    "file_name": "RAFT.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAFT.pdf",
                    "file_type": "application/pdf",
                    "file_size": 784351,
                    "creation_date": "2024-07-29",
                    "last_modified_date": "2024-07-08"
                },
                "hash": "cfa20dff6ddba769682d1d372d8b3ee56ae71d341b05cb9c0ee1b67361813b0c",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "preprint under review shi w min s lomeli m zhou c li m lin v  smith n a zettlemoyer l yih s and lewis m incontext pretraining language modeling beyond document boundaries arxiv preprint arxiv231010638  2023c shi w min s yasunaga m seo m james r lewis m zettlemoyer l and yih wt replug retrievalaugmented blackbox language models arxiv preprint arxiv230112652  2023d t\u00e4nzer m ruder s and rei m memorisation versus generalisation in pretrained lan guage models in proceedings of the 60th annual meeting of the association for computational linguistics volume 1 long papers  pp 75647578 2022 vu t iyyer m wang x constant n wei j wei j tar c sung yh zhou d le q et al freshllms refreshing large language models with search engine augmentation arxiv preprint arxiv231003214  2023 wang b ping w mcafee l xu p  li b shoeybi m and catanzaro b instructretro instruction tuning post retrievalaugmented pretraining arxiv preprint arxiv231007713  2023 wang y kordi y mishra s liu a smith n a khashabi d and hajishirzi h selfinstruct aligning language models with selfgenerated instructions arxiv preprint arxiv221210560  2022 wei j wang x schuurmans d bosma m xia f chi e le q v  zhou d et al chainofthought prompting elicits reasoning in large language models advances in neural information processing systems  352482424837 2022 weston j and sukhbaatar s system 2 attention is something you might need too arxiv preprint arxiv231111829  2023 xiong w liu j molybog i zhang h bhargava p  hou r martin l rungta r sankararaman k a oguz b et al effective longcontext scaling of foundation models arxiv preprint arxiv230916039  2023 xu p  ping w wu x mcafee l zhu c liu z subramanian s bakhturina e shoeybi m and catanzaro b retrieval meets long context large language models arxiv preprint arxiv231003025  2023 yang z qi p  zhang s bengio y cohen w w salakhutdinov r and manning c d hotpotqa a dataset for diverse explainable multihop question answering arxiv preprint arxiv180909600  2018 zhou c liu p  xu p  iyer s sun j mao y ma x efrat a yu p  yu l et al lima less is more for alignment arxiv preprint arxiv230511206  2023 12",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 2113,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "2e252f77-277f-4b61-873b-c90936403e89",
        "embedding": null,
        "metadata": {
            "page_label": "1",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "c86007a4-215e-41ed-9a4e-8bdbc7bc6d3a",
                "node_type": "4",
                "metadata": {
                    "page_label": "1",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "e9d2aa8300d2680225d954936a6236d46bc8f7902c8c3be6692fe9b528a54f43",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "searching for best practices in retrievalaugmented generation xiaohua wang zhenghua wang xuan gao feiran zhang yixin wu zhibo xu tianyuan shi zhengyuan wang shizheng li  qi qian ruicheng yin changze lv xiaoqing zhengxuanjing huang school of computer science fudan university shanghai china shanghai key laboratory of intelligent information processing xiaohuawang22zhenghuawang23 mfudaneducn zhengxqxjhuang fudaneducn abstract retrievalaugmented generation rag techniques have proven to be effective in integrating uptodate information mitigating hallucinations and enhancing response quality particularly in specialized domains while many rag approaches have been proposed to enhance large language models through querydependent retrievals these approaches still suffer from their complex implementation and prolonged response times typically a rag workflow involves multiple processing steps each of which can be executed in various ways here we investigate existing rag approaches and their potential combinations to identify optimal rag practices through extensive experiments we suggest several strategies for deploying rag that balance both performance and efficiency moreover we demonstrate that multimodal retrieval techniques can significantly enhance questionanswering capabilities about visual inputs and accelerate the generation of multimodal content using a retrieval as generation strategy resources are available at httpsgithubcomfudandnnnlprag  1 introduction generative large language models are prone to producing outdated information or fabricating facts although they were aligned with human preferences by reinforcement learning  1 or lightweight alternatives  25 retrievalaugmented generation rag techniques address these issues by com bining the strengths of pretraining and retrievalbased models thereby providing a robust framework for enhancing model performance  6 furthermore rag enables rapid deployment of applications for specific organizations and domains without necessitating updates to the model parameters as long as queryrelated documents are provided many rag approaches have been proposed to enhance large language models llms through querydependent retrievals  68 a typical rag workflow usually contains multiple intervening processing steps query classification determining whether retrieval is necessary for a given input query retrieval efficiently obtaining relevant documents for the query reranking refining the order of retrieved documents based on their relevance to the query repacking organizing the retrieved documents into a structured one for better generation summarization extracting key information for response generation from the repacked document and eliminating redundancies modules implementing rag also requires decisions on the ways to properly split documents into chunks the types of embeddings to use for semantically representing these chunks the choice of corresponding author preprint under reviewarxiv240701219v1 cscl 1 jul 2024",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 2999,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "8f6e8982-c430-41ae-9e55-8212ca0329d0",
        "embedding": null,
        "metadata": {
            "page_label": "2",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "a6eb1f01-84a6-44ba-8d29-128b67d7fd73",
                "node_type": "4",
                "metadata": {
                    "page_label": "2",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "123460db1b8bcf647937fdaf8387fd53c29248d5f9254df2497a431e26646dd8",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "large language model query classification reranking dlm based monot5 monobert rankllama tilde     retrieval original query bm25 contriever llm embedder query rewriting query decomposition hyde hybrid search hydehybrid search         summarization extractive recomp bm25 contriever abstractive longllmlingua selectivecontext recomp        vector database milvus faiss weaviate qdrant chroma     chunking chunking size small2big sliding windows chunk metadata    embedding llm embedder intfloate5 baaibge jinaembeddings v2 gte allmpnet base v2      repacking sides forward reverse   evaluation general performance specific domains retrieval capability   fine tune disturb random normal   retrieval sourcefigure 1 retrievalaugmented generation workflow this study investigates the contribution of each component and provides insights into optimal rag practices through extensive experimentation the optional methods considered for each component are indicated in bold fonts while the methods underlined indicate the default choice for individual modules the methods indicated in blue font denote the bestperforming selections identified empirically vector databases to efficiently store feature representations and the methods for effectively finetuning llms see figure 1 what adds complexity and challenge is the variability in implementing each processing step for example in retrieving relevant documents for an input query various methods can be employed one approach involves rewriting the query first and using the rewritten queries for retrieval  9 alternatively pseudoresponses to the query can be generated first and the similarity between these pseudoresponses and the backend documents can be compared for retrieval  10 another option is to directly employ embedding models typically trained in a contrastive manner using positive and negative queryresponse pairs  1112 the techniques chosen for each step and their combinations significantly impact both the effectiveness and efficiency of rag systems to the best of our knowledge there has been no systematic effort to pursue the optimal implementation of rag particularly for the entire rag workflow in this study we aim to identify the best practices for rag through extensive experimentation given the infeasibility of testing all possible combinations of these methods we adopt a threestep approach to identify optimal rag practices first we compare representative methods for each rag step or module and select up to three of the bestperforming methods next we evaluate the impact of each method on the overall rag performance by testing one method at a time for an individual step while keeping the other rag modules unchanged this allows us to determine the most effective method for each step based on its contribution and interaction with other modules during response generation once the best method is chosen for a module it is used in subsequent experiments finally we empirically explore a few promising combinations suitable for different application scenarios where efficiency might be prioritized over performance or vice versa based on these findings we suggest several strategies for deploying rag that balance both performance and efficiency the contributions of this study are threefold through extensive experimentation we thoroughly investigated existing rag approaches and their combinations to identify and recommend optimal rag practices 2",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 3424,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "6cc8d2a0-b79e-4fc3-aa88-7df5c89f2e84",
        "embedding": null,
        "metadata": {
            "page_label": "3",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "03c4e1fd-c7d6-4e6d-ba95-4afaca28b045",
                "node_type": "4",
                "metadata": {
                    "page_label": "3",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "485a98fe85948a153d1ae2cb5e9997caf74ae0c0a9643edd9779e3306cfce2c6",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "we introduce a comprehensive framework of evaluation metrics and corresponding datasets to comprehensively assess the performance of retrievalaugmented generation models covering general specialized or domainspecific and ragrelated capabilities we demonstrate that the integration of multimodal retrieval techniques can substantially improve questionanswering capabilities on visual inputs and speed up the generation of multimodal content through a strategy of retrieval as generation 2 related work ensuring the accuracy of responses generated by large language models llms such as chat gpt  13 and llama  14 is essential however simply enlarging model size does not fundamentally address the issue of hallucinations 15 16 especially in knowledgeintensive tasks and specialized domains retrievalaugmented generation rag addresses these challenges by retrieving relevant documents from external knowledge bases providing accurate realtime domainspecific context to llms  6 previous works have optimized the rag pipeline through query and retrieval transfor mations enhancing retriever performance and finetuning both the retriever and generator these optimizations improve the interaction between input queries retrieval mechanisms and generation processes ensuring the accuracy and relevance of responses 21 query and retrieval transformation effective retrieval requires queries accurate clear and detailed even when converted into embed dings semantic differences between queries and relevant documents can persist previous works have explored methods to enhance query information through query transformation thereby improving retrieval performance for instance query2doc  17 and hyde  10 generate pseudodocuments from original queries to enhance retrieval while toc  18 decomposes queries into subqueries aggregating the retrieved content for final results other studies have focused on transforming retrieval source documents llamaindex  19 provides an interface to generate pseudoqueries for retrieval documents improving matching with real queries some works employ contrastive learning to bring query and document embeddings closer in semantic space  122021 postprocessing retrieved documents is another method to enhance generator output with techniques like hierarchical prompt summarization  22 and using abstractive and extractive compressors 23 to reduce context length and remove redundancy 24 22 retriever enhancement strategy document chunking and embedding methods significantly impact retrieval performance common chunking strategies divide documents into chunks but determining optimal chunk length can be challenging small chunks may fragment sentences while large chunks might include irrelevant context llamaindex  19 optimizes the chunking method like small2big and sliding window retrieved chunks can be irrelevant and numbers can be large so reranking is necessary to filter irrelevant documents a common reranking approach employs deep language models such as bert  25 t5  26 or llama  27 which requires slow inference steps during reranking but grants better performance tilde  2829 achieves efficiency by precomputing and storing the likelihood of query terms ranking documents based on their sum 23 retriever and generator finetuning finetuning within the rag framework is crucial for optimizing both retrievers and generators some research focuses on finetuning the generator to better utilize retriever context  3032 ensuring faithful and robust generated content others finetune the retriever to learn to retrieve beneficial passages for the generator  3335 holistic approaches treat rag as an integrated system finetuning both retriever and generator together to enhance overall performance  3638 despite increased complexity and integration challenges several surveys have extensively discussed current rag systems covering aspects like text genera tion  78 integration with llms  639 multimodal  40 and aigenerated content  41 while these surveys provide comprehensive overviews of existing rag methodologies selecting the appro 3",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 4067,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "b0ad4e6b-af6b-45ee-b4d8-8f089a8b627c",
        "embedding": null,
        "metadata": {
            "page_label": "4",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "a35538e2-924a-4d83-b288-8b64b77a5d97",
                "node_type": "4",
                "metadata": {
                    "page_label": "4",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "6103d1f9c0e84ec38b4eea83aaadd037079466856ef7aca3fc44deca15e449f6",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "02391d78-2e27-4b9a-8270-3e160881b804",
                "node_type": "1",
                "metadata": {},
                "hash": "3db9f65eeecec718684c5316f09623759ffb187821f795e59a07c2db980067e8",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "which city will the next world cup be held  search  frenchwashington played a crucial role in the american revolutionary war leading the continental army against the british  please continue writing the above paragraph  continuation writing  background knowledge to be or not to be that is the question please translate this sentence into french  translation  insufficient informationsufficient information please give me a plan for holding a graduation party  planning  if youre currently a computer science student and your computer system encounters a malfunction what should you do  role play  write an article about the geography of europe focusing on the changes in rainfall in the western part of the country  writing  no retrieval needed need to retrieval please find a novel that is as famous as one hundred years of solitude  search dave is attending his aunts brother funeral today  paraphrase the given information effectively  rewriting the renaissance was a cultural transformation in european history marking the revival of arts sciences and humanistic thought the fervor of artists and scholars propelled prosperity and innovation in arts literature and science  give me a summary  summarization  identify who is football players messi jordan kobe  closed qa tom has three sisters and each sister has a brother how many siblings are there in total  reasonning  q 31 a 3 q 25 a 5 q 57 a   incontext learning  chatgpt is a product of openai  please provide the ownership relationship  information extraction  no background knowledgeif i want to travel from los angeles to new york and i want to choose the cheapest mode of transportation should i drive or take a plane  decision making  i had a quarrel with my parents because they oppose my relationship with my boyfriend but we genuinely love each other how should i persuade my parents to accept our relationship  suggestion figure 2 classification of retrieval requirements for different tasks in cases where information is not provided we differentiate tasks based on the functions of the model priate algorithm for practical implementation remains challenging in this paper we focus on best practices for applying rag methods advancing the understanding and application of rag in llms 3 rag workflow in this section we detail the components of the rag workflow for each module we review commonly used approaches and select the default and alternative methods for our final pipeline section 4 will discuss best practices figure 1 presents the workflow and methods for each module detailed experimental setups including datasets hyperparameters and results are provided in appendix a 31 query classification not all queries require retrievalaugmented due to the inherent capabilities of llms while rag can enhance information accuracy and reduce hallucinations frequent retrieval can increase response time therefore we begin by classifying queries to determine the necessity of retrieval queries requiring retrieval proceed through the rag modules others are handled directly by llms retrieval is generally recommended when knowledge beyond the models parameters is needed however the necessity of retrieval varies by task for instance an llm trained up to 2023 can handle a translation request for  sora was developed by openai  without retrieval conversely an introduction request for the same topic would require retrieval to provide relevant information therefore we propose classifying tasks by type to determine if a query needs retrieval we categorize modelmetrics acc prec rec f1 bertbasemultilingual 095 096 094 095 table 1 results of the query classifier15 tasks based on whether they provide suffi cient information with specific tasks and exam ples illustrated in figure 2 for tasks entirely based on usergiven information we denote as sufficient  which need not retrieval otherwise we denote as insufficient  and retrieval may be necessary we train a",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 3932,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "02391d78-2e27-4b9a-8270-3e160881b804",
        "embedding": null,
        "metadata": {
            "page_label": "4",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "a35538e2-924a-4d83-b288-8b64b77a5d97",
                "node_type": "4",
                "metadata": {
                    "page_label": "4",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "6103d1f9c0e84ec38b4eea83aaadd037079466856ef7aca3fc44deca15e449f6",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "b0ad4e6b-af6b-45ee-b4d8-8f089a8b627c",
                "node_type": "1",
                "metadata": {
                    "page_label": "4",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "436f65aa3acb7d95e4c5f3229591dc8e7aaa38082f014c643dd66a2905176502",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "whether they provide suffi cient information with specific tasks and exam ples illustrated in figure 2 for tasks entirely based on usergiven information we denote as sufficient  which need not retrieval otherwise we denote as insufficient  and retrieval may be necessary we train a classifier to automate this decisionmaking process experimental de tails are presented in appendix a1 section 4 explores the impact of query classification on the workflow comparing scenarios with and without classification 4",
        "mimetype": "text/plain",
        "start_char_idx": 3651,
        "end_char_idx": 4158,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "73099a08-6da0-476d-9fbb-6621f646cf61",
        "embedding": null,
        "metadata": {
            "page_label": "5",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "939fd250-77ee-46a7-955d-77c373d7b05f",
                "node_type": "4",
                "metadata": {
                    "page_label": "5",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "d1c047d183228545b5dd770a61e46c08a897d40a9b93e1c517fbe765ee843548",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "9895315d-ba5d-449c-a9cf-7526d6c44ce8",
                "node_type": "1",
                "metadata": {},
                "hash": "f3f05109745173c94c6d6ed49a30031195907cbb410c77941ebfdd124c74dd40",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "embedding modelnamespaceptmsmarco mrr1 mrr10 mrr100 r1 r10 r100 baaillmembedder 20 2479 3758 3862 24076645 90 75 baaibgebaseenv15 12 2334 35 80 36 94 22 63 64 12 90 13 baaibgesmallenv15 12 2327 35 78 36 89 22 65 63 92 89 80 baaibgelargeenv15 12 2463 37 48 38 59 23 91 65 57 90 60 baaibgelargeen 12 2484 37 66 38 73 24 13 6609 90 64 baaibgesmallen 12 2328 35 79 36 91 22 62 63 96 89 67 baaibgebaseen 12 2347 35 94 37 07 22 73 64 17 90 14 alibabanlpgtelargeenv15 21 893 15 60 16 71 8 67 32 28 60 36 thenlpergtebase 21 742 13 23 14 30 7 21 28 27 56 20 thenlpergtesmall 21 797 14 81 15 95 7 71 32 07 61 08 jinaaijinaembeddingsv2smallen 42 807 15 02 16 12 7 87 32 55 60 36 intfloate5smallv2 11 1004 18 23 19 41 9 74 38 92 68 42 intfloate5largev2 11 958 17 94 19 03 9 35 39 00 66 11 sentencetransformersallmpnetbasev2 580 11 26 12 26 5 66 25 57 50 94 table 2 results for different embedding models on namespaceptmsmarco 32 chunking chunking documents into smaller segments is crucial for enhancing retrieval precision and avoiding length issues in llms this process can be applied at various levels of granularity such as token sentence and semantic levels tokenlevel chunking is straightforward but may split sentences affecting retrieval quality semanticlevel chunking uses llms to determine breakpoints contextpreserving but time consuming sentencelevel chunking balances preserving text semantics with simplicity and efficiency in this study we use sentencelevel chunking  balancing simplicity and semantic preservation we examine chunking from four dimensions 321 chunk size chunk size significantly impacts performance larger chunks provide more context enhancing comprehension but increasing process time smaller chunks improve retrieval recall and reduce time but may lack sufficient context finding the optimal chunk size involves a balance between some metrics such as faithfulness and relevancy faithfulness measures whether the response is hallucinated or matches the retrieved texts chunk sizelyft_2021 average faithfulnessaverage relevancy 2048 80 37 91 11 1024 94 26 95 56 512 9759 9741 256 97 22 9778 128 95 74 97 22 table 3",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 2134,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "9895315d-ba5d-449c-a9cf-7526d6c44ce8",
        "embedding": null,
        "metadata": {
            "page_label": "5",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "939fd250-77ee-46a7-955d-77c373d7b05f",
                "node_type": "4",
                "metadata": {
                    "page_label": "5",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "d1c047d183228545b5dd770a61e46c08a897d40a9b93e1c517fbe765ee843548",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "73099a08-6da0-476d-9fbb-6621f646cf61",
                "node_type": "1",
                "metadata": {
                    "page_label": "5",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "4a5f4c1112dba8d764743649e72cf33c115180b6d4c122c17746ba2c36ec547a",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "80 37 91 11 1024 94 26 95 56 512 9759 9741 256 97 22 9778 128 95 74 97 22 table 3 comparison of different chunk sizesrelevancy measures whether the retrieved texts and responses match queries we use the evaluation module of llamaindex  43 to cal culate the metrics above for embedding we use the textembeddingada0022model which supports long input length we choose zephyr7balpha3and gpt35turbo4as generation model and evaluation model respec tively the size of the chunk overlap is 20 tokens first sixty pages of the document lyft_20215 are used as corpus then prompting llms to generate about one hundred and seventy queries according to chosen corpus the impact of different chunk sizes is shown in table 3 2httpsplatformopenaicomdocsguidesembeddingsembeddingmodels 3httpshuggingfacecohuggingfaceh4zephyr7balpha 4httpswwwopenaicom 5httpsrawgithubusercontentcomrunllamallama_indexmaindocsdocsexamples data10klyft_2021pdf 5",
        "mimetype": "text/plain",
        "start_char_idx": 2053,
        "end_char_idx": 2976,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "58f5f196-e1e3-4341-bc73-3023adf5da14",
        "embedding": null,
        "metadata": {
            "page_label": "6",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "82d52bd7-bc93-46c3-b6c8-7fc0119867cb",
                "node_type": "4",
                "metadata": {
                    "page_label": "6",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "94d9e67d798f0d6277f47d8f5948f75138325632b4e6d9280a18b53e1374fa14",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "322 chunking techniques advanced techniques such as smalltobig and sliding window improve retrieval quality by organizing chunk block relationships smallsized blocks are used to match queries and larger blocks that include the small ones along with contextual information are returned to demonstrate the effectiveness of advanced chunking techniques we use the llmembedder  20 model as an embedding model the smaller chunk size is 175tokens the larger chunk size is 512 tokens and the chunk overlap is 20tokens techniques like smalltobig and sliding window improve retrieval quality by maintaining context and ensuring relevant information is retrieved detailed results are shown in table 4 323 embedding model selection choosing the right embedding model is crucial for effective semantic matching of queries and chunk blocks we use the evaluation module of flagembedding6which uses the dataset chunk skilllyft_2021 average faithfulnessaverage relevancy original 9574 95 37 small2big 9667 95 37 sliding window 9741 96 85 table 4 comparison of different chunk skillsnamespaceptmsmarco7as queries and dataset namespaceptmsmarcocorpus8as corpus to choose the appropriate open source embedding model as shown in table 2 llmembedder  20 achieves comparable results with baaibgelargeen  12 however the size of the former is three times smaller than that of the latter thus we select the llmembedder 20 for its balance of performance and size 324 metadata addition enhancing chunk blocks with metadata like titles keywords and hypothetical questions can improve retrieval provide more ways to postprocess retrieved texts and help llms better understand retrieved information a detailed study on metadata inclusion will be addressed in future work 33 vector databases vector databases store embedding vectors with their metadata enabling efficient retrieval of doc uments relevant to queries through various indexing and approximate nearest neighbor ann methods to select an appropriate vector database for our research we evaluated several options based on four key criteria multiple index types billionscale vector support hybrid search and cloudnative databasemultiple index typebillion scalehybrid searchcloud native weaviate     faiss     chroma     qdrant     milvus     table 5 comparison of various vector databasescapabilities these criteria were chosen for their impact on flexibility scalability and ease of deployment in modern cloudbased infrastruc tures multiple index types provide the flexibil ity to optimize searches based on different data characteristics and use cases billionscale vec tor support is crucial for handling large datasets in llm applications hybrid search combines vector search with traditional keyword search enhancing retrieval accuracy finally cloud native capabilities ensure seamless integration scalability and management in cloud environments table 5 presents a detailed comparison of five opensource vector databases weaviate faiss  chroma qdrant  and milvus  our evaluation indicates that milvus stands out as the most comprehensive solution among the databases evaluated meeting all the essential criteria and outperforming other opensource options 6httpsgithubcomflagopenflagembedding 7httpshuggingfacecodatasetsnamespaceptmsmarco 8httpshuggingfacecodatasetsnamespaceptmsmarcocorpus 6",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 3324,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "31d145e1-9594-4a1f-bec9-1ee240377c60",
        "embedding": null,
        "metadata": {
            "page_label": "7",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "7b35e19c-a7ab-4e55-adbc-bf95ea8ab0f4",
                "node_type": "4",
                "metadata": {
                    "page_label": "7",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "794b048ebd38d5f03adc6ea74ee9288a5d7d413a5f52a68b2cdd7bba0c431d8d",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "b79c46d5-9538-47f7-8925-657040eaf3d9",
                "node_type": "1",
                "metadata": {},
                "hash": "5b849a6be2c823fe4b9ef509698cd4e1690c973dab84b355088b9329f2169c08",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "methodtrec dl19 trec dl20 map ndcg10 r50 r1k latency map ndcg10 r50 r1k latency unsupervised bm25 3013 50 58 38 32 75 01 007 2856 47 96 46 18 78 63 029 contriever 2399 44 54 37 54 74 59 3 06 23 98 42 13 43 81 75 39 0 98 supervised llmembedder 4466 70 20 49 06 84 48 2 61 4560 68 76 61 36 84 41 0 71  query rewriting 4456 67 89 51 45 85 35 7 80 45 16 65 62 59 63 83 45 2 06  query decomposition 4193 66 10 48 66 82 62 14 98 43 30 64 95 57 74 84 18 2 01  hyde 5087 7544 5493 8876 7 21 50 94 7394 6380 88 03 2 14  hybrid search 4714 72 50 51 13 89 08 320 47 72 69 80 64 32 8804 077  hyde  hybrid search 5213 7334 5538 90 42 11165313 7272 6614 90 67 295 table 6 results for different retrieval methods on trec dl1920 the best result for each method is made bold and the second is underlined configurationtrec dl19 trec dl20 map ndcg10 r50 r1k latency map ndcg10 r50 r1k latency hyde w 1 pseudodoc 4877 72 49 53 20 87 73 8 08 51 31 70 37 63 28 87 81 209 w 1 pseudodoc  query 5087 7544 54 93 8876 721 5094 7394 6380 88 03 2 14 w 8 pseudodoc  query 5164 7512 54 518917 14155314 7365 6579 88 67 344 table 7 hyde with different concatenation of hypothetical documents and queries 34 retrieval methods given a user query the retrieval module selects the top krelevant documents from a prebuilt corpus based on the similarity between the query and the documents the generation model then uses these documents to formulate an appropriate response to the query however original queries often underperform due to poor expression and lack of semantic information  6 negatively impacting the retrieval process to address these issues we evaluated three query transformation methods using the llmembedder recommended in section 32 as the query and document encoder query rewriting  query rewriting refines queries to better match relevant documents inspired by the rewriteretrieveread framework  9 we prompt an llm to rewrite queries to enhance performance query decomposition  this approach involves retrieving documents based on subquestions derived from the original query which is more complex to comprehend and handle pseudodocuments generation  this approach generates a hypothetical document based",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 2187,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "b79c46d5-9538-47f7-8925-657040eaf3d9",
        "embedding": null,
        "metadata": {
            "page_label": "7",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "7b35e19c-a7ab-4e55-adbc-bf95ea8ab0f4",
                "node_type": "4",
                "metadata": {
                    "page_label": "7",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "794b048ebd38d5f03adc6ea74ee9288a5d7d413a5f52a68b2cdd7bba0c431d8d",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "31d145e1-9594-4a1f-bec9-1ee240377c60",
                "node_type": "1",
                "metadata": {
                    "page_label": "7",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "fa08141cbe3072a79f5222c1b5a28fc90298ad8e18b6cc542c9460c264389ab7",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "we prompt an llm to rewrite queries to enhance performance query decomposition  this approach involves retrieving documents based on subquestions derived from the original query which is more complex to comprehend and handle pseudodocuments generation  this approach generates a hypothetical document based on the user query and uses the embedding of hypothetical answers to retrieve similar documents one notable implement is hyde 10 recent studies such as  44 indicate that combining lexicalbased search with vector search signifi cantly enhances performance in this study we use bm25 for sparse retrieval and contriever  45 an unsupervised contrastive encoder for dense retrieval serving as two robust baselines based on thakur et al 46 341 results for different retrieval methods we evaluated the performance of different search methods on the trec dl 2019 and 2020 passage ranking datasets the results presented in table 6 show that supervised methods significantly outperformed unsupervised methods combining with hyde and hybrid search llmembedder achieves the highest scores however query rewriting and query decomposition did not enhance retrieval performance as effectively considering the best performance and tolerated latency we recommend hybrid search with hyde as the default retrieval method taking efficiency into consideration hybrid search combines sparse retrieval bm25 and dense retrieval original embedding and achieves notable performance with relatively low latency 342 hyde with different concatenation of documents and query table 7 shows the impact of different concatenation strategies for hypothetical documents and queries using hyde concatenating multiple pseudodocuments with the original query can significantly 7",
        "mimetype": "text/plain",
        "start_char_idx": 1881,
        "end_char_idx": 3627,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "311005de-975e-45ea-94ab-abf0cac50c5a",
        "embedding": null,
        "metadata": {
            "page_label": "8",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "852deb57-7619-45a9-bf82-8865257879db",
                "node_type": "4",
                "metadata": {
                    "page_label": "8",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "b1429f9fd4170a2a256366fd57f429da56c2309d01228c8f3ba05ab965575913",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "81fd2c7c-84ab-490a-95eb-d15933db9940",
                "node_type": "1",
                "metadata": {},
                "hash": "67291004b8637dc5fdb92229988fe7ef797ef959e2b8ba6a9f72c1f7f27ce024",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "hyperparametertrec dl19 trec dl20 map ndcg10 r50 r1k latency map ndcg10 r50 r1k latency hybrid search \u03b1 01 4600 7087 49 24 88 89 2 98 46 54 69 05 63 36 87 32 0 90 \u03b1 03 4714 7250 5113 8908 320 4772 69 80 6432 8804 0 77 \u03b1 05 4736 7224 5271 8809 3 02 47 19 68 12 6490 8786 0 87 \u03b1 07 4721 71 89 52 40 88 01 3 15 45 82 67 30 64 23 87 92 1 02 \u03b1 09 4635 70 67 52 64 88 22 274 4402 65 55 63 22 87 76 1 20 table 8 results of hybrid search with different alpha values methodms marco passage ranking base model  params mrr1 mrr10 mrr1k hit rate10 latency wo reranking random ordering   0011 0 027 0 068 0 092  bm25   652 11 65 12 59 24 63  dlm reranking monot5 t5base 220m 2162 31 78 32 40 54 07 45 monobert bertlarge 340m 2165 31 69 32 35 53 38 15 8 rankllama llama27b 7b 2208 32 35 32 97 54 53 824 tilde reranking tildev2 bertbase 110m 1857 27 83 28 60 49 07 002 table 9 results of different reranking methods on the dev set of the ms marco passage ranking dataset for each query the top1000 candidate passages retrieved by bm25 are reranked latency is measured in seconds per query enhance retrieval performance though at the cost of increased latency suggesting a tradeoff between retrieval effectiveness and efficiency however indiscriminately increasing the number of hypothetical documents does not yield significant benefits and substantially raises latency indicating that using a single hypothetical document is sufficient 343 hybrid search with different weight on sparse retrieval table 8 presents the impact of different \u03b1values in hybrid search where \u03b1controls the weighting between sparse retrieval and dense retrieval components the relevance score is calculated as follows sh\u03b1sssd 1 where sssdare the normalized relevance scores from sparse retrieval and dense retrieval respectively andshis the total retrieval score we evaluated five different \u03b1values to determine their influence on performance the results indicate that an \u03b1value of 03 yields the best performance demonstrating that appropriate adjustment of \u03b1can enhance retrieval effectiveness to a certain extent therefore we selected \u03b1 03for our retrieval and main experiments additional implementation details are presented in appendix a2 35 reranking methods after the initial retrieval a reranking phase is employed to enhance the relevance of the retrieved documents ensuring that the most pertinent information appears at the top of the list this phase uses more precise and timeintensive methods to reorder documents effectively increasing the similarity between the query and the topranked documents we consider two approaches in our reranking module",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 2621,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "81fd2c7c-84ab-490a-95eb-d15933db9940",
        "embedding": null,
        "metadata": {
            "page_label": "8",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "852deb57-7619-45a9-bf82-8865257879db",
                "node_type": "4",
                "metadata": {
                    "page_label": "8",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "b1429f9fd4170a2a256366fd57f429da56c2309d01228c8f3ba05ab965575913",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "311005de-975e-45ea-94ab-abf0cac50c5a",
                "node_type": "1",
                "metadata": {
                    "page_label": "8",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "d9a20f789ecb547aa9dd57e60c866b4a3d2284a057acf2a716124d55d01531f9",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "retrieved documents ensuring that the most pertinent information appears at the top of the list this phase uses more precise and timeintensive methods to reorder documents effectively increasing the similarity between the query and the topranked documents we consider two approaches in our reranking module dlm reranking  which utilizes classifi cation and tilde reranking  which focuses on query likelihoods these approaches prioritize performance and efficiency respectively dlm reranking this method leverages deep language models dlms  2527 for reranking these models are finetuned to classify document relevancy to a query as true or false during finetuning the model is trained with concatenated query and document inputs labeled by relevancy at inference documents are ranked based on the probability of the true token tilde reranking tilde  2829 calculates the likelihood of each query term independently by predicting token probabilities across the models vocabulary documents are scored by summing 8",
        "mimetype": "text/plain",
        "start_char_idx": 2315,
        "end_char_idx": 3324,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "eb30eca4-a16a-4450-b643-3becd3deedb6",
        "embedding": null,
        "metadata": {
            "page_label": "9",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "6d5fc2c4-917d-481f-9fc8-70e5c582b257",
                "node_type": "4",
                "metadata": {
                    "page_label": "9",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "05db2f43587007383ffd0a6c31dfbde610e1e8d7efaff35afa8da5e3c87903c6",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "92c4e732-312e-48c0-afd0-68145694a067",
                "node_type": "1",
                "metadata": {},
                "hash": "1ae60da31f37d997fe5d2ae5bb8014531ae4adb73da97b8c2e616a49ec998584",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "methodnq tqa hotpotqaavg avg token f1 token f1 token f1 token wo summarization origin prompt 2707 124 33 61 152 33 92 141 31 53 139 extractive method bm25 2797 40 32 44 59 28 00 63 29 47 54 contriever 2362 42 33 79 65 23 64 60 27 02 56 recomp extractive 2784 34 35 32 60 29 46 58 30 87 51 abstractive method selectivecontext 2505 65 34 25 70 3443 66 31 24 67 longllmlingua 2132 51 32 81 56 30 79 57 28 29 55 recomp abstractive 3368 59 3587 61 29 01 57 3285 59 table 10 comparison between different summarization methods the precalculated log probabilities of query tokens allowing for rapid reranking at inference tildev2 improves this by indexing only documentpresent tokens using nce loss and expanding documents thus enhancing efficiency and reducing index size our experiments were conducted on the ms marco passage ranking dataset  47 a largescale dataset for machine reading comprehension we follow and make modifications to the implementation provided by pygaggle  26 and tilde  28 using the models monot5 monobert rankllama and tildev2 reranking results are shown in table 9 we recommend monot5 as a comprehensive method balancing performance and efficiency rankllama is suitable for achieving the best performance while tildev2 is ideal for the quickest experience on a fixed collection details on the experimental setup and results are presented in appendix a3 36 document repacking the performance of subsequent processes such as llm response generation may be affected by the order documents are provided to address this issue we incorporate a compact repacking module into the workflow after reranking featuring three repacking methods forward reverse andsides  the forward method repacks documents by descending relevancy scores from the reranking phase whereas the reverse arranges them in ascending order inspired by liu et al 48 concluding that optimal performance is achieved when relevant information is placed at the head or tail of the input we also include a sides option since the repacking method primarily affects subsequent modules we select the best repacking method in section 4 by testing it in combination with other modules in this section we choose the sides method as the default repacking method 37 summarization retrieval results may contain redundant or unnecessary information potentially preventing llms from generating accurate responses additionally long prompts can slow down the inference process therefore efficient methods to summarize retrieved documents are crucial in the rag pipeline summarization tasks can be extractive orabstractive  extractive methods segment text into sen tences then score and rank them based on importance abstractive compressors synthesize infor mation from multiple documents to rephrase and generate a cohesive summary these tasks can be querybased or nonquerybased in this paper as rag retrieves information relevant to queries we focus exclusively on querybased methods recomp recomp  23 has extractive and abstractive compressors the extractive compressor selects useful sentences while the abstractive compressor synthesizes information from multiple documents longllmlingua longllmlingua  49 improves llmlingua by focusing",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 3202,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "92c4e732-312e-48c0-afd0-68145694a067",
        "embedding": null,
        "metadata": {
            "page_label": "9",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "6d5fc2c4-917d-481f-9fc8-70e5c582b257",
                "node_type": "4",
                "metadata": {
                    "page_label": "9",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "05db2f43587007383ffd0a6c31dfbde610e1e8d7efaff35afa8da5e3c87903c6",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "eb30eca4-a16a-4450-b643-3becd3deedb6",
                "node_type": "1",
                "metadata": {
                    "page_label": "9",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "edb6dda6bb4bde7c39b60e4c0460866978ccad7b3b2e556fc8e7d6d1368fc235",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "23 has extractive and abstractive compressors the extractive compressor selects useful sentences while the abstractive compressor synthesizes information from multiple documents longllmlingua longllmlingua  49 improves llmlingua by focusing on key informa tion related to the query selective context selective context enhances llm efficiency by identifying and removing redundant information in the input context it evaluates the informativeness of lexical units using 9",
        "mimetype": "text/plain",
        "start_char_idx": 2962,
        "end_char_idx": 3432,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "9bc0b211-1fa9-4936-91b7-78cf581401b5",
        "embedding": null,
        "metadata": {
            "page_label": "10",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "fb02abd6-2be2-4ec0-beda-0b4eab19e04e",
                "node_type": "4",
                "metadata": {
                    "page_label": "10",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "4d6fad2246b36a6b9b41d5b73a31ee283b37ce08281e237db607fb93854f3bd9",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "6ceace5a-787b-48a8-a1d3-39984700cdd5",
                "node_type": "1",
                "metadata": {},
                "hash": "f437338ab24432553567af423aa1c9d9bdbb7fea5709e2057c040c12a2a0d300",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "selfinformation computed by a base causal language model this method is nonquerybased allowing a comparison between querybased and nonquerybased approaches we evaluate these methods on three benchmark datasets nq triviaqa and hotpotqa comparative results of different summarization methods are shown in table 10 we recommend recomp for its outstanding performance longllmlingua does not perform well but demonstrates better generalization capabilities as it was not trained on these experimental datasets therefore we consider it as an alternative method additional implementation details and discussions on nonquerybased methods are provided in appendix a4 38 generator finetuning in this section we focus on finetuning the generator while leaving retriever finetuning for future exploration we aim to investigate the impact of finetuning particularly the influence of relevant or irrelevant contexts on the generators performance formally we denote xas the query fed into the rag system and das the contexts for this input the finetuning loss of the generator is the negative loglikelihood of the groundtruth output y to explore the impact of finetuning especially relevant and irrelevant contexts we define dgoldas a context relevant to the query and drandom as a randomly retrieved context we train the model by varying the composition of das follows dg the augmented context consists of queryrelevant documents denoted as dgdgold dr the context contains one randomly sampled document denoted as drdrandom  dgr the augmented context comprises a relevant document and a randomlyselected one denoted asdgrdgold drandom  dgg the augmented context consists of two copies of a queryrelevant document denoted as dggdgold dgold we denote the base lm generator not finetuned as mb and the model finetuned under the corresponding dasmgmrmgrmgg we finetuned our model on several qa and reading uni00000006 uni00000006uni00000090 uni00000006uni0000009b uni00000006uni00000090uni0000009b020406080100uni00000005uni00000098uni0000009funi0000008euni0000009buni0000008auni00000090uni0000008euni00000231uni00000015uni0000008cuni00000098uni0000009buni0000008euni0000000funi00000098uni0000008duni0000008euni00000095uni0000009cuni00000231uni00000016uni0000009buni0000008auni00000092uni00000097uni0000008euni0000008duni00000231uni000000a0uni00000092uni0000009duni00000091uni00000231uni00000006uni00000092uni0000008funi0000008funi0000008euni0000009buni0000008euni00000097uni0000009duni00000231uni0000000funi0000008euni0000009duni00000091uni00000098uni0000008d uni0000000funi0000008b uni0000000funi00000090uni0000000funi0000009b uni0000000funi00000090uni0000009buni0000000funi00000090uni00000090 figure 3 results of generator finetuningcomprehension datasets groundtruth coverage is used as our evaluation metric since qa task answers are relatively short",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 2836,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "6ceace5a-787b-48a8-a1d3-39984700cdd5",
        "embedding": null,
        "metadata": {
            "page_label": "10",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "fb02abd6-2be2-4ec0-beda-0b4eab19e04e",
                "node_type": "4",
                "metadata": {
                    "page_label": "10",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "4d6fad2246b36a6b9b41d5b73a31ee283b37ce08281e237db607fb93854f3bd9",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "9bc0b211-1fa9-4936-91b7-78cf581401b5",
                "node_type": "1",
                "metadata": {
                    "page_label": "10",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "8654015e2a61c63d1f536b8bbdcbad8bac8293a17c680f9d4421863b7b3f290f",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "figure 3 results of generator finetuningcomprehension datasets groundtruth coverage is used as our evaluation metric since qa task answers are relatively short we select llama2 7b 50 as the base model similar to training we evaluate all trained models on validation sets withdgdrdgr andd where dindicates inference without retrieval figure 3 presents our main results models trained with a mix of relevant and random documents  mgr perform best when provided with either gold or mixed contexts this suggests that mixing relevant and random contexts during training can enhance the generators robustness to irrelevant information while ensuring effective utilization of relevant contexts therefore we identify the practice of augmenting with a few relevant and randomlyselected documents during training as the best approach detailed dataset information hyperparameters and experimental results can be found in appendix a5 4 searching for best rag practices in the following section we investigate the optimal practices for implementing rag to begin with we used the default practice identified in section 3 for each module following the workflow depicted in figure 1 we sequentially optimized individual modules and selected the most effective option among alternatives this iterative process continued until we determined the best method for implementing the final summarization module based on section 38 we used the llama27bchat model finetuned where each query was augmented by a few randomselected and relevant documents 10",
        "mimetype": "text/plain",
        "start_char_idx": 2677,
        "end_char_idx": 4205,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "3aa7ff86-2f74-4e8f-bcc6-ee6ae7817469",
        "embedding": null,
        "metadata": {
            "page_label": "11",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "aa08840c-7a2d-4b6e-acad-f149deeff9ba",
                "node_type": "4",
                "metadata": {
                    "page_label": "11",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "6985489af49c301bcc515ec027b0896eb17680540d84e08be0d419a01585d97e",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "2d4839e3-a396-407d-9fc7-2fce97423a28",
                "node_type": "1",
                "metadata": {},
                "hash": "6dfefecc2666ff3d053608af20987ec8784bd2eefd5b42c916527f4e7a72c0b3",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "methodcommonsense fact check odqa multihop medical rag avg acc acc em f1 em f1 acc score score f1 latency classification module  hybrid with hyde monot5 sides recomp wo classification 0719 0505 0391 0450 0212 0255 0528 0540 0465 0353 1658 classification 0727 0595 0393 0450 0207 0257 0460 0580 0478 0353 1171 with classification retrieval module  monot5 sides recomp  hyde 0718 0595 0320 0373 0170 0213 0400 0545 0443 0293 1158  original 0721 0585 0300 0350 0153 0197 0390 0486 0428 0273 144  hybrid 0718 0595 0347 0397 0190 0240 0750 0498 0477 0318 145 hybrid with hyde 0727 0595 0393 0450 0207 0257 0460 0580 0478 0353 1171 with classification hybrid with hyde reranking module  sides recomp wo reranking 0720 0591 0365 0429 0211 0260 0512 0530 0470 0334 1031 monot5 0727 0595 0393 0450 0207 0257 0460 0580 0478 0353 1171  monobert 0723 0593 0383 0443 0217 0259 0482 0551 0475 0351 1165  rankllama 0723 0597 0382 0443 0197 0240 0454 0558 0470 0342 1351  tildev2 0725 0588 0394 0456 0209 0255 0486 0536 0476 0355 1126 with classification hybrid with hyde monot5 repacking module  recomp  sides 0727 0595 0393 0450 0207 0257 0460 0580 0478 0353 1171  forward 0722 0599 0379 0437 0215 0260 0472 0542 0474 0349 1168 reverse 0728 0592 0387 0445 0219 0263 0532 0560 0483 0354 1170 with classification hybrid with hyde monot5 reverse summarization module wo summarization 0729 0591 0402 0457 0205 0252 0528 0533 0480 0355 1097 recomp 0728 0592 0387 0445 0219 0263 0532 0560 0483 0354 1170  longllmlingua 0713 0581 0362 0423 0199 0245 0530 0539 0466 0334 1617 table 11 results of the search for optimal rag practices modules enclosed in",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 1630,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "2d4839e3-a396-407d-9fc7-2fce97423a28",
        "embedding": null,
        "metadata": {
            "page_label": "11",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "aa08840c-7a2d-4b6e-acad-f149deeff9ba",
                "node_type": "4",
                "metadata": {
                    "page_label": "11",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "6985489af49c301bcc515ec027b0896eb17680540d84e08be0d419a01585d97e",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "3aa7ff86-2f74-4e8f-bcc6-ee6ae7817469",
                "node_type": "1",
                "metadata": {
                    "page_label": "11",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "854b05e98fd9ed742fc2ee702b23be9d763378bf5ebd842905fa8c7eafe230db",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "0713 0581 0362 0423 0199 0245 0530 0539 0466 0334 1617 table 11 results of the search for optimal rag practices modules enclosed in a boxed module are under investigation to determine the best method the underlined method represents the selected implementation the avg average score is calculated based on the acc em and rag scores for all tasks while the average latency is measured in seconds per query the best scores are highlighted inbold  as the generator we used milvus to build a vector database that includes 10million text of english wikipedia and 4million text of medical data we also investigated the impact of removing the query classification reranking and summarization modules to assess their contributions 41 comprehensive evaluation we conducted extensive experiments across various nlp tasks and datasets to assess the perfor mance of rag systems specifically i commonsense reasoning  ii fact checking  iii opendomain qa  iv multihop qa  v medical qa  for further details on the tasks and their corresponding datasets please refer to appendix a6 furthermore we evaluated the rag capabilities on subsets extracted from these datasets employing the metrics recommended in ra gas  51 including faithfulness context relevancy answer relevancy and answer correctness additionally we measured retrieval similarity by computing the cosine similarity between retrieved documents and gold documents we used accuracy as the evaluation metric for the tasks of commonsense reasoning fact checking and medical qa for opendomain qa and multihop qa we employed tokenlevel f1 score and exact match em score the final rag score was calculated by averaging the aforementioned five rag capabilities we followed trivedi et al 52 and subsampled up to 500examples from each dataset 42 results and analysis based on the experimental results presented in table 11 the following key insights emerge query classification module this module is referenced and contributes to both effectiveness and efficiency leading to an average improvement in the overall score from 0428to0443and a reduction in latency time from 1641to1158seconds per query 11",
        "mimetype": "text/plain",
        "start_char_idx": 1499,
        "end_char_idx": 3636,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "cf548314-3230-40bb-99bf-de01f0fcae28",
        "embedding": null,
        "metadata": {
            "page_label": "12",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "3509bf5f-2499-4636-a869-c90b4cbd9a92",
                "node_type": "4",
                "metadata": {
                    "page_label": "12",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "5be05832e891f4d14e2ef064b0d15a0853e215847c2a3f1ec9e98f02a3c62c92",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "retrieval module while the hybrid with hyde method attained the highest rag score of 058 it does so at a considerable computational cost with 1171second per query consequently the hybrid or original methods are recommended as they reduce latency while maintaining comparable performance reranking module the absence of a reranking module led to a noticeable drop in performance highlighting its necessity monot5 achieved the highest average score affirming its efficacy in augmenting the relevance of retrieved documents this indicates the critical role of reranking in enhancing the quality of generated responses repacking module the reverse configuration exhibited superior performance achieving an rag score of 0560 this indicates that positioning more relevant context closer to the query leads to optimal outcomes summarization module recomp demonstrated superior performance although achieving compa rable results with lower latency was possible by removing the summarization module nevertheless recomp remains the preferred choice due to its capability to address the generators maximum length constraints in timesensitive applications removing summarization could effectively reduce response time the experimental results demonstrate that each module contributes uniquely to the overall perfor mance of the rag system the query classification module enhances accuracy and reduces latency while the retrieval and reranking modules significantly improve the systems ability to handle diverse queries the repacking and summarization modules further refine the systems output ensuring highquality responses across different tasks 5 discussion 51 best practices for implementing rag according to our experimental findings we suggest two distinct recipes or practices for implementing rag systems each customized to address specific requirements one focusing on maximizing performance and the other on striking a balance between efficiency and efficacy best performance practice to achieve the highest performance it is recommended to incorporate query classification module use the hybrid with hyde method for retrieval employ monot5 for reranking opt for reverse for repacking and leverage recomp for summarization this configuration yielded the highest average score of 0483 albeit with a computationallyintensive process balanced efficiency practice in order to achieve a balance between performance and efficiency it is recommended to incorporate the query classification module implement the hybrid method for retrieval use tildev2 for reranking opt for reverse for repacking and employ recomp for summarization given that the retrieval module accounts for the majority of processing time in the system transitioning to the hybrid method while keeping other modules unchanged can substantially reduce latency while preserving a comparable performance 52 multimodal extension we have extended rag to multimodal applications specifically we have incorporated text2image and image2text retrieval capabilities into the system with a substantial collection of paired image and textual descriptions as a retrieval source as depicted in figure 4 the text2image capability speeds up the image generation process when a user query aligns well with the textual descriptions of stored images ie retrieval as generation strategy while the image2text functionality comes into play when a user provides an image and engages in conversation about the input image these multimodal rag capabilities offer the following advantages groundedness  retrieval methods provide information from verified multimodal materials thereby ensuring authenticity and specificity in contrast onthefly generation relies on models to generate new content which can occasionally result in factual errors or inaccuracies efficiency  retrieval methods are typically more efficient especially when the answer already exists in stored materials conversely generation methods may require more computational resources to produce new content particularly for images or lengthy texts 12",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 4050,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "67f8e427-af22-46c3-a13d-1843db7df2d7",
        "embedding": null,
        "metadata": {
            "page_label": "13",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "9a17639c-03a9-4c85-8b09-bacc74ae493e",
                "node_type": "4",
                "metadata": {
                    "page_label": "13",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "8f73ec50d2f039127ebc251d6ec724eaa3dab8b17da80e4bad229c6a232a6b30",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "a dog is sleeping retrieval retrieval retrieval a dog is sleeping a dog is drinking water a dog is sleeping retrieval a dog is sleepingimage2text retrievaltext2image retrieval high similaritylow similarity user query image caption modelimage generation model figure 4 workflow of multimodal retrieval the upper section illustrates the texttoimage retrieval process initially a text query is used to find images in the database with the highest similarity if a high similarity is found the image is returned directly if not an image generation model is employed to create and return an appropriate image the lower section demonstrates the imagetotext retrieval process here a userprovided image is matched with images in the database to find the highest similarity if a high similarity is identified the prestored caption of the matching image is returned otherwise an image captioning model generates and returns a new caption maintainability  generation models often necessitate careful finetuning to tailor them for new applications in contrast retrievalbased methods can be improved to address new demands by simply enlarging the size and enhancing the quality of retrieval sources we plan to broaden the application of this strategy to include other modalities such as video and speech while also exploring efficient and effective crossmodal retrieval techniques 6 conclusion in this study we aim to identify optimal practices for implementing retrievalaugmented generation in order to improve the quality and reliability of content produced by large language models we systematically assessed a range of potential solutions for each module within the rag framework and recommended the most effective approach for each module furthermore we introduced a comprehensive evaluation benchmark for rag systems and conducted extensive experiments to determine the best practices among various alternatives our findings not only contribute to a deeper understanding of retrievalaugmented generation systems but also establish a foundation for future research limitations we have evaluated the impact of various methods for finetuning llm generators previous studies have demonstrated the feasibility of training both the retriever and generator jointly we would like to explore this possibility in the future in this study we embraced the principle of modular 13",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 2359,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "5b10ecde-d8b2-4c7f-9a33-0e89feeee43e",
        "embedding": null,
        "metadata": {
            "page_label": "14",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "929827ab-12eb-4b71-8673-13aae1e70182",
                "node_type": "4",
                "metadata": {
                    "page_label": "14",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "649969c5019b73bfc9e7ef2c69c486939db0c62959875e8fd2476e0b083ee3fa",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "13885124-ac71-4fbf-9495-6aa7925770c2",
                "node_type": "1",
                "metadata": {},
                "hash": "d3e605751f0e64dee922faf7d8602268156960771ccc80a1f0c2f78391a4d87e",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "design to simplify the search for optimal rag implementations thereby reducing complexity due to the daunting costs associated with constructing vector databases and conducting experiments our evaluation was limited to investigating the effectiveness and influence of representative chunking techniques within the chunking module it would be intriguing to further explore the impact of different chunking techniques on the entire rag systems while we have discussed the application of rag in the domain of nlp and extended its scope to image generation an enticing avenue for future exploration would involve expanding this research to other modalities such as speech and video acknowledgments the authors would like to thank the anonymous reviewers for their valuable comments this work was supported by national natural science foundation of china no 62076068  references 1long ouyang jeff wu xu jiang diogo almeida carroll l wainwright pamela mishkin chong zhang sandhini agarwal katarina slama alex ray john schulman jacob hilton fraser kelton luke miller maddie simens amanda askell peter welinder paul christiano jan leike and ryan lowe training language models to follow instructions with human feedback in proceedings of the conference on neural information processing systems neurips 2022  2022 2rafael rafailov archit sharma eric mitchell stefano ermon christopher d manning and chelsea finn direct preference optimization your language model is secretly a reward model arxiv preprint arxiv230518290  2023 3yao zhao rishabh joshi tianqi liu misha khalman mohammad saleh and peter j liu slic hf sequence likelihood calibration with human feedback arxiv preprint arxiv230510425  2023 4zheng yuan hongyi yuan chuanqi tan wei wang songfang huang and fei huang rrhf rank responses to align language models with human feedback without tears arxiv preprint arxiv230405302  2023 5wenhao liu xiaohua wang muling wu tianlong li changze lv zixuan ling jianhao zhu cenyuan zhang xiaoqing zheng and xuanjing huang aligning large language models with human preferences through representation engineering arxiv preprint arxiv231215997  2023 6yunfan gao yun xiong xinyu gao kangxiang jia jinliu pan yuxi bi yi dai jiawei sun and haofen wang retrievalaugmented generation for large language models a survey arxiv preprint arxiv231210997  2023 7huayang li yixuan su deng cai yan wang and lemao liu a survey on retrievalaugmented text generation arxiv preprint arxiv220201110  2022 8deng cai yan wang lemao liu and shuming shi recent advances in retrievalaugmented text generation in proceedings of the 45th international acm sigir conference on research and development in information retrieval  pages 34173419 2022 9xinbei ma yeyun gong pengcheng he hai zhao and nan duan query rewriting for retrievalaugmented large language models arxiv preprint arxiv230514283  2023 10 luyu gao xueguang ma jimmy lin and jamie callan precise zeroshot dense retrieval",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 2945,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "13885124-ac71-4fbf-9495-6aa7925770c2",
        "embedding": null,
        "metadata": {
            "page_label": "14",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "929827ab-12eb-4b71-8673-13aae1e70182",
                "node_type": "4",
                "metadata": {
                    "page_label": "14",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "649969c5019b73bfc9e7ef2c69c486939db0c62959875e8fd2476e0b083ee3fa",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "5b10ecde-d8b2-4c7f-9a33-0e89feeee43e",
                "node_type": "1",
                "metadata": {
                    "page_label": "14",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "19c81663d926bbfd62757d87461fc029aec129390a33114c2bc7c068ef8a9090",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "nan duan query rewriting for retrievalaugmented large language models arxiv preprint arxiv230514283  2023 10 luyu gao xueguang ma jimmy lin and jamie callan precise zeroshot dense retrieval without relevance labels arxiv preprint arxiv221210496  2022 11 liang wang nan yang xiaolong huang binxing jiao linjun yang daxin jiang rangan majumder and furu wei text embeddings by weaklysupervised contrastive pretraining arxiv preprint arxiv221203533  2022 12 shitao xiao zheng liu peitian zhang and niklas muennighoff cpack packaged resources to advance general chinese embedding 2023 14",
        "mimetype": "text/plain",
        "start_char_idx": 2756,
        "end_char_idx": 3338,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "d4aa682e-3f8b-435b-b03a-ea24071199a0",
        "embedding": null,
        "metadata": {
            "page_label": "15",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "f849a120-3175-45b1-8c32-31264b11cf44",
                "node_type": "4",
                "metadata": {
                    "page_label": "15",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "792742b1a3ae8377e4a085fddf57a753bbd76cc2e710eceee294869a87b857cf",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "d80609f3-8029-4e68-9265-473b27e7a320",
                "node_type": "1",
                "metadata": {},
                "hash": "5c7ee68777935bee3758b144759e0e0f5ea132e5554de40a8986b879b4f17fef",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "13 openai gpt4 technical report corr  abs230308774 2023 doi 1048550arxiv 2303 08774 url httpsdoiorg1048550arxiv230308774  14 hugo touvron thibaut lavril gautier izacard xavier martinet marieanne lachaux timo th\u00e9e lacroix baptiste rozi\u00e8re naman goyal eric hambro faisal azhar et al llama open and efficient foundation language models arxiv preprint arxiv230213971  2023 15 yue zhang yafu li leyang cui deng cai lemao liu tingchen fu xinting huang enbo zhao yu zhang yulong chen et al sirens song in the ai ocean a survey on hallucination in large language models arxiv preprint arxiv230901219  2023 16 xiaohua wang yuliang yan longtao huang xiaoqing zheng and xuanjing huang halluci nation detection for generative large language models by bayesian sequential estimation in proceedings of the 2023 conference on empirical methods in natural language processing  pages 1536115371 2023 17 liang wang nan yang and furu wei query2doc query expansion with large language models arxiv preprint arxiv230307678  2023 18 gangwoo kim sungdong kim byeongguk jeon joonsuk park and jaewoo kang tree of clarifications answering ambiguous questions with retrievalaugmented large language models arxiv preprint arxiv231014696  2023 19 jerry liu llamaindex 11 2022 url httpsgithubcomjerryjliullama_index  20 peitian zhang shitao xiao zheng liu zhicheng dou and jianyun nie retrieve anything to augment large language models arxiv preprint arxiv231007554  2023 21 zehan li xin zhang yanzhao zhang dingkun long pengjun xie and meishan zhang towards general text embeddings with multistage contrastive learning arxiv preprint arxiv230803281  2023 22 huiqiang jiang qianhui wu chinyew lin yuqing yang and lili qiu llmlingua compressing prompts for accelerated inference of large language models arxiv preprint arxiv231005736  2023 23 fangyuan xu weijia shi and eunsol choi recomp improving retrievalaugmented lms with compression and selective augmentation arxiv preprint arxiv231004408  2023 24 zhiruo wang jun araki zhengbao jiang md rizwan parvez and graham neubig learning to filter context for retrievalaugmented generation arxiv preprint arxiv231108377  2023 25 rodrigo nogueira wei yang kyunghyun cho and jimmy lin multistage document ranking with bert arxiv preprint arxiv191014424  2019 26 rodrigo nogueira zhiying jiang and jimmy lin document ranking with a pretrained sequencetosequence model arxiv preprint arxiv200306713  2020 27 xueguang ma liang wang nan yang furu wei and jimmy",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 2471,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "d80609f3-8029-4e68-9265-473b27e7a320",
        "embedding": null,
        "metadata": {
            "page_label": "15",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "f849a120-3175-45b1-8c32-31264b11cf44",
                "node_type": "4",
                "metadata": {
                    "page_label": "15",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "792742b1a3ae8377e4a085fddf57a753bbd76cc2e710eceee294869a87b857cf",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "d4aa682e-3f8b-435b-b03a-ea24071199a0",
                "node_type": "1",
                "metadata": {
                    "page_label": "15",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "60dc9f6e3b2f6bbb53cd1e5a5e5c2816ae7a30206a75aa802c284a5776569af6",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "jiang and jimmy lin document ranking with a pretrained sequencetosequence model arxiv preprint arxiv200306713  2020 27 xueguang ma liang wang nan yang furu wei and jimmy lin finetuning llama for multistage text retrieval arxiv preprint arxiv231008319  2023 28 shengyao zhuang and guido zuccon tilde term independent likelihood model for passage reranking in proceedings of the 44th international acm sigir conference on research and development in information retrieval  pages 14831492 2021 29 shengyao zhuang and guido zuccon fast passage reranking with contextualized exact term matching and efficient passage expansion arxiv preprint arxiv210808513  2021 30 hongyin luo yungsung chuang yuan gong tianhua zhang yoon kim xixin wu danny fox helen m meng and james r glass sail searchaugmented instruction learning inconference on empirical methods in natural language processing  2023 url https apisemanticscholarorgcorpusid258865283  15",
        "mimetype": "text/plain",
        "start_char_idx": 2302,
        "end_char_idx": 3239,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "c4dee8e5-92c0-4300-b597-f2282ff70c6d",
        "embedding": null,
        "metadata": {
            "page_label": "16",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "4c35688a-ac06-47b6-8232-7d121df1ec30",
                "node_type": "4",
                "metadata": {
                    "page_label": "16",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "ebc1735cbb1b272e85ce6c9c67af9410f7d9c679728b354532cc4b475bf28604",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "add45f6d-829e-4063-81bd-350c6039efa3",
                "node_type": "1",
                "metadata": {},
                "hash": "9ad224a8fe2d048d1ea4e4abcdf35380199b6b3904e1e10687d15b043e14a4aa",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "31 tianjun zhang shishir g patil naman jain sheng shen matei a zaharia ion stoica and joseph e gonzalez raft adapting language model to domain specific rag arxiv  abs240310131 2024 32 zihan liu wei ping rajarshi roy peng xu chankyu lee mohammad shoeybi and bryan catanzaro chatqa surpassing gpt4 on conversational qa and rag 2024 url https apisemanticscholarorgcorpusid267035133  33 gautier izacard patrick lewis maria lomeli lucas hosseini fabio petroni timo schick jane a yu armand joulin sebastian riedel and edouard grave fewshot learning with retrieval augmented language models arxiv  abs220803299 2022 34 lingxi zhang yue yu kuan wang and chao zhang arl2 aligning retrievers for blackbox large language models via selfguided adaptive relevance labeling arxiv  abs240213542 2024 35 weijia shi sewon min michihiro yasunaga minjoon seo rich james mike lewis luke zettlemoyer and wentau yih replug retrievalaugmented blackbox language models arxiv preprint arxiv230112652  2023 36 kelvin guu kenton lee zora tung panupong pasupat and mingwei chang realm retrievalaugmented language model pretraining arxiv  abs200208909 2020 37 xi victoria lin xilun chen mingda chen weijia shi maria lomeli rich james pedro rodriguez jacob kahn gergely szilvasy mike lewis luke zettlemoyer and scott yih radit retrievalaugmented dual instruction tuning arxiv  abs231001352 2023 38 hamed zamani and michael bendersky stochastic rag endtoend retrievalaugmented gen eration through expected utility maximization 2024 url httpsapisemanticscholar orgcorpusid269605438  39 yizheng huang and jimmy huang a survey on retrievalaugmented text generation for large language models arxiv preprint arxiv240410981  2024 40 ruochen zhao hailin chen weishi wang fangkai jiao xuan long do chengwei qin bosheng ding xiaobao guo minzhi li xingxuan li et al retrieving multimodal information for augmented generation a survey arxiv preprint arxiv230310868  2023 41 penghao zhao hailin zhang qinhan yu zhengren wang yunteng geng fangcheng fu ling yang wentao zhang and bin cui retrievalaugmented generation for aigenerated content a survey arxiv preprint arxiv240219473  2024 42 michael g\u00fcnther jackmin ong isabelle mohr alaeddine abdessalem tanguy abel moham mad kalim akram susana guzman georgios mastrapas saba sturua bo wang et al jina embeddings 2 8192token generalpurpose text embeddings for long documents arxiv preprint arxiv231019923  2023 43 llamaindex",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 2428,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "add45f6d-829e-4063-81bd-350c6039efa3",
        "embedding": null,
        "metadata": {
            "page_label": "16",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "4c35688a-ac06-47b6-8232-7d121df1ec30",
                "node_type": "4",
                "metadata": {
                    "page_label": "16",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "ebc1735cbb1b272e85ce6c9c67af9410f7d9c679728b354532cc4b475bf28604",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "c4dee8e5-92c0-4300-b597-f2282ff70c6d",
                "node_type": "1",
                "metadata": {
                    "page_label": "16",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "1338db703c072a0f06ccaf39c61798fffb2f9632cd8a78fc94bee2673918f822",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "georgios mastrapas saba sturua bo wang et al jina embeddings 2 8192token generalpurpose text embeddings for long documents arxiv preprint arxiv231019923  2023 43 llamaindex llamaindex website httpswwwllamaindexcom  accessed 20240608 44 kunal sawarkar abhilasha mangal and shivam raj solanki blended rag improving rag retrieveraugmented generation accuracy with semantic search and hybrid querybased retriev ersarxiv preprint arxiv240407220  2024 45 gautier izacard mathilde caron lucas hosseini sebastian riedel piotr bojanowski armand joulin and edouard grave unsupervised dense information retrieval with contrastive learning arxiv preprint arxiv211209118  2021 46 nandan thakur nils reimers andreas r\u00fcckl\u00e9 abhishek srivastava and iryna gurevych beir a heterogenous benchmark for zeroshot evaluation of information retrieval models arxiv preprint arxiv210408663  2021 47 payal bajaj daniel campos nick craswell li deng jianfeng gao xiaodong liu rangan majumder andrew mcnamara bhaskar mitra tri nguyen et al ms marco a human generated machine reading comprehension dataset arxiv preprint arxiv161109268  2016 16",
        "mimetype": "text/plain",
        "start_char_idx": 2256,
        "end_char_idx": 3369,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "ff4593e0-bf2c-4a64-a964-6e147cd9405b",
        "embedding": null,
        "metadata": {
            "page_label": "17",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "17818555-8de9-41f4-9f99-d06cab3a138d",
                "node_type": "4",
                "metadata": {
                    "page_label": "17",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "fef362e31c823d7d197a77ff31c8ee91d4386f84c89336fd8b5fa2b800faf788",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "dcf71081-2ae4-417c-8d1f-6bd7d8988c6f",
                "node_type": "1",
                "metadata": {},
                "hash": "2602bd12ca82271ffd2ed364000ef7a35c6390a0d436550cc7bedecf56bcf420",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "48 nelson f liu kevin lin john hewitt ashwin paranjape michele bevilacqua fabio petroni and percy liang lost in the middle how language models use long contexts transactions of the association for computational linguistics  12157173 2024 49 huiqiang jiang qianhui wu xufang luo dongsheng li chinyew lin yuqing yang and lili qiu longllmlingua accelerating and enhancing llms in long context scenarios via prompt compression arxiv preprint arxiv231006839  2023 50 hugo touvron louis martin kevin r stone peter albert amjad almahairi yasmine babaei nikolay bashlykov soumya batra prajjwal bhargava shruti bhosale daniel m bikel lukas blecher cristian cant\u00f3n ferrer moya chen guillem cucurull david esiobu jude fernandes jeremy fu wenyin fu brian fuller cynthia gao vedanuj goswami naman goyal anthony s hartshorn saghar hosseini rui hou hakan inan marcin kardas viktor kerkez madian khabsa isabel m kloumann a v  korenev punit singh koura marieanne lachaux thibaut lavril jenya lee diana liskovich yinghai lu yuning mao xavier martinet todor mihaylov pushkar mishra igor molybog yixin nie andrew poulton jeremy reizenstein rashi rungta kalyan saladi alan schelten ruan silva eric michael smith r subramanian xia tan binh tang ross taylor adina williams jian xiang kuan puxin xu zhengxu yan iliyan zarov yuchen zhang angela fan melanie kambadur sharan narang aurelien rodriguez robert stojnic sergey edunov and thomas scialom llama 2 open foundation and finetuned chat models arxiv  abs230709288 2023 51 es shahul jithin james luis espinosa anke and steven schockaert ragas automated evaluation of retrieval augmented generation in conference of the european chapter of the association for computational linguistics  2023 url httpsapisemanticscholarorg corpusid263152733  52 harsh trivedi niranjan balasubramanian tushar khot and ashish sabharwal musique multihop questions via singlehop question composition transactions of the association for computational linguistics  page 539554 may 2022 doi 101162tacl_a_00475 url httpdxdoiorg101162tacl_a_00475  53 mike conover matt hayes ankit mathur jianwei xie jun wan sam shah ali ghodsi patrick wendell matei zaharia and reynold xin free dolly introducing the worlds first truly open instructiontuned llm 2023 url httpswwwdatabrickscomblog20230412 dollyfirstopencommerciallyviableinstructiontunedllm  54 nick craswell bhaskar mitra emine yilmaz daniel",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 2392,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "dcf71081-2ae4-417c-8d1f-6bd7d8988c6f",
        "embedding": null,
        "metadata": {
            "page_label": "17",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "17818555-8de9-41f4-9f99-d06cab3a138d",
                "node_type": "4",
                "metadata": {
                    "page_label": "17",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "fef362e31c823d7d197a77ff31c8ee91d4386f84c89336fd8b5fa2b800faf788",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "ff4593e0-bf2c-4a64-a964-6e147cd9405b",
                "node_type": "1",
                "metadata": {
                    "page_label": "17",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "4edba051ea03c4a0f52c129d5f756e2a8e5cd9a63ce640089e2bd8cc8b0e2e5a",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "llm 2023 url httpswwwdatabrickscomblog20230412 dollyfirstopencommerciallyviableinstructiontunedllm  54 nick craswell bhaskar mitra emine yilmaz daniel fernando campos and ellen m v oorhees overview of the trec 2019 deep learning track arxiv  abs200307820 2020 url https apisemanticscholarorgcorpusid253234683  55 nick craswell bhaskar mitra emine yilmaz daniel fernando campos and ellen m v oorhees overview of the trec 2020 deep learning track arxiv  abs210207662 2021 url https apisemanticscholarorgcorpusid212737158  56 jimmy lin xueguang ma shengchieh lin jhenghong yang ronak pradeep and rodrigo nogueira pyserini a python toolkit for reproducible information retrieval research with sparse and dense representations in proceedings of the 44th international acm sigir conference on research and development in information retrieval  pages 23562362 2021 57 tom kwiatkowski jennimaria palomaki olivia redfield michael collins ankur p parikh chris alberti danielle epstein illia polosukhin jacob devlin kenton lee kristina toutanova llion jones matthew kelcey mingwei chang andrew m dai jakob uszkoreit quoc v  le and slav petrov natural questions a benchmark for question answering research transactions of the association for computational linguistics  7453466 2019 58 mandar joshi eunsol choi daniel s weld and luke zettlemoyer triviaqa a large scale distantly supervised challenge dataset for reading comprehension arxiv  abs170503551 2017 59 zhilin yang peng qi saizheng zhang yoshua bengio william w cohen ruslan salakhut dinov and christopher d manning hotpotqa a dataset for diverse explainable multihop question answering arxiv preprint arxiv180909600  2018 17",
        "mimetype": "text/plain",
        "start_char_idx": 2242,
        "end_char_idx": 3913,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "423a6847-e238-4c9f-b27c-70bbfbed6705",
        "embedding": null,
        "metadata": {
            "page_label": "18",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "fc36d370-87f9-4a3f-a557-5f7045a4f6a4",
                "node_type": "4",
                "metadata": {
                    "page_label": "18",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "1436bf3eb788ca1803452463cabefb308e001fbfa364b7860904ae7a4dc86dbc",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "98db3e26-d7b4-44eb-9b42-fc4a56e6348b",
                "node_type": "1",
                "metadata": {},
                "hash": "c6dcbe8923129a5b40bcc9eb70b4108aae445f36bdf47a5fee2ca9eaec071679",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "60 ivan stelmakh yi luan bhuwan dhingra and mingwei chang asqa factoid questions meet longform answers arxiv  abs220406092 2022 61 tom\u00e1\u0161 ko \u02c7cisky jonathan schwarz phil blunsom chris dyer karl moritz hermann g\u00e1bor melis and edward grefenstette the narrativeqa reading comprehension challenge transac tions of the association for computational linguistics  6317328 2018 62 pranav rajpurkar jian zhang konstantin lopyrev and percy liang squad 100000 questions for machine comprehension of text arxiv preprint arxiv160605250  2016 63 stephanie lin jacob hilton and owain evans truthfulqa measuring how models mimic human falsehoods arxiv preprint arxiv210907958  2021 64 j edward hu yelong shen phillip wallis zeyuan allenzhu yuanzhi li shean wang and weizhu chen lora lowrank adaptation of large language models arxiv  abs210609685 2021 65 dan hendrycks collin burns steven basart andy zou mantas mazeika dawn song and jacob steinhardt measuring massive multitask language understanding cornell university  arxivcornell university  arxiv  sep 2020 66 peter clark isaac cowhey oren etzioni tushar khot ashish sabharwal carissa schoenick and oyvind tafjord think you have solved question answering try arc the ai2 reasoning chal lenge arxiv  abs180305457 2018 url httpsapisemanticscholarorgcorpusid 3922816  67 todor mihaylov peter clark tushar khot and ashish sabharwal can a suit of armor conduct electricity a new dataset for open book question answering in proceedings of the 2018 conference on empirical methods in natural language processing  jan 2018 doi 1018653v1d181260 url httpdxdoiorg1018653v1d181260  68 james thorne andreas vlachos christos christodoulopoulos and arpit mittal fever a largescale dataset for fact extraction and verification arxiv  abs180305355 2018 url httpsapisemanticscholarorgcorpusid4711425  69 tianhua zhang hongyin luo yungsung chuang wei fang luc gaitskell thomas hartvigsen xixin wu danny fox helen m meng and james r glass interpretable unified language checking arxiv  abs230403728 2023 url httpsapisemanticscholar orgcorpusid258041307  70 jonathan berant andrew chou roy frostig and percy liang semantic parsing on freebase from questionanswer pairs empirical methods in natural language processingempirical methods in natural language processing  oct 2013 71 xanh ho a nguyen saku sugawara and akiko aizawa constructing a multihop qa dataset for comprehensive evaluation of reasoning steps arxiv  abs201101060 2020 url httpsapisemanticscholarorgcorpusid226236740  72 ofir press muru zhang sewon min ludwig schmidt noaha smith and mike",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 2572,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "98db3e26-d7b4-44eb-9b42-fc4a56e6348b",
        "embedding": null,
        "metadata": {
            "page_label": "18",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "fc36d370-87f9-4a3f-a557-5f7045a4f6a4",
                "node_type": "4",
                "metadata": {
                    "page_label": "18",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "1436bf3eb788ca1803452463cabefb308e001fbfa364b7860904ae7a4dc86dbc",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "423a6847-e238-4c9f-b27c-70bbfbed6705",
                "node_type": "1",
                "metadata": {
                    "page_label": "18",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "3b51dd33c6742eea4c94d783003116ee58c7f5447849a02f402978cc038e1e2f",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "evaluation of reasoning steps arxiv  abs201101060 2020 url httpsapisemanticscholarorgcorpusid226236740  72 ofir press muru zhang sewon min ludwig schmidt noaha smith and mike lewis measuring and narrowing the compositionality gap in language models oct 2022 73 qiao jin bhuwan dhingra zhengping liu william w cohen and xinghua lu pubmedqa a dataset for biomedical research question answering in conference on empirical methods in natural language processing  2019 url httpsapisemanticscholarorgcorpusid 202572622  74 akari asai zeqiu wu yizhong wang avirup sil and hannaneh hajishirzi selfrag learning to retrieve generate and critique through selfreflection arxiv preprint arxiv231011511  2023 18",
        "mimetype": "text/plain",
        "start_char_idx": 2398,
        "end_char_idx": 3095,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "0fbca574-e99b-4f1b-adef-6026b4b620c2",
        "embedding": null,
        "metadata": {
            "page_label": "19",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "8810312f-2c72-4f71-a3bf-58e7c5f86095",
                "node_type": "4",
                "metadata": {
                    "page_label": "19",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "48b799c99658d393343064abc025d0e826f9b8fc095365f219bba7624235ffaa",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "43d231d1-3f56-45e6-89f5-41c13164c658",
                "node_type": "1",
                "metadata": {},
                "hash": "bdacb8c1a59686485d3e56643a818fe43102d254b4dd3b555cfd93ffdf442abb",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "a experimental details in this section we provide detailed experimental settings for each module covering dataset specifics training parameters and any additional experimental results a1 query classification datasets we utilized a subset of the databricksdolly15k  53 and generated additional data using gpt4the prompt template for generating questions is shown in table 14 implementation details we choose bertbasemultilingualcased as our classifier with a batch size of 16 and a learning rate of 1e5 the evaluation of results is showcased in table 1 a2 experimental details of retrieval methods implementation details of the comparative experiments of different retrieval methods are as below datasets we use the trec dl 2019 54 and 2020 55 passage ranking datasets to evaluate the performance of different retrieval methods metrics widelyused evaluation metrics for retrieval include map ndcg10 r50 and r1k both map and ndcg10 are orderaware metrics that take the ranking of search results into account in contrast rk is an orderunaware metric we also report the average latency incurred by each method per query implementation details for sparse retrieval we use the bm25 algorithm which relies on the tf idf algorithm for dense retrieval we employ contriever as our unsupervised contrastive text encoder based on our evaluation of embedding models we implement our supervised dense retrieval using llmembedder we use the default implementation of bm25 and contriever from pyserini  56 the bm25 index is constructed using lucene on ms marco collections while the dense vector index is generated with faiss employing flat configuration on the same dataset for query rewriting we prompt zephyr7balpha9 a model trained to act as a helpful assistant to rewrite the original query for query decomposition we employ gpt35turbo0125 to break down the original query into multiple subqueries we closely follow the implementation from hyde  10 utilizing the more advanced instructionfollowing language model gpt35turboinstruct to generate hypothetical answers the model infers with a default temperature of 07 sampling up to a maximum of 512 tokens retrieval experiments and evaluation are conducted using the pyserini toolkit a3 experimental details of reranking methods datasets our experiments utilize the ms marco passage ranking dataset a substantial corpus designed for machine reading comprehension tasks this dataset comprises over 88 million passages and 1 million queries the training set contains approximately 398m tuples of queries paired with corresponding positive and negative passages while the development set comprises 6980 queries paired with their bm25 retrieval results and preserves the top1000 ranked candidate passages for each query we evaluate the effectiveness of the methods on the development set as the test set is not publicly available metrics the evaluation metrics mrr1 mrr10 mrr1k and hit rate10 are used mrr10 is the official metric proposed by ms marco implementation details we follow and make modifications to the implementation provided by pygaggle  26 and tilde  28 for dlmbased reranking we use monot5  26 based on t5base monobert  25 based on bertlarge and rankllama  27 based on llama27b for tilde reranking we use tildev2 29 based on bertbase typically 50 documents are retrieved as input for the reranking module the documents remaining after the reranking and repacking phase can be further concentrated by assigning a topk value or a relevancy score threshold result analysis reranking results are shown in table 9 we compare our results with a randomly shuffled ordering and the bm25 retrieval baseline all",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 3650,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "43d231d1-3f56-45e6-89f5-41c13164c658",
        "embedding": null,
        "metadata": {
            "page_label": "19",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "8810312f-2c72-4f71-a3bf-58e7c5f86095",
                "node_type": "4",
                "metadata": {
                    "page_label": "19",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "48b799c99658d393343064abc025d0e826f9b8fc095365f219bba7624235ffaa",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "0fbca574-e99b-4f1b-adef-6026b4b620c2",
                "node_type": "1",
                "metadata": {
                    "page_label": "19",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "f983b01cc43e05799bb737cdfd149d982f530e38d98e0b62c96083f593dc762e",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "the reranking and repacking phase can be further concentrated by assigning a topk value or a relevancy score threshold result analysis reranking results are shown in table 9 we compare our results with a randomly shuffled ordering and the bm25 retrieval baseline all reranking methods demonstrate a notable 9httpshuggingfacecohuggingfaceh4zephyr7balpha 19",
        "mimetype": "text/plain",
        "start_char_idx": 3384,
        "end_char_idx": 3739,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "2cb88009-da7c-40fa-b6fd-ac1b4403d34e",
        "embedding": null,
        "metadata": {
            "page_label": "20",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "c0a5ac0a-b527-458d-9ce3-e6460560347d",
                "node_type": "4",
                "metadata": {
                    "page_label": "20",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "21612556b231f50576b73381ce84b14bbbeb2cdcdab30e3ecdf2afeb25c64e68",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "b906ffee-7cdb-4ea7-8c2e-0f116d46863d",
                "node_type": "1",
                "metadata": {},
                "hash": "0e5b529f7ed866eb4845a35b6f33a3977524886310a3866a325c44270da2fe50",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "context model nq triviaqa hotpotqa asqa avg dmb 2978 60 44 23 73 37 89 37 96 mg 2623 5826 26 67 32 30 35 87 mr 3110 61 37 28 40 39 96 40 21 mgr 2592 57 62 26 43 32 99 35 70 mgg 2669 58 07 27 04 33 75 36 39 dgmb 4478 79 90 56 72 71 64 63 26 mg 8572 88 16 79 82 85 51 84 80 mr 6098 80 20 65 73 67 49 68 60 mgr 8760 87 94 8107 8758 8605 mgg 8672 8835 7959 83 44 84 53 drmb 1649 50 03 21 57 28 79 29 22 mg 2215 46 98 24 36 29 40 30 72 mr 3692 58 42 29 64 39 54 41 13 mgr 2363 45 01 24 17 27 95 30 19 mgg 2108 43 83 23 23 27 33 28 87 dgrmb 3465 81 27 52 75 65 42 58 52 mg 8500 87 33 78 18 83 02 83 38 mr 6028 79 32 63 82 67 29 67 68 mgr 8763 8714 79 95 8778 8563 mgg 8631 86 90 78 10 83 85 83 79 table 12 results of the model augmented with different contexts on various qa datasets increase in performance across all metrics approximately equal performance is achieved by monot5 and monobert and rankllama performs best each ascending in latency tildev2 is the fastest taking approximately 10 to 20 milliseconds per query at the cost of performance additionally tildev2 requires that the passages reranked be identically included in the previously indexed collection preprocessing must be redone at inference for new unseen passages negating the efficiency advantages a4 experimental details of summarization methods selective context selective context enhances llm efficiency by identifying and removing redundant information in the input context it evaluates the informativeness of lexical units using selfinformation computed by a base causal language model this method is nonquerybased allowing a comparison between querybased and nonquerybased approaches datasets we evaluated these methods on three datasets natural questions nq  57 trivi aqa 58 and hotpotqa 59 metrics evaluation metrics include the f1 score and the number of tokens changed after summa rization to measure conciseness implementation details for all methods we use llama38binstruct as the generator model and set a summarization ratio of 04 for extractive methods importance scores determine the sentences retained for abstractive methods we control the maximum generation length using the summarization ratio to align with extractive methods experiments are conducted on the nq test set triviaqa test set and hotpotqa development set a5 experimental details of generator finetuning datasets",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 2361,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "b906ffee-7cdb-4ea7-8c2e-0f116d46863d",
        "embedding": null,
        "metadata": {
            "page_label": "20",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "c0a5ac0a-b527-458d-9ce3-e6460560347d",
                "node_type": "4",
                "metadata": {
                    "page_label": "20",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "21612556b231f50576b73381ce84b14bbbeb2cdcdab30e3ecdf2afeb25c64e68",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "2cb88009-da7c-40fa-b6fd-ac1b4403d34e",
                "node_type": "1",
                "metadata": {
                    "page_label": "20",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "a3943ebe2fa58b34610d3209d1990b3748a4eabc943dc9a0ce231d0991836c9c",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "abstractive methods we control the maximum generation length using the summarization ratio to align with extractive methods experiments are conducted on the nq test set triviaqa test set and hotpotqa development set a5 experimental details of generator finetuning datasets we finetune our model on several question answeringqa and reading comprehension datasets including asqa  60 hotpotqa  59 narrativeqa  61 nq  57 squad  62 trivi aqa  58 truthfulqa  63 we use their train splits for those containing significantly more data 20",
        "mimetype": "text/plain",
        "start_char_idx": 2089,
        "end_char_idx": 2618,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "fcaab0d8-c255-4d9a-9dfa-5abc4ec2af75",
        "embedding": null,
        "metadata": {
            "page_label": "21",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "785528eb-20e6-45ca-bd61-2f0094460b6b",
                "node_type": "4",
                "metadata": {
                    "page_label": "21",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "aada94d317308090fa519e051e59da4ecba1f0d6c5a81b170779bd2756d6beb0",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "31e2f2c6-0d58-4b63-9213-76c780e24033",
                "node_type": "1",
                "metadata": {},
                "hash": "90d484be80e0fd2422eebd1e0703a08566622881f8836f135be0d7fc90aea4ce",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "instruction please generate ten descriptions for the continuation task context for example 1frenchwashington played a crucial role in the american revolutionary war leading the continental army against the british please continue writing the above paragraph 2the discovery of the double helix structure of dna by james watson and francis crick revolutionized the field of genetics laying the foundation for modern molecular biology and biotechnology please continue by discussing recent developments in genetic research such as crispr gene editing and their potential ethical implications table 14 template for generating task classification data entries than others we conducted a random sample for evaluation asqa  60 hotpotqa  59 nq  57 triviaqa  58 are used we evaluate our model on their validation splits or manually split a dataset train eval asqa 2090 483 hotpotqa 15000 7 405 triviaqa 9000 6 368 nq 15000 8 006 narrativeqa 7000  squad 6700  truthfulqa 817  table 13 number of examples in each dataset used in the finetuning experimentssubset from the training set to avoid overlapping the exact number of entries in each train and test set is detailed in table 13 we use the datasetprovided documents as dgold for each data entry to obtain drandom we sam ple the context of different entries within the same dataset to make sure the distributions of drandom anddgoldare roughly similar metrics we use the groundtruth coverage as our evaluation metric considering that the answers of qa tasks are relatively short while the generation length of the model is sometimes hard to limit implementation details we select llama27b  50 as the base model for efficiency we use lora  64 and int8 quantization during training the prompt templates used for finetuning and evaluation mainly follow lin et al 37 we train our generator for 3 epochs and constrain the maximum length of the sequence to 1600 using a batch size of 4 and a learning rate of 5e5 during testing we use a zeroshot setting detailed results table 12 shows our evaluation results on each dataset a6 experimental details of comprehensive evaluation tasks and datasets we conducted extensive experiments across various nlp tasks and datasets to assess the performance of rag systems specifically 1 commonsense reasoning  we evaluated on mmlu  65 arcchallenge  66 and openbookqa  67 datasets 2 fact checking  our evaluation encompassed the fever  68 and pubhealth  69 datasets 3 opendomain qa  we assessed on nq  57 triviaqa  58 and webquestions  70 datasets 4 multihop qa  our evaluation included the hotpotqa  59 2wikimultihopqa  71 and musique  52 datasets for musique we followed the approach outlined in  72 and focused solely on answerable 2hop questions 5 medical qa  we also assessed on the pubmedqa  73 dataset in each dataset we randomly subsample 500 entries from the test set for our experiments for datasets without test set we use develop set instead to assess rag capabilities we evenly collect a total of 500 entries from nq triviaqa hotpotqa 2wikimultihopqa and musique each entry is a question gold document gold answer triple metrics we use tokenlevel f1 score and em score for opendomain qa and multihop qa tasks and accuracy for others we use a more lenient em score which evaluates",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 3266,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "31e2f2c6-0d58-4b63-9213-76c780e24033",
        "embedding": null,
        "metadata": {
            "page_label": "21",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "785528eb-20e6-45ca-bd61-2f0094460b6b",
                "node_type": "4",
                "metadata": {
                    "page_label": "21",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "aada94d317308090fa519e051e59da4ecba1f0d6c5a81b170779bd2756d6beb0",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "fcaab0d8-c255-4d9a-9dfa-5abc4ec2af75",
                "node_type": "1",
                "metadata": {
                    "page_label": "21",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "a3a04fb940faeacc17ecb30ea5e6157a5fdef8a2d4a704357467e9d5cd4de654",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "and musique each entry is a question gold document gold answer triple metrics we use tokenlevel f1 score and em score for opendomain qa and multihop qa tasks and accuracy for others we use a more lenient em score which evaluates performance based on whether the model generations include gold answers instead of strictly exact matching 74 towards rag capabilities evaluation we adopt four metrics from ragas including faithfulness  context relevancy answer relevancy  and answer correctness  faithfulness measures how factually consistent the generated answer is with the retrieved context an answer is considered faithful if all claims made can be directly inferred from the provided context context relevancy evaluates how relevant the retrieved context is to the original query answer relevancy assesses the 21",
        "mimetype": "text/plain",
        "start_char_idx": 3038,
        "end_char_idx": 3851,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "132127ed-9d52-42bf-8916-032f3afcca70",
        "embedding": null,
        "metadata": {
            "page_label": "22",
            "file_name": "RAG_Best_Practices.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
            "file_type": "application/pdf",
            "file_size": 914162,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "1d7ffcf1-65a8-4d68-8643-4cd89aa4d028",
                "node_type": "4",
                "metadata": {
                    "page_label": "22",
                    "file_name": "RAG_Best_Practices.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\RAG_Best_Practices.pdf",
                    "file_type": "application/pdf",
                    "file_size": 914162,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "1deb0cc359c7d80630ebda04b4a22711e4db7843ef855cdfe9dbfc5f6f062f8b",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "pertinence of the generated answer to the original query answer correctness involves the accuracy of the generated answer when compared to the ground truth for example context relevancy is calculated from the proportion of sentences within the retrieved context that are relevant for answering the given question to all sentences context relevancy s total2 where sdenotes the number of relevant sentences totaldenotes the total number of sentences retrieved all these metrics are evaluated using the ragas framework with gpt4 serving as the judge additionally we compute the cosine similarity between the retrieved document and the gold document asretrieval similarity  the retrieved document and gold document are fed into an embedding model then the resulting embeddings are used to compute the cosine similarity implementation details for opendomain qa and multihop qa datasets we set the generation models maximum new token number to 100 tokens for other datasets we set it to 50 tokens to deal with excessively long retrieved documents we truncated the documents to 2048 words when evaluating rankllama and longllmlingua for all datasets we use greedy decoding during generation to better compare the capabilities of different rag modules we adopt the 0shot evaluation setting ie no incontext examples are offered in the multiple choice and fact checking tasks answers generated by the model may take a variety of forms eg the answer is a instead of a therefore we preprocess the responses generated by the model applying regular expression templates to match them with gold labels 22",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 1589,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "0add80d8-a6e4-4131-9a63-fe372a61c129",
        "embedding": null,
        "metadata": {
            "page_label": "1",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "73a24e42-1b4f-4f7d-9007-ab83fdc3e569",
                "node_type": "4",
                "metadata": {
                    "page_label": "1",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "94b94e353647a8e6d46febdce1be7940e26e4b64c7af65e9ba6a6e9e00f8e60a",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "4c25b32d-1570-4c99-bcc6-d7dd53f823ea",
                "node_type": "1",
                "metadata": {},
                "hash": "baff206c8f7e3892d1e90c215628e11ab6b79620dd756bdf240169a0f2353775",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "recursive introspection teaching language model agents howtoselfimprove yuxiao qu1 tianjun zhang2 naman garg3and aviral kumar1 1carnegie mellon university2uc berkeley3multion acentralpieceinenablingintelligentagenticbehaviorinfoundationmodelsistomakethemcapableofintrospecting upon their behavior reasoning and correcting their mistakes as more computation or interaction is available even the strongest proprietary large language models llms do not quite exhibit the ability of continually improving their responses sequentially even in scenarios where they are explicitly told that they are making a mistake in this paper we develop riserecursiveintrospection an approach for finetuning llms to introduce this capability despite prior work hypothesizing that this capability may not be possible to attain our approach prescribes an iterative finetuning procedure which attempts to teach the model how to alter its response after having executed previouslyunsuccessfulattemptstosolveahardtesttimeproblemwithoptionallyadditionalenvironmentfeedback rise poses finetuning for a singleturn prompt as solving a multiturn markov decision process mdp where the initial state is the prompt inspired by principles in online imitation learning and reinforcement learning we propose strategies for multiturn data collection and training so as to imbue an llm with the capability to recursively detect and correct its previous mistakes in subsequent iterations our experiments show that rise enables llama2 llama3 and mistral models to improve themselves with more turns on math reasoning tasks outperforming several singleturn strategies given an equal amount of inferencetime computation we also find that rise scales well often attaining larger benefits with more capable models our analysis shows that rise makes meaningful improvements to responses to arrive at the correct solution for challenging prompts without disrupting oneturn abilities as a result of expressing more complex distributions 1 introduction a promising approach to utilizing and deploying foundation models and in particular large language models llms is to treat them as generalpurpose decisionmaking machines or agents to be successful an llm agent must not just provide plausible completions for input text but must exhibit interactive goaldirected behavior to accomplish a given task put in abstract terms this requires mastering two qualities aproducing responses that explicitly seek information about the task followed bybmaking decisions and improving them by thinking and verifying them at inference time for instance tosucceedinusinganewcodinglibrary aneffectivellmagentshouldfirstsynthesizeprograms then try the most promising subset against a compiler use the resulting feedback to improve the program and repeat the process for multiple turns having the ability to successfully improve a response in sequential attempts is equivalent to a form of selfimprovement at test time to enable testtime selfimprovement recent approaches attempt to repurpose the knowledge already stored in pretrained models via fewshot prompting  715315264 although prompt tuning in conjunction with feedback is effective in eliciting improved responses from capable models it fails to produce models that can succeed in complex tasks by correcting their own mistakes such as those that require logical reasoning  2155 in many of these problems models contain the knowledge needed to answer a challenging prompt but are not able to elicit that knowledge even when asked to sequentially correct their mistakes finetuning the llm on domainspecific questionanswering data  62939 can help but it still does not teach the agent a testtime improvement strategy see section 6 a strategy for corresponding authors yuxiaoqandrewcmuedu this work was done at carnegie mellon universityarxiv240718219v2 cslg 26 jul",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 3856,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "4c25b32d-1570-4c99-bcc6-d7dd53f823ea",
        "embedding": null,
        "metadata": {
            "page_label": "1",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "73a24e42-1b4f-4f7d-9007-ab83fdc3e569",
                "node_type": "4",
                "metadata": {
                    "page_label": "1",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "94b94e353647a8e6d46febdce1be7940e26e4b64c7af65e9ba6a6e9e00f8e60a",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "0add80d8-a6e4-4131-9a63-fe372a61c129",
                "node_type": "1",
                "metadata": {
                    "page_label": "1",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "95926190fe9d8dfd1e4119c0a906feb1f7602fa62c03e1dffba57710458a395a",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "teach the agent a testtime improvement strategy see section 6 a strategy for corresponding authors yuxiaoqandrewcmuedu this work was done at carnegie mellon universityarxiv240718219v2 cslg 26 jul 2024",
        "mimetype": "text/plain",
        "start_char_idx": 3661,
        "end_char_idx": 3861,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "4803218b-1d52-47f9-89d7-3937e97f8b0f",
        "embedding": null,
        "metadata": {
            "page_label": "2",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "fb55cb81-499e-49a9-b188-86f537bc7f10",
                "node_type": "4",
                "metadata": {
                    "page_label": "2",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "13044208093bb7137ecfe8141fdde0ec091f081df63c118575deceae8c0bde7c",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "recursive introspection teaching language model agents howtoselfimprove figure1recursive introspection rise using iterative multiround training on onpolicy rollouts and supervision from a reward function rise trains models that are capable of improving themselves over multiple turns at inference we run majority voting on candidate outputs from different turns to obtain the final response improving responses over sequential attempts at test time is crucial for tackling challenging prompts where directly attempting the problem in one shot may largely be futile can we train models to be capable of improving their ownresponses if done correctly and on a diverse set of problems and scenarios this could introduce in an llm a general procedure for howit can tackle a hard prompt by improving itself as opposed to supervising it with what to respond with which may not generalize as the test prompt becomes out of distribution although one straightforward approach to inducing this capability into a model would be to generate data that showcase improvements over multiple sequential turns potentially from highly capable models we find that simply imitating these data is not sufficient to enable this capability section 64 quite well this is due to two reasons first multiturn data from a different model would not show improvements in the kinds of errors the learner would make thereby being irrelevant to the learner  24 second often sequential multiturn data collected from proprietary models is also not of high quality since these models are typically not good at proposing meaningful improvements to their own errors  21 even though they can still provide useful responses to the problem at hand therefore we need a different strategy to endow models with a selfimprovement capability our key insight is to supervise improvements to the learners own responses in an iterative fashion taking inspiration from methods in online imitation learning  36 and reinforcement learning rl  45 this supervision can be in the form of oracle responses to the prompt sampled iid from more capable models or be generated from the learner itself our contribution is an algorithm rise recursive introspection figure 1 that utilizes these insights to improve the selfimprovement capability of an llm over the course of multiple attempts at a given prompt in each iteration our approach bootstraps onpolicy rollouts from the learner with better responses at the next turn obtained by running bestofn using a success indicator on the task on multiple revision candidates obtained by sampling from the learner itself or using responses from a more capable model whichever is more convenient in this way we are able to construct rollouts that demonstrate the learner how it can improve its responses under its own distribution then we finetune the learner on these data using a rewardweighted regression rwr  3435 objective that is able to learn from both high and lowquality parts of such rollouts by iteratively repeating this procedure we are able to instill a general selfimprovement capability into an llm our results show that llms trained via rise can produce correct responses on more prompts improving over turns for more challenging prompts even though strong base and intructiontuned llms  2358 often fail to improve their responses over multiplesequentialattemptsevenwhenexplicitlytoldabouttheirmistakespreviously risesuccessfully 2",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 3432,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "1ff7e00c-8f4d-4e69-ba6b-85806f9a6d73",
        "embedding": null,
        "metadata": {
            "page_label": "3",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "16998841-b717-49a7-8ddb-b39e65e4798f",
                "node_type": "4",
                "metadata": {
                    "page_label": "3",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "1a8e30571f00d52d7ce6174c1bf2fd980e3f12349c77c82a47c6ebaabc3e27b2",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "8b2bcbf8-df29-4e1e-b2d4-34c3565e14a3",
                "node_type": "1",
                "metadata": {},
                "hash": "e665af3cfafb7b26ef29d696f83ee625a1510c98cc4aacf0802b4d14b72ee152",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "recursive introspection teaching language model agents howtoselfimprove endows similarlysized llms with selfimprovement capabilities resulting in monotonically increasing task performance after each turn specifically on the gsm8k  11 dataset rise demonstrates significant improvement over various models rise improves the performance of llama38b by 82 and mistral7b by 66 entirely using their own data rise attains a 177 improvement for llama27b over the course of 5turn introspection outperforming parallel sampling from the first turn and a 239 improvement for mistral7b in contrast gpt35 itself only improves by 46 over five turns we see similar trends on the math dataset  18 where rise improves llama27b by 46 and mistral7b by 111 over five turns we also study why and how rise is able to induce selfimprovement abilities and show that this ability generalizes to outofdistribution prompts as well these results consistently demonstrate rises effectiveness in enhancing mathematical reasoning capabilities for different models 2 related work several prior works build techniques to improve reasoning and thinking capabilities of foundation models for downstream applications typically these works focus on building prompting techniques for effective multiturn interaction with external tools  571432495456 sequentially refining predictions by reflecting on actions  71563 asking the model to verbalize its thoughts  335265 asking the model to critique and revise itself  3140 or by using other models to critique a primary models responses  2122054 although a subset of this work does improve its own responses this selfcorrection ability often requires access to detailed error traces eg execution traces from code compilers  731 in order to succeed in fact  21 and table 1 both indicate that selfimprovement guided by the llm itself ie intrinsic selfcorrection is often infeasible for offtheshelf llms even when they contain the knowledge required to tackle the prompt given but finetuning with rise induces this capability as we show in this paper beyond prompting previous work also attempts to finetune llm to obtain selfimprovement capabili ties 63962 these works attempt to improve reasoning performance by training on selfgenerated responses  3046575860 to achieve this these works use a combination of learned verifiers  28 4750 search  13263338 contrastive prompting on negative data  948 and iterated supervised or reinforcement learning rl  83759 although our approach also trains on modelgenerated data we aim to introduce a complementary capability to improve performance over sequential turns of interaction rather than to improve singleturn performance alone other work finetunes llms for multiturn interaction directly via rl 41 66 while this is indeed related singleturn problems posed in multiturn scenarios require addressing distinct challenges than generic multiturn rl isample efficiency is not a concern since the entire environment is fully characterized by the training dataset of prompts and oracle answers and dynamics are deterministic and iiwe need to generalize to novel test prompts multiturn rl focuses on sample efficiency which is not as critical in our setting though of course learning to generalize from a limited number of initial states would be appealing our main focus is to show that it is possible to train models for selfimprovement via appropriately designing multiturn finetuning objectives this is orthogonal from the choice of training approach rl or not the most related to our work are glore  17 and selfcorrect  53 which train separate models to identify errors and refine incorrect answers of other llms unlike these works our approach trains a",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 3702,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "8b2bcbf8-df29-4e1e-b2d4-34c3565e14a3",
        "embedding": null,
        "metadata": {
            "page_label": "3",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "16998841-b717-49a7-8ddb-b39e65e4798f",
                "node_type": "4",
                "metadata": {
                    "page_label": "3",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "1a8e30571f00d52d7ce6174c1bf2fd980e3f12349c77c82a47c6ebaabc3e27b2",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "1ff7e00c-8f4d-4e69-ba6b-85806f9a6d73",
                "node_type": "1",
                "metadata": {
                    "page_label": "3",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "336c1c54455701b64baebc1e1cb56a184253fd2d03dab289de8633762c2c2c2c",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "orthogonal from the choice of training approach rl or not the most related to our work are glore  17 and selfcorrect  53 which train separate models to identify errors and refine incorrect answers of other llms unlike these works our approach trains a single model to produce answers and improve them over more than two turns which is the maximal number of turns studied in these works we show that doing so successfully requires careful design choices an iterative onpolicy data generation strategy along with a training objective that can learn from both successful and unsuccessful rollouts from an algorithmic point of view rise is similar to online 3",
        "mimetype": "text/plain",
        "start_char_idx": 3451,
        "end_char_idx": 4106,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "1f135688-d5f8-4969-8931-ea0266203a14",
        "embedding": null,
        "metadata": {
            "page_label": "4",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "44bcde6c-d509-4947-868c-5ea93e16bdab",
                "node_type": "4",
                "metadata": {
                    "page_label": "4",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "3e8c5713d88aa10a538f07ecae8bb555b6f0e1008fd5d9dbee026174c5d4a6f0",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "b7e37b4b-bc17-4623-9049-23303b4bf421",
                "node_type": "1",
                "metadata": {},
                "hash": "051e0ed32f883fb07c68c74464036b3ecd4614d00c6fa158472306fd908ff4b4",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "recursive introspection teaching language model agents howtoselfimprove imitation learning  3644 in that it queries expert supervision on states attained by onpolicy rollouts onpolicy distillation for llms  14 utilizes this idea but queries an expert to provide completions on partial responses instead of sequential attempts that we do in this work 3 problem setup and preliminaries the goal of our work is to improve llm performance over sequential attempts  turns at a given problem concretely given a dataset \ud835\udc9f\ud835\udc65\ud835\udc56\ud835\udc66 \ud835\udc56\ud835\udc41 \ud835\udc561of problems \ud835\udc65\ud835\udc56and oracle responses \ud835\udc66 \ud835\udc56 our goal is to obtain an llm \ud835\udf0b\ud835\udf03\ud835\udc65\u02c6\ud835\udc661\ud835\udc61 \ud835\udc5d1\ud835\udc61that given the problem \ud835\udc65 previous model attempts \u02c6\ud835\udc661\ud835\udc61at the problem and auxiliary instructions \ud835\udc5d1\ud835\udc61eg instruction to find a mistake and improve the response or additional compiler feedback from the environment solves a given problem as correctly as possible to this end we encode this goal into the following learning objective that we wish to optimize max \ud835\udf0b\ud835\udf03\ud835\udc3f \ud835\udc561e\ud835\udc65\ud835\udc66\ud835\udc9f\ud835\udc66\ud835\udc56\ud835\udf0b\ud835\udf03\ud835\udc65\ud835\udc661\ud835\udc561\ud835\udc5d1\ud835\udc561i\u02c6\ud835\udc66\ud835\udc56\ud835\udc66 31 unlike standard supervised finetuning that trains the model \ud835\udf0bto produce a single response \u02c6\ud835\udc66given \ud835\udc65 equation 31 trains \ud835\udf0bto also appropriately react to a given history of responses from its own previous attempts \u02c6\ud835\udc661\ud835\udc561 equation 31 most closely resembles an rl objective and we will indeed develop our approach by converting a singleturn problem into a multiturn mdp finally note that promptingbased methods such as selfrefine  31 can still be viewed as training \ud835\udf0bto optimize \ud835\udf0b\ud835\udc66\ud835\udc65but only when only allowed to modulate the prompt \ud835\udc5d\ud835\udc56to optimize equation 31 naturally since the parameters \ud835\udf03are unchanged this would not be effective in optimizing the objective fully 4 rise recursive introspection for selfimprovement since even strong offtheshelf models do not exhibit an effective ability to improve themselves when provided with sequential attempts at a given problem  21 a natural next step is to ask how to train models to induce this capability in this section we will develop our approach rise for finetuning foundation models towards improving their own predictions over multiple turns our approach will first convert a problem into a multiturn mdp then collect data and finally run offline rewardweighted supervised learning in this multiturn mdp to induce this capability figure2left problem formulation we convert singleturn problems into multiturn mdps as discussed in section 41 the state is given by the prompt history of prior attempts and optional feedback from the environment an action is a response generated from the llm given the state of multiturn interaction so far right data collection we collect data by unrolling the current model \ud835\udc581times followed by an improved version of the response which is obtained by either 1 selfdistillation  sample multiple responses from the current model and use the best response or 2 distillation  obtain oracle responses by querying a more capable",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 2889,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "b7e37b4b-bc17-4623-9049-23303b4bf421",
        "embedding": null,
        "metadata": {
            "page_label": "4",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "44bcde6c-d509-4947-868c-5ea93e16bdab",
                "node_type": "4",
                "metadata": {
                    "page_label": "4",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "3e8c5713d88aa10a538f07ecae8bb555b6f0e1008fd5d9dbee026174c5d4a6f0",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "1f135688-d5f8-4969-8931-ea0266203a14",
                "node_type": "1",
                "metadata": {
                    "page_label": "4",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "578fb17f6120b65d0bc3c2540f7e5f77cad4c7e2a6323a9d980232dc736717b8",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "\ud835\udc581times followed by an improved version of the response which is obtained by either 1 selfdistillation  sample multiple responses from the current model and use the best response or 2 distillation  obtain oracle responses by querying a more capable model in either case rise then trains on the generated data 4",
        "mimetype": "text/plain",
        "start_char_idx": 2641,
        "end_char_idx": 2951,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "ec6443e7-2df8-419a-bec0-6465ed2e01eb",
        "embedding": null,
        "metadata": {
            "page_label": "5",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "907bb34d-64c2-465d-a132-988ccb9130a4",
                "node_type": "4",
                "metadata": {
                    "page_label": "5",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "be63633387b8ad7f36e9f9acc09e3e78c961e4f113e762564f123c8f0b7ea3fc",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "823c69ab-73d6-4cc4-8986-91db3e82e69a",
                "node_type": "1",
                "metadata": {},
                "hash": "1fbdd36975bde970bb13e02c1db85ee2825fbce60876fae444eaf3f53e1aa9bb",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "recursive introspection teaching language model agents howtoselfimprove 41 converting singleturn problems into a multiturn markov decision process mdp the first step in building our approach is to procedurally construct a multiturn mdp out of a singleturn dataset of prompts and oracle responses figure 2 left given a dataset \ud835\udc9f\ud835\udc65\ud835\udc56\ud835\udc66 \ud835\udc56 consisting of prompts \ud835\udc65\ud835\udc56and corresponding oracle responses \ud835\udc66 \ud835\udc56eg math questions and natural language responses to those questions we will construct an induced mdp\u2133from\ud835\udc9f and then learn policies in this mdp an initial state in this mdp is a possible prompt \ud835\udc65\ud835\udc56\ud835\udc9f we denote the output response from the foundation model as action \ud835\udc4e given a state \ud835\udc60 the next state can be obtained by concatenating the tokens representing \ud835\udc60with the action \ud835\udc4eproposed by the model and an additional fixed prompt \ud835\udc53that asks the model to introspect eg this response is not correct please introspect and correct your answer the exact prompt is shown in appendix d4 the reward function is a sparse binary indicator of answer correctness at a given state \ud835\udc60\ud835\udc5f\ud835\udc65\ud835\udc56\ud835\udc4e  1if and only if \ud835\udc4e\ud835\udc66 \ud835\udc56and is obtained from an answer checking function this construction from dataset \ud835\udc9fto mdp\u2133is shown below \ud835\udc9f\ud835\udc65\ud835\udc56\ud835\udc66 \ud835\udc56  \u2133 \ud835\udf0c\ud835\udc600 unif\ud835\udc651\ud835\udc652\ud835\udc65\ud835\udc41 41 \ud835\udc43\ud835\udc60\ud835\udc60\ud835\udc4e \ud835\udeff \ud835\udc60concat \ud835\udc60\ud835\udc4e\ud835\udc53 42 \ud835\udc5f\ud835\udc60\ud835\udc4e 1\ud835\udc4e\ud835\udc66 \ud835\udc56if\ud835\udc65\ud835\udc56\ud835\udc60 43 42 learning in the multiturn mdp with the mdp construction in place the next step involves training a model to improve itself over the course of a rollout we subscribe to an offline approach to learning that we describe in the following step 1 data collection for selfimprovement to ensure that rollout data from this multiturn mdp is useful for teaching the model how to selfimprove it must satisfy a few desiderata 1it must illustrate the mistakes that the learner is likely to make and showcase how to improve upon them in the next attempt 2the data must illustrate responses that are relevant to the model given the problem and previous attempts in context and 3it must not contain any rollout that degrades in a subsequent turn our data collection strategy figure 2 right satisfies these desiderata in a given round \ud835\udc58 for a given problem \ud835\udc65\ud835\udc56 we unroll the currentmodel \ud835\udf0b\ud835\udf03\ud835\udc58to produce multiple sequential attempts denoted by \ud835\udc66\ud835\udc56 \ud835\udc61\ud835\udf0b\ud835\udf03\ud835\udc58\ud835\udc60\ud835\udc56 \ud835\udc61 in problems where external input eg compiler feedback is available we also observe a variablelength natural language external input \ud835\udc53\ud835\udc56 \ud835\udc61eg in mathproblemsweaskthemodeltocorrectitself wealsoobserveascalarrewardvalue \ud835\udc5f\ud835\udc60\ud835\udc56 \ud835\udc61\ud835\udc66\ud835\udc56 \ud835\udc61denoted",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 2425,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "823c69ab-73d6-4cc4-8986-91db3e82e69a",
        "embedding": null,
        "metadata": {
            "page_label": "5",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "907bb34d-64c2-465d-a132-988ccb9130a4",
                "node_type": "4",
                "metadata": {
                    "page_label": "5",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "be63633387b8ad7f36e9f9acc09e3e78c961e4f113e762564f123c8f0b7ea3fc",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "ec6443e7-2df8-419a-bec0-6465ed2e01eb",
                "node_type": "1",
                "metadata": {
                    "page_label": "5",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "2b1821ecdc13361344b6af8620b46ab4acfa10b782a046bb5f7db24b530e4f10",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "\ud835\udc61eg in mathproblemsweaskthemodeltocorrectitself wealsoobserveascalarrewardvalue \ud835\udc5f\ud835\udc60\ud835\udc56 \ud835\udc61\ud835\udc66\ud835\udc56 \ud835\udc61denoted as\ud835\udc5f\ud835\udc56 \ud835\udc61in short let us denote this dataset of onpolicy model rollouts as \ud835\udc9fonpolicy \ud835\udc60\ud835\udc56 \ud835\udc61\ud835\udc66\ud835\udc56 \ud835\udc61 \ud835\udc53\ud835\udc56 \ud835\udc61 \ud835\udc5f\ud835\udc56 \ud835\udc61\ud835\udc47 \ud835\udc611 for each timestep we construct an improved version of the response \ud835\udc66\ud835\udc56 \ud835\udc61that we will denote by \ud835\udc66\ud835\udc56 \ud835\udc61 we also record the reward score associated with this improved response as \ud835\udc5f\ud835\udc60\ud835\udc56 \ud835\udc61\ud835\udc66\ud835\udc56 \ud835\udc61 or\ud835\udc5f\ud835\udc56 \ud835\udc61in short to obtain an improved version of a response \ud835\udc66\ud835\udc56 \ud835\udc61 we can employ several strategies perhaps the most straightforward approach is to query an offtheshelf more capable model to provide a correct response given the prompt \ud835\udc65\ud835\udc56 the previous response \ud835\udc66\ud835\udc56 \ud835\udc61 and an optional external feedback \ud835\udc53\ud835\udc56 \ud835\udc61 we refer to this as the distillation variant of our approach since it uses a strong teacher model to guide selfimprovement note that this is different from the classic notion of knowledge distillation and we will in fact show results in section 61 that will help understand the differences \ud835\udc9fonpolicy  distill  \ud835\udc60\ud835\udc56 \ud835\udc61\ud835\udc66\ud835\udc56 \ud835\udc61 \ud835\udc53\ud835\udc56 \ud835\udc61\ud835\udc5f\ud835\udc56 \ud835\udc61\ud835\udc47 \ud835\udc611\ud835\udc9f \ud835\udc561 44 5",
        "mimetype": "text/plain",
        "start_char_idx": 2329,
        "end_char_idx": 3355,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "ed83d05f-3ce2-4b10-a5bc-7ae77ec4da82",
        "embedding": null,
        "metadata": {
            "page_label": "6",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "ab0805bb-ebf2-4370-aef4-7d093a58b00e",
                "node_type": "4",
                "metadata": {
                    "page_label": "6",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "30cad2e9da6de3c524d1adc7680783860ebc0a90d7aeeb23480afcc8f330577f",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "24fae848-0d0f-470f-9477-3f49114269a1",
                "node_type": "1",
                "metadata": {},
                "hash": "a51c47f57eea09c1f074611f6359ba02cd529fbabbe9da22148277aab3042114",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "recursive introspection teaching language model agents howtoselfimprove the second variant of our approach which alleviates the need for a teacher model involves constructing an improved response by sampling multiple times from the learner itself we refer to this approach as the selfdistillation variant concretely for each state in the dataset \ud835\udc60\ud835\udc56 \ud835\udc61\ud835\udc9fonpolicy we sample \ud835\udc41responses \ud835\udc66\ud835\udc56 \ud835\udc610\ud835\udc66\ud835\udc56 \ud835\udc611\ud835\udc66\ud835\udc56 \ud835\udc61\ud835\udc41\ud835\udf0b\ud835\udf03\ud835\udc60\ud835\udc56 \ud835\udc61 and use the best response from these \ud835\udc41candidates as measured by the associated reward values \ud835\udc5f\ud835\udc56 \ud835\udc610\ud835\udc5f\ud835\udc56 \ud835\udc61\ud835\udc41 to relabel the model response at the next step \ud835\udc61 1in an improvement trajectory formally say \ud835\udc66\ud835\udc56 \ud835\udc61\ud835\udc5a  arg max \ud835\udc57\ud835\udc41\ud835\udc5f\ud835\udc60\ud835\udc56\ud835\udc66\ud835\udc56 \ud835\udc61\ud835\udc57 then we label the responses in the dataset\ud835\udc9fonpolicyat step \ud835\udc61 1with the improved response and its associated reward value \ud835\udc5f\ud835\udc56 \ud835\udc61\ud835\udc5a \ud835\udc9fonpolicy  selfdistillation  \ud835\udc60\ud835\udc56 \ud835\udc611\ud835\udc66\ud835\udc56 \ud835\udc61\ud835\udc5a \ud835\udc53\ud835\udc56 \ud835\udc611\ud835\udc5f\ud835\udc56 \ud835\udc61\ud835\udc5a\ud835\udc471 \ud835\udc610\ud835\udc9f \ud835\udc561 45 step 2 policy improvement with the aforementioned data construction schemes we can now train a model on these datasets while in general any offline rl approach can be used to train on these data in our experiments we adopt an approach based on weighted supervised learning  35 due to ease of experimentation and its simplicity in particular we perform a weighted supervised regression where the weights are given by the exponential transformation of the reward values in \ud835\udc9f rewardweighted rl max \ud835\udf03e\ud835\udc65\ud835\udc56\ud835\udc9f\ud835\udc47 \ud835\udc611log\ud835\udf0b\ud835\udf03\ud835\udc66\ud835\udc56 \ud835\udc61\ud835\udc60\ud835\udc56 \ud835\udc61exp\ud835\udc5f\ud835\udc61 \ud835\udc56\ud835\udf0f  46 where \ud835\udf0fis a temperature parameter to further expand or narrow the difference between good and bad actions in our preliminary experiments we found that equation 46 can often induce a bias towards increasing log likelihoods of responses where rewards are high prioritizing updates on easy problems where rewards are already high to address this issue we apply a slight modification to equation 46 and center the exponentiated rewards around the mean value averaged across all attempts on a given prompt akin to advantageweighted regression  34 we find that the use of advantages in place of rewards helps us avoid the richgetsricher phenomenon with easy problems 43 inference at deployment time rise can be run in two modes at inference time perhaps the most straightforward way to run the policy \ud835\udf0b\ud835\udf03trained by rise is within a multiturn rollout where the model samples a new response conditioned on the past context ie state in the multiturn mdp this past context consists of the external feedback \ud835\udc5dtest \ud835\udc56concerning the response \ud835\udc66test \ud835\udc56and the rollout terminates as soon as the current response is judged",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 2447,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "24fae848-0d0f-470f-9477-3f49114269a1",
        "embedding": null,
        "metadata": {
            "page_label": "6",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "ab0805bb-ebf2-4370-aef4-7d093a58b00e",
                "node_type": "4",
                "metadata": {
                    "page_label": "6",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "30cad2e9da6de3c524d1adc7680783860ebc0a90d7aeeb23480afcc8f330577f",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "ed83d05f-3ce2-4b10-a5bc-7ae77ec4da82",
                "node_type": "1",
                "metadata": {
                    "page_label": "6",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "271726ea4142b7854faf4e1be0507199e7cae8b95b9c206baf4b75b83355b84d",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "the past context ie state in the multiturn mdp this past context consists of the external feedback \ud835\udc5dtest \ud835\udc56concerning the response \ud835\udc66test \ud835\udc56and the rollout terminates as soon as the current response is judged to be correct according to the environments answer verification function put in other words we terminate the rollout as soon as the reward is equal to the reward for the oracle response \ud835\udc5f\ud835\udc65\ud835\udc66test \ud835\udc56 \ud835\udc5f\ud835\udc65\ud835\udc66 this protocol invokes queries to the reward function after each turn in the rollout since several reward function queries are performed we refer to this approach as with oracle  rise can also be run in a mode that avoids the need to query the answer checker or the reward function within a rollout in this case we run fulllength rollouts by forcing the model to retry ignoring the correctness of the response we then utilize a selfconsistency mechanism  51 based on majority voting to decide the candidate response at the end of each turn concretely at the end of each turn \ud835\udc57 we identify the response by running a majority vote over all response candidates from the previous turns maj \ud835\udc66test 1\ud835\udc66test 2\ud835\udc66test \ud835\udc57  including turn \ud835\udc57 we call this without oracle  a schematic illustration of these approach is shown in figure 3 most of our evaluations use no oracle 6",
        "mimetype": "text/plain",
        "start_char_idx": 2242,
        "end_char_idx": 3505,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "125c9f27-fe14-414e-b468-94670e41cbf9",
        "embedding": null,
        "metadata": {
            "page_label": "7",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "598db97f-704f-4d3a-aef9-4c3624820420",
                "node_type": "4",
                "metadata": {
                    "page_label": "7",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "d9bae1b9f25ae9ba8881942a79bf050e5cbc07c5903a082d6128d87acb780bfd",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "recursive introspection teaching language model agents howtoselfimprove figure3rise inference there are two ways to query the model trained via rise upon inference 1 with oracle  left each time the model improves its response it is allowed to check its answer against an environment and terminate early as soon as a correct answer is found or 2 without oracle  right we ask the model to sequentially revise its own responses j times and perform majority voting on all candidate outputs from different turns to obtain the final response if the turn number \ud835\udc57is larger than the iteration number \ud835\udc58 the agent only keeps the most recent history with \ud835\udc58interactions to avoid testtime distribution shift at iteration \ud835\udc58 since the agent is able to improve its own response from \ud835\udc57to\ud835\udc57 1when \ud835\udc57\ud835\udc58 to avoid test time distribution shift in both modes we use a size \ud835\udc58shift window to store the most recent conversation history when the turn number \ud835\udc57is larger than the iteration number \ud835\udc58 44 practical algorithm and implementation details a complete algorithmic pseudocode for each approach is shown in appendix c we trained 7b models via rise and found that these models often could not adhere to response style and instructions for improving their responses when generating onpolicy data as a result before running onpolicy data collection we find it often useful to run an initial phase of supervised finetuning on indomain multiturn rollouts generated from a capable model to provide style and instructionfollowing information to the learner we call this the knowledge boosting stage we then run onpolicy rollouts starting from a boosted model in each iteration we generate 1 trajectory for each unique problem we then run finetuning with hyperparameters and details in appendix d for iterative finetuning we find that starting from the basemodel but training on data from all iterations thus far is more beneficial than continued finetuning from the checkpoint obtained in the previous iteration 5 when and why is selfimprovement over turns possible a natural question to ask is why selfimprovement with riseeven possible one might surmise that the model may simply not have enough knowledge to correct its ownmistakes if it is unable to correctly answer the problem in the first turn then why is it possible to teach the model to correct its own mistakes in this section we provide the reason why this kind of selfimprovement is possible supported with empirical evidence to justify our hypotheses iteratively teaching a model how to make updates on a given response can be crucial when representing the target distribution \ud835\udc5d\ud835\udc66\ud835\udc65requires more capacity than what the model \ud835\udf0b\ud835\udf03affords by conditioning on only the input prompt tokens when the target distribution requires greater capacity learning a sequence of conditionals \ud835\udf0b\ud835\udf03\ud835\udc66\ud835\udc561\ud835\udc65\ud835\udc660\ud835\udc56followed by marginalization is expected to induce a more 7",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 2870,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "6bfd75f7-2502-4a97-a7ca-0cd6364f2b9a",
        "embedding": null,
        "metadata": {
            "page_label": "8",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "8ba08bc2-f556-40ff-807f-17ed258f6d93",
                "node_type": "4",
                "metadata": {
                    "page_label": "8",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "a9bb864fe9d4afc3a16a6b00b764acaf05e8668fd0572e42eccb78cc3f44c7be",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "recursive introspection teaching language model agents howtoselfimprove figure4the probability of the true answer given the prompt observe that model trained with rise has higher probability for the true answer figure5the training perplexity loss of fitting only the oracle answer or a sequence of answers observe that fitting a sequence of answers rise reduces the loss more than fitting only the oracle answer classic flexible marginal distribution over \ud835\udc66\ud835\udc47given \ud835\udc65 this hypothesis is akin to the difference between diffusion models  42 and variational autoencoders vaes  25 in image generation iteratively fitting a sequence of generative distributions over intermediate noisy inputs in a diffusion model gives rise to a more flexible distribution  43 than monolithic variational autoencoding even though diffusion models still utilize an evidence lowerbound objectiveelbo while the diffusion process utilizes handdesigned noise schedules rise utilizes the base model itself to induce iterative improvements to verify if this hypothesis is true we tracked the training unweighted negative loglikelihood loss nll values for the oracle response \ud835\udc66given the input prompt \ud835\udc65marginalized over intermediate steps in a multiturn rollout and compared it against the nll values log\ud835\udc5d\ud835\udf03\ud835\udc66\ud835\udc65attained by directly attempting to predict the final response in figure 4 labeled as classic concretely we sampled 256 prompts \ud835\udc65 and their oracle responses \ud835\udc66and computed the average log\ud835\udc5d\ud835\udf03\ud835\udc66\ud835\udc65across all \ud835\udc65 along with a 95 confidence interval for different checkpoints during training we find that for any given number of epochs including fractional number of epochs on the xaxis the nll value is lower when conditioning on multiturn data that rise generates in comparison with oracle responses to the prompts obtained from an expert this suggests that rise is able to utilize the computation of tokens from previous turns to model the target distribution we also measure the average nll loss on all samples through training sampled iid from the training dataset for rise and classic finetuning and observe a similar trend rise is able to reduce loss more than the standard approach attaining lower perplexity values figure 5 of course in problems that require knowledgebased question answering it is not possible for the model to produce any meaningful improvements because learning \ud835\udc5d\ud835\udc66\ud835\udc65is not bounded by insufficient capacity of \ud835\udf0b\ud835\udf03\ud835\udc66\ud835\udc65 but is rather unable to match \ud835\udc5ddue to the absence of features that are critical to learn the correct mapping from \ud835\udc65to\ud835\udc66 we expect that training with rise would only incentivize hallucinations in this case  24 since more input tokens appearing from previous attempts would only provide easier ways to pick up on spurious correlations however this is not the failure mode on reasoning problems  27 where majk rates at turn 1 tend to be higher than pass1 as we find in our experiments indicating that performance can be improved by sampling the model itself in fact in figure 6 we also show that the sequential procedure learned by rise can even solve a significant fraction of problems that were unsolved by passb for much larger \ud835\udc35in the first turn indicating that it learns to index into the 8",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 3196,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "f6a2b0a5-5023-4c02-9c7b-a6425b268dbb",
        "embedding": null,
        "metadata": {
            "page_label": "9",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "664c06fd-0c59-4b3f-aed0-7cbd18610e0f",
                "node_type": "4",
                "metadata": {
                    "page_label": "9",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "fed98f790e692f28589a633093fd9193e0df4a7d9ceeced3202b53ea081d9910",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "recursive introspection teaching language model agents howtoselfimprove pretrained knowledge of the model in a different manner as opposed to simply translating the passk performance into the pass1 performance of the model that majority of singleturn approaches are believed to be doing figure6fraction of problems unsolved by passb at the first turn that sequential 5turn sampling from rise solves where \ud835\udc35 5\ud835\udc58\ud835\udc58is the xaxis rise can solve several challenging problems that sampling at the first turn with much larger budgets cannot solve 6 experimental evaluation the goal of our experiments is to demonstrate the efficacy of rise in instilling language models with the ability to selfimprove their responses over turns our experiments answer the following questions 1 how effectively can rise improve performance over multiple sequential attempts ie turns at a given prompt 2does the performance of rise improve with more rounds of iterative training 3does the selfimprovement strategy induced by rise generalize to novel problems that are out of the training domain and finally 4what is the best data composition for training rise to this end we compare rise to other prior and baseline approaches and perform ablations on gsm8k 11 and math 18 baselines comparisons and evaluation we compare rise to several prior methods that attempt to induce similar selfimprovement capabilities a selfrefine 2131 that prompts a base model to critique and revise its mistakes b glore 17 which trains a separate reward model to locate errors and a refinement model to improve responses of a base llm and c selfconsistency 51 which runs majority voting on multiple responses from the first turn as a baseline to compare to our sequential strategy we tried to construct fair comparisons between rise and these methods by using a similarsized model  2358 but differences in the base model training data and evaluation setups still prohibits us from performing an applestoapples comparison in some cases nonetheless we can still hope to understand the ballpark of improvement by contextualizing our results with these prior works we also compare to vstar 19 but since this is not an fair comparison we defer it to appendix b we evaluate rise in both modes at inference time with and without an oracle section 43 at the end of five turns concretely these metrics are defined as follows with oracle p1t5  this run terminates the rollout as soon as the response is correct in other words this metric allows queries to the final answer verifier at the end of each turn withoutoraclem1t5  thisrundoesnotterminatetherolloutbeforefiveturnsandwecompute the maj1 performance on the candidates produced in each turn as detailed in section 43 we also compare majk performance at the first turn for all the models we train m1t1 m5t1 9",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 2804,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "804e4f63-f146-457c-bb24-4f71e762ef38",
        "embedding": null,
        "metadata": {
            "page_label": "10",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "21be2dfd-852d-4c3a-81bf-e5d02081e746",
                "node_type": "4",
                "metadata": {
                    "page_label": "10",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "3fd277fe2c1477512fb205cd0b370ee3cc2b07c9ef6744b87c53a4e0fb3b1c93",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "c62729e3-719f-4d6c-b1f3-31b3abcdd94b",
                "node_type": "1",
                "metadata": {},
                "hash": "a908e07c32afa0db8b626162aa628f305b018c02def40e5b1760f9287c1c8b23",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "recursive introspection teaching language model agents howtoselfimprove approachgsm8k 10 math18 wo oracle w oracle wo oracle w oracle m1t1m5t1m1t5 p1t5 m1t1m5t1m1t5 p1t5 rise ours llama2 base 105 228 123 11106 13934 19 51 32 1405 2304 boost 329 454 125 39263 555226 55 68 13 5500 14691 iteration 1 356 497 141 507151 639283 63 88 25 9734 194131 iteration 2 373 510 137 550177 684311 58 104 46 10446 198140 sft on oracle data only correct data 274 422 149 34066 436162 58 79 21 5503 12162 correct and incorrect 257 418 161 31255 415158 50 52 02 5000 13181 rise ours mistral7b 337 494 157 39053 469132 75 130 55 8409 13055  iteration 1 353 506 153 59223968633367 95 28 184111297224 7b sota 58 eurus7bsft 363 663 300479116 531168 123 198 7516340 229106 selfrefine 31 m1t3p1t3 m1t3p1t3 base 105 224 119 7134 13025 19 51 32 1900 3112 iteration 2 373 505 132 33340 44572 58 94 36 5701 9537 gpt35 664 802 138 61054 71652 397 465 68 36532 46770 mistral7b 337 485 148 212125 37942 75 123 48 7104 11439 eurus7bsft 363 659 296 262101 42865 123 194 71 9033 15128 glore 17 m1t3p1t3 orm 482 495 13 57189 sorm 482 516 34 597115 not studied in 17 direct 482 474 08 592110 table 1 rise vs other approaches selfrefine glore and baselines observe that rise attains the biggest performance improvement in brown between 1turn m5t1 and 5turn m1t5 performance wo an oracle on both gsm8k and math this performance gap is even larger when oracle early termination is allowed p1t5 w oracle selfrefine  31 degrades performance across the board when used without an oracle and attains minor performance improvements when used with an oracle glore trains a separate refinement model but still performs worse than rise more details about it are in appendix b using rise on top of a better base model mistral7b is also effective positive improvements with multiple turns and note the m1t5 performance of mistral7b exceeds even stateoftheart math models such as eurus7bsft  58 simply running singleturn sft on data utilized by rise is not effective at",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 2019,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "c62729e3-719f-4d6c-b1f3-31b3abcdd94b",
        "embedding": null,
        "metadata": {
            "page_label": "10",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "21be2dfd-852d-4c3a-81bf-e5d02081e746",
                "node_type": "4",
                "metadata": {
                    "page_label": "10",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "3fd277fe2c1477512fb205cd0b370ee3cc2b07c9ef6744b87c53a4e0fb3b1c93",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "804e4f63-f146-457c-bb24-4f71e762ef38",
                "node_type": "1",
                "metadata": {
                    "page_label": "10",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "be88ab7840f91193d83c184d1b4d0dca4ee03a5d1c577004f66462426a8cde54",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "improvements with multiple turns and note the m1t5 performance of mistral7b exceeds even stateoftheart math models such as eurus7bsft  58 simply running singleturn sft on data utilized by rise is not effective at inducing a selfimprovement capability implying that the algorithmic design choices in rise are crucial for performance color coding indicates numbers that can be compared to each other 61 does rise improve performance over multiple turns compared to other approaches main results we present the comparisons in table 1 first note that rise iteration 1 and iteration 2 boosts up the llama2 base models fiveturn performance by 151 and 177 respectively with each iteration on gsm8k and 34 and 46 on math wo any oracle interestingly we found using promptingonly selfrefine  31 largely degrades performance across the board even with a strong proprietary model gpt35 the strongest 7b base models mistral7b and eurus7bsft  58 when coupled with standard prompting are only able to improve their performance but only by 53  116 and 09  40 respectively on gsm8k and math which is significantly lower than our approach the performance of glore improves only by 34 on gsm8k over two turns but this is still lower than our approach which improves by 63 in two turns and 134 in three turns see appendix b1 this indicates that rise is effective in teaching models how to improve their own errors to summarize training with rise gives the largest performance improvement gains compared to other approaches both with and without the use of an oracle and these gains are transferred to other base models one might also hypothesize that the performance gains with rise here are largely a result of utilizing 10",
        "mimetype": "text/plain",
        "start_char_idx": 1807,
        "end_char_idx": 3511,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "8f2a3bbf-8f5f-44f1-991e-971d415c2f91",
        "embedding": null,
        "metadata": {
            "page_label": "11",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "9a795bd8-2a29-4c1d-a235-cb3493d19955",
                "node_type": "4",
                "metadata": {
                    "page_label": "11",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "13268092932495eb03655e7f97b236ed025dd0218e009676b84de14570df01c2",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "c7cdb358-b5e0-463b-9080-a21bccb6f0ce",
                "node_type": "1",
                "metadata": {},
                "hash": "a0e335a0c635230ff45c83df4d8802957bad309ab801ff04b57c78ad69d387c6",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "recursive introspection teaching language model agents howtoselfimprove queries to an offtheshelf more capable model for providing supervision and not the algorithmic approach for data collection and training to address this hypothesis we store all the data generated by rise from more capable models and train on this data via standard singleturn sft  sftonoracledata  since not all of this data are guaranteed to be correct we also run this experiment on only the correct responses in these oracle data observe in table 1 that this procedure does not still instill selfimprovement capabilities largely preserving or degrading sequential  maj1turn5  performance compared to simply sampling one response in the first turn this means that the algorithmic design of rise is critical in enabling it to learn selfimprovement capabilities as opposed to simply the use of expert supervision 611 can rise effectively make use of mistakes and correct them one concern that arises from prior results on selfrefinement or selfcorrection is whether the model can truly correct itself over turns or whether the improvement comes from the effect of sampling more answers and picking the best one in table 1 we see that sequentially improving responses via rise maj1turn5  outperforms sampling 5 responses in parallel at the first turn and applying a majority vote on them  maj5turn1  please note that this comparison utilizes an equal number of samples with the only difference being that these samples are drawn in parallel at the first turn in one case and sequentially at the end of five turns in the other comparing maj5 performance at the end of 1 turn and 5 turns we observe a consistent 4 to 8 improvement on gsm8k and an 65 improvement on math with mistral7b model this means that rise can imbue models with a selfimprovement ability while running parallel sampling alone on any model cannot endow the same ability even the maj5turn1 performance of standard singleturn sft on the data used by rise is substantially worse than the sequential maj1turn5 performance of rise implying that the algorithmic protocol of rise plays a critical underlying role finally we also remark that in figure 6 we showed that the sequential procedure learned by rise over five turns could solve a significant fraction of problems that were unsolved by passb for much larger values of \ud835\udc355in the first turn implying that sequential rise can actually tackle prompts that were not solvable by simply sampling more responses in the first turn one might also speculate if these improvements in sequential improvement ability largely come at a cost of reduced improvements in first turn performance in addition we also observe that running multiple iterations of rise still preserves the first turn performance while improving the 5turn performance 612 how does the base model affect rise the performance of rise with llama27b on an absolute scale is lower than the best models specifically finetuned on math data eg eurus7bsft or mistral7b however we find that rise is still effective on top of mistral7b base model in fact our performance at the end of five turns outperforms one of the best 7b sft models customized to math reasoning  compare the m1t5 performance of eurus7bsft and mistral7b in rise ours to find that mistral7b  rise outperforms eurus7bsft 613 selfdistillation version of rise we also compare the performance of rise with entirely selfgenerated data and supervision equation 44 \ud835\udc41 16 after one iteration directly on top of more capable models mistral7b",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 3538,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "c7cdb358-b5e0-463b-9080-a21bccb6f0ce",
        "embedding": null,
        "metadata": {
            "page_label": "11",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "9a795bd8-2a29-4c1d-a235-cb3493d19955",
                "node_type": "4",
                "metadata": {
                    "page_label": "11",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "13268092932495eb03655e7f97b236ed025dd0218e009676b84de14570df01c2",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "8f2a3bbf-8f5f-44f1-991e-971d415c2f91",
                "node_type": "1",
                "metadata": {
                    "page_label": "11",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "3ab619eba545eeb56c1b1b487a2449d7efbae3e138d7c3074c9d759df047f885",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "eurus7bsft 613 selfdistillation version of rise we also compare the performance of rise with entirely selfgenerated data and supervision equation 44 \ud835\udc41 16 after one iteration directly on top of more capable models mistral7b and llama38b on gsm8k in table 2 without any knowledge boosting phase we find that this variant also improves the 5turn performance of the base model compared to the first turn compare m1t5 vs m1t1 for both the models llama38b and mistral7b where rise boosts the sequential selfimprovement performance by more than 1 compared to turn 1 performance wo any oracle of course we also note that this version of rise does not outperform the m5t1 performance of the 11",
        "mimetype": "text/plain",
        "start_char_idx": 3316,
        "end_char_idx": 4000,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "2df73074-6962-460a-b410-2ac8fa707ef2",
        "embedding": null,
        "metadata": {
            "page_label": "12",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "26d72c97-ff69-4dee-8d95-b0536116ca2d",
                "node_type": "4",
                "metadata": {
                    "page_label": "12",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "2582f49164f5e54b1689dc8cc8c059fae0002322b6234670aca3edd5eae7f27e",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "5dc1dd23-7ea4-47c7-9840-5384c0feefb6",
                "node_type": "1",
                "metadata": {},
                "hash": "48ed5692536e8da63cb794776ddbe6e6550005d4e43e1225fe934cbebb239a90",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "recursive introspection teaching language model agents howtoselfimprove rise selfwo oracle w oracle m1t1m5t1m1t5 p1t5 mistral7b 337 494 157 39053 469132  iteration 1 368 444 76 39566 487159 llama38b 453 697 244 52572 610157  iteration 1 656 807 151 73882 812156 table 2 rise with selfdistillation on gsm8k rise is able to improve 5turn maj1 performance of the model with entirely selfgenerated data and supervision despite the fact that the base mistral7b model does not produce correct answers for several problems finetuned model we expect this to be largely a function of one single iteration of training since the selfdistillation version of rise utilizes bestofn sampling against the same model to produce supervision for selfimprovement rise would first have to match the performance of bestofn sampling before it can start to improve over it via reward maximization due to the significant gap between the base models m5t1 and m1t5 performance we expect that this will take quite a few iterations or a fully online rl algorithm we did not have computational resources and infrastructure to run multiple iterations but this is an interesting avenue for future work in this selfdistillation setting we could also divide the computation between sequential and parallel sampling strategies to get the best results at the end of five turns nonetheless this result shows that even by training on selfgenerated samples rise can actually amplify the sequential sampling performance of the base model 62 does the performance of rise improve with iterative training next we attempt to understand if rise improves with multiple rounds of training on onpolicy data as shown in tables 1 and 2 the performance of rise improves from iteration to iteration constantly the 5turn performance of rise both with and without an oracle exhibits a clear improvement with more rounds this implies that iterative selftraining procedures of the form of star  61 can also be combined with rise to train models for selfimprovement this also perhaps serves as a strong hint towards the potential utility of full online reinforcement learning rl techniques 63 does rise also improve sequential performance on outofdistribution prompts in table 3 our aim is to evaluate the robustness of the strategy induced by rise on new unseen prompts specifically we compare the performance of the rise model trained with a dataset on evaluation prompts from another dataset note in table 3 these datasets include math gsm8k and svamp generally we observe that the model trained on one dataset is still able to improve the base models performance on another dataset over the course of sequential five turns more concretely while the base llama2 model largely degrades its turn 1 performance over turn 5 performance models trained with rise enable a positive performance improvement on these outofdistribution prompts this means that even though these models have not seen queries similar to the evaluation dataset simply training with rise onsomekind of mathematical prompts still boosts the efficacy of the selfimprovement strategy on a new distribution of test prompts this finding suggests that rise is capable of instilling selfimprovement procedures that can generalize beyond the distribution of prompts in the finetuning data 64 what data compositions and data quantity are crucial for rise we now study how different data compositions affect the performance of rise with the goal of answering questions such as should we collect onpolicy error correction data like dagger  36 or should we bias towards highquality offpolicy data  to understand",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 3614,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "5dc1dd23-7ea4-47c7-9840-5384c0feefb6",
        "embedding": null,
        "metadata": {
            "page_label": "12",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "26d72c97-ff69-4dee-8d95-b0536116ca2d",
                "node_type": "4",
                "metadata": {
                    "page_label": "12",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "2582f49164f5e54b1689dc8cc8c059fae0002322b6234670aca3edd5eae7f27e",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "2df73074-6962-460a-b410-2ac8fa707ef2",
                "node_type": "1",
                "metadata": {
                    "page_label": "12",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "3de81c3a48dbfab2d664ab48df87bc02c105c74c2401ed740210132bc58a8734",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "are crucial for rise we now study how different data compositions affect the performance of rise with the goal of answering questions such as should we collect onpolicy error correction data like dagger  36 or should we bias towards highquality offpolicy data  to understand the utility of different data compositions we enlist 12",
        "mimetype": "text/plain",
        "start_char_idx": 3340,
        "end_char_idx": 3670,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "f1447bbb-c1a8-42c6-8cf6-9f1d030237d6",
        "embedding": null,
        "metadata": {
            "page_label": "13",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "5dd40b21-3e28-4383-8e66-ed9f65dbedbb",
                "node_type": "4",
                "metadata": {
                    "page_label": "13",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "d13b729b00b3edee79d903599452689b9c6d8c7cd396437024ada3791f0a9b0e",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "recursive introspection teaching language model agents howtoselfimprove risewo oracle w oracle m1t1m1t5 p1t5 gsm8k llama2 base 105 111 06 13934 iteration 1 rise model trained on math 193 326 133 484291 math llama2 base 19 14 05 2304 iteration 1 rise model trained on gsm8k 43 44 01 12178 svamp llama2 base 292 305 13 34048 iteration 1 rise model trained on math 301 314 12 459158 iteration 1 rise model trained on gsm8k 422 500 78 636214 table 3 outofdistribution generalization of rise we evaluate model finetuned on math on the gsm8k test set model finetuned gsm8k on math and the model finetuned on a mixture of gsm8k and math on the svamp data observe even though we train on ood prompts rise can still improve sequential performance the three aspects rise athe use of multiturn rollout data for finetuning bthe use of unsuccessful  suboptimal rollouts via weighted supervised finetuning compared to na\u00efve supervised learning which only utilizes successful rollouts for finetuning and cthe use of onpolicy rollouts and selfgenerated or oracle data we will now perform controlled experiments to understand the effect of each of these factors on the overall performance of rise figure7left the importance of multiturn interaction history and weighted objectives for training rise note that training with multiturn data leads to better selfimprovement performance at the end of 5 turns than oneturn data obtained from the original dataset with oracle answers from another model also observe that using a weighted objective performs better right the importance of using all rollouts for learning  instead of only successful rollouts or only successful responses in the data using all data performs best in our results a data composition for finetuning we first study the necessity of using the interaction of error correction history for training rise in figure 7 left we compare two approaches model trained with oracle answers shown right after the query 1turn and oracle answers shown after intermediate failed attempts multiturn in figure 7 left even though the latter trains on intermediate responses that may not always be correct it attains a higher performance than simply training on the correct response for a given prompt this highlights the importance of training on contexts that include a multiturn interaction history depicting mistakes from the learner to improve selfimprovement capabilities b weighted supervised learning vs unweighted supervised learning next we investigate the effect 13",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 2507,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "d7334d7a-5f7a-470f-b543-ed5fe085224a",
        "embedding": null,
        "metadata": {
            "page_label": "14",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "b8d2a1fe-0283-4573-b39b-1ac78b424f0a",
                "node_type": "4",
                "metadata": {
                    "page_label": "14",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "121ad90490ed346a3ca235cdb68b18ef9427c7ac99d20b0b457215babcb062cb",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "recursive introspection teaching language model agents howtoselfimprove of rewardweighted rl on multiturn data in rise as opposed to simply imitating filtered successful data we find that using all the data leads to improved performance over simply filtering good datain figure 7 right which reduces sample size in figure 7 left we find that rewardweighted training improves performance on later turns allowing us to better leverage all the suboptimal data c onpolicy vs offpolicy data selfgenerated vs expert data rise runs onpolicy rollouts and seeks improvements on responses that the learner produces as shown in figure 8 left a dagger  36style approach that seeks improvements on responses appearing in onpolicy rollouts improves performance greenorange compared to using expert data alone bluepink conceptually this addresses the traintest mismatch between the distribution of context tokens enabling imitation learning methods to now target the correct distribution in addition recent work  24 has shown that llms often memorize unfamiliar examples generated by oracle models by training on onpolicy rollouts we should be able to eliminate any such potential issues thus while the model trained via offline imitation is able to reduce loss these improvements do not generalize to new problems figure8left the importance of data sources used for training we study the performance of the iteration 1 of rise on gsm8k with different data sources expert refers to the use of an oracle model onpolicy corresponds to sampling from the learner and bestofn means using the best sample out of \ud835\udc41from the learner here \ud835\udc41 16right comparing rise with oracle error feedback pass1  turn k solid lines to parallel sampling of 5 responses at turn 1 passk  turn 1 dashed lines over number of turns \ud835\udc58on the xaxis on gsm8k observe that sequential sampling with iteration 1 and iteration 2 rise models consistently outperforms parallel sampling for all values of turn \ud835\udc58 and the gap grows as the number of iterations increases in contrast this trend is absent for base and sft models 65 passk vs sequential sampling via rise we now study the performance of sequential sampling with oracle feedback in gsm8k unlike relying on majority voting as in table 1 specifically we compare the performance of rise with early termination of evaluation rollouts against pass5 not maj5 performance of the rise model at the first turn which makes an equal number of queries to the groundtruth correctness indicator access to groundtruth correctness indicator is expected to improve performance for both parallel and sequential sampling unsurprisingly but we see in figure 8 right that rise is able to improve performance more beyond simply sampling more samples at the first turn and computing passk despite this strong assumption of access to an oracle final answer verifier made by the parallel sampling approach we would expect parallel sampling via passk to be most performant when provided access to oracle answer checking as the model can choose to simply sample \ud835\udc3eindependent responses if the base model accuracy on this task is reasonable passk  turn 1 also upper bounds the first turn accuracy of any procedure that does not query the oracle eg with verifiers with majority voting etc hence access 14",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 3277,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "8662e9d5-fb86-468a-a15b-322707946548",
        "embedding": null,
        "metadata": {
            "page_label": "15",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "0f1488cf-2603-417e-aaf2-b0d1dc9ff26b",
                "node_type": "4",
                "metadata": {
                    "page_label": "15",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "a9f571c17de20032385de53da74dfe8534793e74f432b79f1c4cc3915e2c6d41",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "recursive introspection teaching language model agents howtoselfimprove to oracle answer checking for each individual response presents the strongest result one couldexpect out of parallel sampling in one turn on the other hand sequential sampling produces correlated samples and hence should in principle not be able to improve over parallel sampling unlessthe model is unable to use the additional tokens and computation provided by the feedback selfimprovement prompt to meaningfully correct itself since the sequential performance of the model is larger than the parallel performance above this means that rise indeed does this successfully 66 error analysis of rise over turns following the protocol of huang et al 21 in this section we perform an error analysis of the improve ment performed by rise without any oracle feedback to understand how the fraction of incorrect and correct responses changes over turns when no oracle is used for early termination we demonstrate this in the form of venn diagrams in figure 9 first note that there is a consistent increase in the portion of problems that stay correct and a consistent decrease in the portion of problems that stay incorrect which means that the model is able to answer more and more problems as we increase the number of turns second there is a consistent decrease in the number of problems that change from being correct to incorrect which is often also not the case for strong proprietary llms such as gpt in huang et al21 we also note that there is a decrease in the total number of incorrect problems that become correct in the subsequent turn but this is a direct consequence of a shrinkage in the size of the incorrect response set as more problems become correct over turns this indicates that one can induce intrinsic selfimprovement per the terminology of huang et al 21 via finetuning with rise even though no external environment input is provided during evaluation figure9change in the fraction of responses that transition their correctness values over the course of multiturn rollouts from rise wo oracle observe that in general the fraction of correct correct responses increases incorrect  incorrect responses decreases and the fraction of correct incorrect responses also decreases indicating that rise wo any oracle is able to iteratively improve its responses qualitative examples we also inspect several examples from the gsm8k test set to qualitatively understand the behavior of rise over turns and observe different behavior patterns that we show in appendix b2 for instance the trained model may choose to completely rewrite its previous response if it is totally incorrect in order to get to the correct answer or make small edits if the previous response is mostly correct another interesting pattern we note is that the model implicitly has the ability to locate errors in previous responses and only refine the erroneous steps additionally the model is tolerant of noisy environmental feedback when there is no oracleassisted early termination 15",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 3040,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "e3cec830-fa39-4f92-852c-b7a71e799840",
        "embedding": null,
        "metadata": {
            "page_label": "16",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "2376cb87-6d49-47b2-bdf8-b1f685441027",
                "node_type": "4",
                "metadata": {
                    "page_label": "16",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "6353f9511f94c10e225df5c3e9bd1637824e6134f7a9bc220138e5fbcfc0f39a",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "6a0cf7b4-d3df-4c10-88de-80c87515fd17",
                "node_type": "1",
                "metadata": {},
                "hash": "04d2ed676623e2c587aabf921f5938a99c65fb950221ff2a6921239d5a57ea7b",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "recursive introspection teaching language model agents howtoselfimprove 7 discussion future directions and limitations we presented rise an approach for finetuning llms to be able to improve their own responses over multiple turns sequentially rise prescribes an iterative rl recipe on top of onpolicy rollout data with expert or selfgenerated supervision to steer selfimprovement rise significantly improves the self improvement abilities of 7b models on reasoning tasks gsm8k and math attaining an improvement over turns that previous work  21 has not observed in strong proprietary models in addition rise outperforms prior approaches that attempt to tackle similar problems of refinement and correction while being simpler in that it does not require running multiple models and works well with just one model despite these good results there are still many open questions and limitations due to computational constraints we were not able to perform more than two iterations of training with rise and no more than one iteration when the supervision comes from the learner itself improving with selfgenerated supervision will likely require more computation and more iterations since it will be slower than when using an offtheshelf expert model rise requires running manual iterations and hence a more online variant of rise is likely the solution in the long run especially when we wish to scale onpolicy learning in a dataefficient manner additionally while our work finetunes models on one task at a time it will be certainly interesting to include data from the protocols specified by rise into general instruction tuning and posttraining pipelines given the results that finetuning on data prescribed by rise does not hurt the firstturn performance of any model we trained we hypothesize that adding this sort of data in generalinstructiontuningpipelinesshouldnothurteitherwhileenablingthesequentialselfimprovement capability that is largely absent from models today acknowledgements this work was done at cmu we thank fahim tajwar abitha thankaraj amrith setlur and charlie snell for their feedback and informative discussions this work was supported by onr under n000142412206 openai superalignment fast grants and used the delta system and jetstream2  16 at the national center for supercomputing applications through cis240249 and cis230278 supported by the national science foundation we thank openai for providing gpt4 credits for academic use references 1rishabh agarwal nino vieillard piotr stanczyk sabela ramos matthieu geist and olivier bachem gkd generalized knowledge distillation for autoregressive sequence models arxiv preprint arxiv230613649  2023 2yuntao bai saurav kadavath sandipan kundu amanda askell jackson kernion andy jones anna chen anna goldie azalia mirhoseini cameron mckinnon et al constitutional ai harmlessness from ai feedback arxiv preprint arxiv221208073  2022 3collin burns pavel izmailov jan hendrik kirchner bowen baker leo gao leopold aschenbrenner yining chen adrien ecoffet manas joglekar jan leike ilya sutskever and jeff wu weakto strong generalization eliciting strong capabilities with weak supervision 2023 url https arxivorgabs231209390  4jonathan d chang wenhao shan owen oertell kiant\u00e9 brantley dipendra misra jason d lee and wen sun dataset reset policy optimization for",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 3329,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "6a0cf7b4-d3df-4c10-88de-80c87515fd17",
        "embedding": null,
        "metadata": {
            "page_label": "16",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "2376cb87-6d49-47b2-bdf8-b1f685441027",
                "node_type": "4",
                "metadata": {
                    "page_label": "16",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "6353f9511f94c10e225df5c3e9bd1637824e6134f7a9bc220138e5fbcfc0f39a",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "e3cec830-fa39-4f92-852c-b7a71e799840",
                "node_type": "1",
                "metadata": {
                    "page_label": "16",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "6f52982c51996707bc6ffa1d8da74669052aeddb6fe95fcba5c5fdf328f32a93",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "url https arxivorgabs231209390  4jonathan d chang wenhao shan owen oertell kiant\u00e9 brantley dipendra misra jason d lee and wen sun dataset reset policy optimization for rlhf arxiv preprint arxiv240408495  2024 16",
        "mimetype": "text/plain",
        "start_char_idx": 3162,
        "end_char_idx": 3373,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "4d11f968-5ced-4fd3-926a-50de14a25ded",
        "embedding": null,
        "metadata": {
            "page_label": "17",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "d5bff947-3bc5-4eb7-94e9-730637902c5f",
                "node_type": "4",
                "metadata": {
                    "page_label": "17",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "fa56209de96fc9d0d5532b5c4352e73d683989d8f980d71111bd4e887f083e17",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "2a6b76dd-bb9c-448d-9a72-6cf11289635c",
                "node_type": "1",
                "metadata": {},
                "hash": "7c361c13f5ea08007e7b07c30e8d9d58654043aa993092509702846952e0515c",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "recursive introspection teaching language model agents howtoselfimprove 5yiannis charalambous norbert tihanyi ridhi jain youcheng sun mohamed amine ferrag and lucas c cordeiro a new era in software security towards selfhealing software via large language models and formal verification arxiv preprint arxiv230514752  2023 6baian chen chang shu ehsan shareghi nigel collier karthik narasimhan and shunyu yao fireact toward language agent finetuning 2023 7xinyun chen maxwell lin nathanael sch\u00e4rli and denny zhou teaching large language models to selfdebug arxiv preprint arxiv230405128  2023 8zixiang chen yihe deng huizhuo yuan kaixuan ji and quanquan gu selfplay finetuning converts weak language models to strong language models arxiv preprint arxiv240101335  2024 9yew ken chia guizhen chen luu anh tuan soujanya poria and lidong bing contrastive chainofthought prompting arxiv preprint arxiv231109277  2023 10karlcobbe christopherhesse jacobhilton andjohnschulman leveragingproceduralgeneration to benchmark reinforcement learning arxiv preprint arxiv191201588  2019 11karlcobbevineetkosarajumohammadbavarianmarkchenheewoojunlukaszkaisermatthias plappert jerry tworek jacob hilton reiichiro nakano christopher hesse and john schulman training verifiers to solve math word problems arxiv preprint arxiv211014168  2021 12yilun du shuang li antonio torralba joshua b tenenbaum and igor mordatch improving factual ity and reasoning in language models through multiagent debate arxiv preprint arxiv230514325  2023 13kanishk gandhi denise lee gabriel grand muxin liu winson cheng archit sharma and noah d goodman stream of search sos learning to search in language arxiv preprint arxiv240403683  2024 14luyu gao aman madaan shuyan zhou uri alon pengfei liu yiming yang jamie callan and graham neubig pal programaided language models in international conference on machine learning  pages 1076410799 pmlr 2023 15zhibin gou zhihong shao yeyun gong yelong shen yujiu yang nan duan and weizhu chen critic large language models can selfcorrect with toolinteractive critiquing arxiv preprint arxiv230511738  2023 16david y hancock jeremy fischer john michael lowe winona snappchilds marlon pierce suresh marru j eric coulter matthew vaughn brian beck nirav merchant edwin skidmore and gwen jacobs jetstream2 accelerating cloud computing via jetstream in practice and experience in advanced research computing  pearc 21 new york ny usa 2021 association for computing machinery isbn 9781450382922 doi",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 2490,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "2a6b76dd-bb9c-448d-9a72-6cf11289635c",
        "embedding": null,
        "metadata": {
            "page_label": "17",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "d5bff947-3bc5-4eb7-94e9-730637902c5f",
                "node_type": "4",
                "metadata": {
                    "page_label": "17",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "fa56209de96fc9d0d5532b5c4352e73d683989d8f980d71111bd4e887f083e17",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "4d11f968-5ced-4fd3-926a-50de14a25ded",
                "node_type": "1",
                "metadata": {
                    "page_label": "17",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "7554ec3d63a73283fe39e1f9a697a73f56aa095bc105c9ef3d1492c071e99674",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "skidmore and gwen jacobs jetstream2 accelerating cloud computing via jetstream in practice and experience in advanced research computing  pearc 21 new york ny usa 2021 association for computing machinery isbn 9781450382922 doi 10114534373593465565 url https doiorg10114534373593465565  17alex havrilla sharath raparthy christoforus nalmpantis jane dwivediyu maksym zhuravinskyi eric hambro and roberta railneau glore when where and how to improve llm reasoning via global and local refinements arxiv preprint arxiv240210963  2024 17",
        "mimetype": "text/plain",
        "start_char_idx": 2264,
        "end_char_idx": 2796,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "8cdb6d8f-867d-4d7b-a80f-be5eb8b80718",
        "embedding": null,
        "metadata": {
            "page_label": "18",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "43a7c500-c11f-403c-9a38-fce84eb1b495",
                "node_type": "4",
                "metadata": {
                    "page_label": "18",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "16da7c5c74f775ac64350c5c2dbee58a368b6d1ea488841b8875e41be050658c",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "79c34068-4ed0-443f-8ec8-ede80e8058b2",
                "node_type": "1",
                "metadata": {},
                "hash": "6da195f6ae177ccfd94867d533cf5bcf97d961b9ea8fa90b3fac5dda38ff4665",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "recursive introspection teaching language model agents howtoselfimprove 18dan hendrycks collin burns saurav kadavath akul arora steven basart eric tang dawn song and jacob steinhardt measuring mathematical problem solving with the math dataset neurips  2021 19arian hosseini xingdi yuan nikolay malkin aaron courville alessandro sordoni and rishabh agarwal vstar training verifiers for selftaught reasoners arxiv preprint arxiv240206457  2024 20dong huang qingwen bu jie m zhang michael luck and heming cui agentcoder multiagent based code generation with iterative testing and optimisation arxiv preprint arxiv231213010  2023 21jie huang xinyun chen swaroop mishra huaixiu steven zheng adams wei yu xinying song and denny zhou large language models cannot selfcorrect reasoning yet arxiv preprint arxiv231001798  2023 22wenlong huang pieter abbeel deepak pathak and igor mordatch language models as zeroshot planners extracting actionable knowledge for embodied agents in international conference on machine learning  pages 91189147 pmlr 2022 23albert q jiang alexandre sablayrolles arthur mensch chris bamford devendra singh chaplot diego de las casas florian bressand gianna lengyel guillaume lample lucile saulnier et al mistral 7b arxiv preprint arxiv231006825  2023 24katie kang eric wallace claire tomlin aviral kumar and sergey levine unfamiliar finetuning examples control how language models hallucinate 2024 25diederik p kingma and max welling autoencoding variational bayes 2022 url https arxivorgabs13126114  26lucas lehnert sainbayar sukhbaatar paul mcvay michael rabbat and yuandong tian be yond a better planning with transformers via search dynamics bootstrapping arxiv preprint arxiv240214083  2024 27chen li weiqi wang jingcheng hu yixuan wei nanning zheng han hu zheng zhang and houwenpeng common7blanguagemodelsalreadypossessstrongmathcapabilities arxivpreprint arxiv240304706  2024 28hunter lightman vineet kosaraju yura burda harri edwards bowen baker teddy lee jan leike john schulman ilya sutskever and karl cobbe lets verify step by step arxiv preprint arxiv230520050  2023 29xiaoliu haoyu hanchenzhang yifanxu xuanyulei hanyulai yugu hangliangding kaiwen men kejuan yang et al agentbench evaluating llms as agents arxiv preprint arxiv230803688  2023 30haipengluoqingfengsuncanxupuzhaojianguanglouchongyangtaoxiubogengqingwei lin shifeng chen and dongmei zhang wizardmath empowering mathematical reasoning for large language models via reinforced evolinstruct arxiv preprint",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 2500,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "79c34068-4ed0-443f-8ec8-ede80e8058b2",
        "embedding": null,
        "metadata": {
            "page_label": "18",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "43a7c500-c11f-403c-9a38-fce84eb1b495",
                "node_type": "4",
                "metadata": {
                    "page_label": "18",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "16da7c5c74f775ac64350c5c2dbee58a368b6d1ea488841b8875e41be050658c",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "8cdb6d8f-867d-4d7b-a80f-be5eb8b80718",
                "node_type": "1",
                "metadata": {
                    "page_label": "18",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "dfd10c18e83c70a8cf255fc946982f670398e0dac52845a97d6db8e01e0a4da2",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "lin shifeng chen and dongmei zhang wizardmath empowering mathematical reasoning for large language models via reinforced evolinstruct arxiv preprint arxiv230809583  2023 18",
        "mimetype": "text/plain",
        "start_char_idx": 2352,
        "end_char_idx": 2524,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "96aae380-c462-47ba-9adf-0d8e8e8d7bb1",
        "embedding": null,
        "metadata": {
            "page_label": "19",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "8e3015a5-e662-4aee-a474-eb34f5cd4d99",
                "node_type": "4",
                "metadata": {
                    "page_label": "19",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "6cfa706d28c6b892c4a2ca473349c6591c6903e4b0c10d9fff7db51f167376da",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "03be0741-b39b-4e00-9ab0-a5cc1cac82ef",
                "node_type": "1",
                "metadata": {},
                "hash": "05d4751d8b483ef24121bf84b60823d2ed7b78bca8e426ce8c35843b306be15d",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "recursive introspection teaching language model agents howtoselfimprove 31aman madaan niket tandon prakhar gupta skyler hallinan luyu gao sarah wiegreffe uri alon nouha dziri shrimai prabhumoye yiming yang et al selfrefine iterative refinement with selffeedback arxiv preprint arxiv230317651  2023 32erik nijkamp bo pang hiroaki hayashi lifu tu huan wang yingbo zhou silvio savarese and caiming xiong codegen an open large language model for code with multiturn program synthesis iclr 2023 33maxwell nye anders johan andreassen guy gurari henryk michalewski jacob austin david bieber david dohan aitor lewkowycz maarten bosma david luan et al show your work scratchpads for intermediate computation with language models arxiv preprint arxiv211200114  2021 34xue bin peng aviral kumar grace zhang and sergey levine advantageweighted regression simple and scalable offpolicy reinforcement learning arxiv preprint arxiv191000177  2019 35janpetersandstefanschaal reinforcementlearningbyrewardweightedregressionforoperational spacecontrol in proceedingsofthe24thinternationalconferenceonmachinelearning pages745750 acm 2007 36stephanerossgeoffreygordonanddrewbagnell areductionofimitationlearningandstructured prediction to noregret online learning in geoffrey gordon david dunson and miroslav dud\u00edk editors proceedings of the fourteenth international conference on artificial intelligence and statistics  volume 15 of proceedings of machine learning research  pages 627635 fort lauderdale fl usa 1113 apr 2011 pmlr url httpproceedingsmlrpressv15ross11ahtml  37corby rosset chingan cheng arindam mitra michael santacroce ahmed awadallah and tengyang xie direct nash optimization teaching language models to selfimprove with general preferences arxiv preprint arxiv240403715  2024 38swarnadeep saha omer levy asli celikyilmaz mohit bansal jason weston and xian li branchsolvemerge improves large language model evaluation and generation arxiv preprint arxiv231015123  2023 39timo schick jane dwivediyu roberto dess\u00ec roberta raileanu maria lomeli luke zettlemoyer nicola cancedda and thomas scialom toolformer language models can teach themselves to use toolsarxiv preprint arxiv230204761  2023 40noah shinn beck labash and ashwin gopinath reflexion an autonomous agent with dynamic memory and selfreflection arxiv preprint arxiv230311366  2023 41charlie snell ilya kostrikov yi su mengjiao yang and sergey levine offline rl for natural language generation with implicit language q learning arxiv preprint arxiv220611871  2022 42jaschasohldicksteinericaweissnirumaheswaranathanandsuryaganguli deepunsupervised learning using nonequilibrium thermodynamics 2015",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 2652,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "03be0741-b39b-4e00-9ab0-a5cc1cac82ef",
        "embedding": null,
        "metadata": {
            "page_label": "19",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "8e3015a5-e662-4aee-a474-eb34f5cd4d99",
                "node_type": "4",
                "metadata": {
                    "page_label": "19",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "6cfa706d28c6b892c4a2ca473349c6591c6903e4b0c10d9fff7db51f167376da",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "96aae380-c462-47ba-9adf-0d8e8e8d7bb1",
                "node_type": "1",
                "metadata": {
                    "page_label": "19",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "e896727eb12326cfe1c39cd014b7a2b1b674fb893dc711bbd741ae215a932682",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "preprint arxiv220611871  2022 42jaschasohldicksteinericaweissnirumaheswaranathanandsuryaganguli deepunsupervised learning using nonequilibrium thermodynamics 2015 url httpsarxivorgabs1503 03585 43yang song and diederik p kingma how to train your energybased models 2021 url https arxivorgabs210103288  19",
        "mimetype": "text/plain",
        "start_char_idx": 2490,
        "end_char_idx": 2794,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "767999ea-8a58-4c41-b827-30e37038c9b6",
        "embedding": null,
        "metadata": {
            "page_label": "20",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "eb62ea6a-4a63-4e74-a9d0-5add90836ef3",
                "node_type": "4",
                "metadata": {
                    "page_label": "20",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "5bee922186c8afdfd348fc3555db5f6d53eb98e9464e3b8156b0eaecb81bcc0e",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "e7f5fc87-9225-4c50-b643-0c76c2295767",
                "node_type": "1",
                "metadata": {},
                "hash": "52709b14b7a69cab67dd06668dde8b1e26dfa402ec60de9f2ee224604860d84f",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "recursive introspection teaching language model agents howtoselfimprove 44liting sun cheng peng wei zhan and masayoshi tomizuka a fast integrated planning and control framework for autonomous driving via imitation learning in dynamic systems and control conference  volume 51913 page v003t37a012 american society of mechanical engineers 2018 45gokul swamy sanjiban choudhury j andrew bagnell and zhiwei steven wu inverse reinforce ment learning without reinforcement learning 2024 url httpsarxivorgabs2303 14623 46shubham toshniwal ivan moshkov sean narenthiran daria gitman fei jia and igor gitman openmathinstruct1 a18millionmathinstructiontuningdataset arxivpreprintarxiv240210176  2024 47jonathan uesato nate kushman ramana kumar francis song noah siegel lisa wang antonia creswell geoffrey irving and irina higgins solving math word problems with processand outcomebased feedback arxiv preprint arxiv221114275  2022 48boshi wang sewon min xiang deng jiaming shen you wu luke zettlemoyer and huan sun towards understanding chainofthought prompting an empirical study of what matters arxiv preprint arxiv221210001  2022 49guanzhi wang yuqi xie yunfan jiang ajay mandlekar chaowei xiao yuke zhu linxi fan and anima anandkumar voyager an openended embodied agent with large language models arxiv preprint arxiv arxiv230516291  2023 50peiyi wang lei li zhihong shao rx xu damai dai yifei li deli chen y wu and zhifang sui mathshepherd verify and reinforce llms stepbystep without human annotations corr abs231208935  2023 51xuezhiwangjasonweidaleschuurmansquocleedchisharannarangaakankshachowdhery and denny zhou selfconsistency improves chain of thought reasoning in language models arxiv preprint arxiv220311171  2022 52jason wei xuezhi wang dale schuurmans maarten bosma fei xia ed chi quoc v le denny zhou et al chainofthought prompting elicits reasoning in large language models neurips  2022 53sean welleck ximing lu peter west faeze brahman tianxiao shen daniel khashabi and yejin choi generating sequences by learning to selfcorrect in the eleventh international conference on learning representations  2023 url httpsopenreviewnetforumidhh36jeqzdao  54hui yang sifu yue and yunzhong he autogpt for online decision making benchmarks and additional opinions arxiv preprint arxiv230602224  2023 55kaiyu yang aidan m swope alex gu rahul chalamala peiyang song shixing yu saad godil ryan prenger and anima anandkumar leandojo theorem proving with retrievalaugmented language models arxiv preprint arxiv230615626  2023 56shunyu yao",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 2533,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "e7f5fc87-9225-4c50-b643-0c76c2295767",
        "embedding": null,
        "metadata": {
            "page_label": "20",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "eb62ea6a-4a63-4e74-a9d0-5add90836ef3",
                "node_type": "4",
                "metadata": {
                    "page_label": "20",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "5bee922186c8afdfd348fc3555db5f6d53eb98e9464e3b8156b0eaecb81bcc0e",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "767999ea-8a58-4c41-b827-30e37038c9b6",
                "node_type": "1",
                "metadata": {
                    "page_label": "20",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "b8fbdd8122f2a528eadbfb032db3ab8cbb56c537c18110d612619835916b8d36",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "yu saad godil ryan prenger and anima anandkumar leandojo theorem proving with retrievalaugmented language models arxiv preprint arxiv230615626  2023 56shunyu yao jeffrey zhao dian yu nan du izhak shafran karthik narasimhan and yuan cao react synergizing reasoning and acting in language models arxiv preprint arxiv221003629  2022 20",
        "mimetype": "text/plain",
        "start_char_idx": 2372,
        "end_char_idx": 2704,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "4453abd7-96f9-4f8d-bb46-cc4c9fcd392a",
        "embedding": null,
        "metadata": {
            "page_label": "21",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "c7685967-8d39-4472-a2f1-f66655bb6ddb",
                "node_type": "4",
                "metadata": {
                    "page_label": "21",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "d22c1b82ec0ad4e0d0b85d6a84a8e3a189e0d50fffe99280b6921092e20b1f12",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "recursive introspection teaching language model agents howtoselfimprove 57longhuiyu weisenjiang hanshi jinchengyu zhengyingliu yuzhang jamestkwok zhenguo li adrian weller and weiyang liu metamath bootstrap your own mathematical questions for large language models arxiv preprint arxiv230912284  2023 58lifan yuan ganqu cui hanbin wang ning ding xingyao wang jia deng boji shan huimin chen ruobing xie yankai lin et al advancing llm reasoning generalists with preference trees arxiv preprint arxiv240402078  2024 59 weizhe yuan richard yuanzhe pang kyunghyun cho sainbayar sukhbaatar jing xu and jason weston selfrewarding language models arxiv preprint arxiv240110020  2024 60xiang yue xingwei qu ge zhang yao fu wenhao huang huan sun yu su and wenhu chen mammoth building math generalist models through hybrid instruction tuning arxiv preprint arxiv230905653  2023 61eric zelikman yuhuai wu jesse mu and noah goodman star bootstrapping reasoning with reasoning advances in neural information processing systems  351547615488 2022 62aohan zeng mingdao liu rui lu bowen wang xiao liu yuxiao dong and jie tang agenttuning enabling generalized agent abilities for llms arxiv preprint arxiv231012823  2023 63tianjun zhang xuezhi wang denny zhou dale schuurmans and joseph e gonzalez tempera testtime prompting via reinforcement learning arxiv preprint arxiv221111890  2022 64tianjun zhang aman madaan luyu gao steven zheng swaroop mishra yiming yang niket tandon and uri alon incontext principle learning from mistakes arxiv preprint arxiv240205403  2024 65andy zhou kai yan michal shlapentokhrothman haohan wang and yuxiong wang lan guage agent tree search unifies reasoning acting and planning in language models arxiv preprint arxiv231004406  2023 66yifei zhou andrea zanette jiayi pan sergey levine and aviral kumar archer training language model agents via hierarchical multiturn rl arxiv preprint arxiv240219446  2024 21",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 1922,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "9da7bbc3-ebde-4dd0-bb40-43edbef6684d",
        "embedding": null,
        "metadata": {
            "page_label": "22",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "d021eb02-dd6a-4ade-95d4-832a5d7eeca8",
                "node_type": "4",
                "metadata": {
                    "page_label": "22",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "774232776dfa4af53dbca90e03db806c3617ea87d015f1c74fb3bbacb3a3c31a",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "recursive introspection teaching language model agents howtoselfimprove appendices a additional ablations on data composition and weaktostrong generalization a1 inclusion of correcttocorrect data intuitively selfimprovement over turns is largely only possible when the model can learn to verify the correctness of its previous response and decide to appropriately modify its response toward correctness thus far the rise has only trained on data that showed how to convert incorrect responses to correct responses but never illustrated how the model could act on correct responses to understand if perfor mance can be boosted by also illustrating examples of how the model could act on correct responses we ran a number of ablations we took the rise data generated during iteration 1 of training on gsm8k with llama27b and modified the multiturn rollouts to create several cases first we duplicated the correct response appearing at the end of every successful multiturn rollout and trained for one extra turn this should teach the model that correct responses should not be modified unlike incorrect responses appearing in previous turns in the rollout second we also ran a variant in which the correct response appearing at the end of every successful rollout is followed by a different correct response this variant should teach the model that if it chooses to modify a correct response it must still produce another correct response as shown in table 4 all methods improved performance over the base model though only appending with a successful rollout with a novel correct response leads to best performance the default design of rise in the main paper attains a close second position and repeating a correct response at the end of a successful rollout largely reduces performance we suspect that the poor performance of repeating the same correct response is largely a result of inducing spurious correlations due to data duplication rise llama2wo oracle w oracle m1t1m5t1m1t5 p1t5 boost 329 453 124 26564 40980 rise default 356 497 141 507151 639283 repeating a correct response 342 489 146 462126 577235 appending a different correct response 331 493 162 511180 649318 table 4 comparison of model performance on gsm8k with different mechanisms of adding correcttocorrect data in risevalues in parentheses indicate improvement over m1t1 note that appending a successful rollout with a a novel correct response leads to the highest performance gains to further investigate selfimprovement capabilities we analyzed the percentage of correct responses changing to incorrect responses in consecutive turns t \ud835\udc56to t\ud835\udc56 1 as illustrated in figure 10 generally a decreasing trend suggests better selfimprovement while lower absolute values indicate better resistance to noisy feedback the results reveal unexpected patterns across configurations the boost configuration shows the poorest performance with the highest overall percentages and an increase from turn 4 to 5 suggesting that it struggles to consistently maintain correct responses repeating a correct response shows the lowest initial percentage 63 but increases from turn 3 onward indicating potential issues in extended interactions both default rise and appending a different correct response demonstrate a favorable trend steadily decreasing from 123 to 39 and from 98 to 33 respectively suggesting a good balance between maintaining correct responses and allowing improvements these findings provide nuanced insights into the stability and selfimprovement capabilities of rise and align with our earlier observation of its superior performance in overall accuracy 22",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 3630,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "d7568c5b-42df-49f3-a2af-3bd04889bc07",
        "embedding": null,
        "metadata": {
            "page_label": "23",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "da12f0ab-a95a-49a7-953d-945c1389e461",
                "node_type": "4",
                "metadata": {
                    "page_label": "23",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "574e11f79122609041962628615e891e239f7e4ebcc965cef05df24c0e276dac",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "recursive introspection teaching language model agents howtoselfimprove figure10percentage of correct responses in turn t \ud835\udc56that change to being incorrect in turn t \ud835\udc561this figure illustrates the percentage of correct responses that change to incorrect responses across consecutive turns t \ud835\udc56to t\ud835\udc561 for different model configurations a continuously decreasing trend suggests better selfimprovement performance a2 weaktostrong generalization rise on weak model data improves strong models in this section we compare the performance of llama2 and mistral7b with rise in the weaktostrong setting 3 concretelyweareinterestedinusingdatageneratedviarisewithaweakmodelllama27b to train a strong model mistral7b our analysis reveals intriguing insights into the transferability of risegenerated data across models of different capabilities risewo oracle w oracle m1t1m5t1m1t5 p1t5 llama27b 105 228 123 11106 13934  iteration 1 356 497 141 507151 639283  iteration 1 mistral7b 271 401 130 452181 591320 mistral7b 337 494 157 39053 469132  iteration 1 353 506 153 592239 686333  iteration 1 llama27b 382 554 172 627245 735353 table 5 weaktostrong generalization on gsm8k comparing performance of rise when training on rollouts generated by llama27b vs mistral7b note that training the mistral7b model on rollouts generated by the weaker llama27b with rise improves performance compared to using data generated by the mistral7b model itself however the reverse is not true training the llama2 model on mistrals mistakes leads to worse performance likely because errors from the mistral7b model are harder to comprehend for a worse base model all values are in  accuracy and values in parentheses indicate improvement over m1t1 as shown in table 5 we find that mistral7b  iteration 1 data generated from llama2 outperforms training the llama27b model itself on these data ie llama27b  iteration1 on all the metrics reported with particularly significant improvements in multiturn reasoning m1t5 in fact training on multiturn rollouts from llama27b also outperforms training on onpolicy mistral7b rollouts as well interestingly we observed that training llama27b on multiturn rollouts from mistral7b performs worse than training on onpolicy llama27b rollouts suggesting that llama27b despite its lower absolute performance demonstrates more informative mistakes that can be leveraged to better boost the self improvement capability this phenomenon underscores the importance of the quality and nature of errors in the training data rather than just the overall performance of the model that generates them these findings collectively suggest that the data generated from a weaker llama2 model can still be used to induce a selfimprovement capability in a stronger model although the reverse is not true as is also evident from the fact that using gpt35 rollouts in the boosting phase for training does not improve performance for any model in table 1 we suspect that this is becaue the reverse poses a much harder 23",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 3000,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "a063ddc9-0efc-47d9-8929-59108bff1584",
        "embedding": null,
        "metadata": {
            "page_label": "24",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "000c7321-6d14-4311-ba9d-2c4a5d426341",
                "node_type": "4",
                "metadata": {
                    "page_label": "24",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "6cd91a4db00ce0d1f350ab980954203536fa5677a3b99e2d352eea217d5ddf7d",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "09186a90-93f1-404e-87eb-39e7a359783f",
                "node_type": "1",
                "metadata": {},
                "hash": "5cbd0521b10fe0b496275e511349766fb177e1bc254449faa5cfb9e9cc17cb06",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "recursive introspection teaching language model agents howtoselfimprove learning problem since a weak model need to internalize the mistakes of a stronger model resulting in hallucinations and memorization  24 note that training on these data does not degrade singleturn performance either this hints at an added benefit of training with rise weaktostrong generalization which can be quite useful in practice when rolling out stronger models is expensive b additional results b1 complete comparisons and discussion extended version of table 1 we provide an extended version of table 1 with a clear explanation of how we implement baselines and a discussion of comparisons approachgsm8k 10 math18 wo oracle w oracle wo oracle w oracle m1t1m5t1m1t5 p1t5 m1t1m5t1m1t5 p1t5 rise ours llama2 base 105 228 123 11106 13934 19 51 32 1405 2304 boost 329 454 125 39263 555226 55 68 13 5500 14691 iteration 1 356 497 141 507151 639283 63 88 25 9734 194131 iteration 2 373 510 137 550177 684311 58 104 46 10446 198140 rise ours mistral7b 337 494 157 39053 469132 75 130 55 8409 13055  iteration 1 353 506 153 592239 686333 67 95 28 184111 297224 sft on oracle data only correct data 274 422 149 34066 436162 58 79 21 5503 12162 correct and incorrect 257 418 161 31255 415158 50 52 02 5000 13181 baselines gpt35 664 806 142 71046 74783 397 478 81 45154 543146 mistral7b 337 494 157 39053 469132 75 130 55 8409 13055 eurus7bsft 363 663 300 479116 531168 123 198 75 16340 229106 selfrefine m1t3p1t3 m1t3p1t3 base 105 224 119 7134 13025 19 51 32 1900 3112 boost 329 453 124 26564 40980 55 65 10 2926 7217 iteration1 356 495 139 31739 43781 63 87 24 5904 9936 iteration2 373 505 132 33340 44572 58 94 36 5701 9537 gpt35 664 802 138 61054 71652 397 465 68 36532 46770 mistral7b 337 485 148 212125 37942 75 123 48 7104 11439 eurus7bsft 363 659 296 262101 42865 123 194 71 9033 15128 glore m1t3p1t3 orm 482 495 13 57189 sorm 482 516",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 1912,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "09186a90-93f1-404e-87eb-39e7a359783f",
        "embedding": null,
        "metadata": {
            "page_label": "24",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "000c7321-6d14-4311-ba9d-2c4a5d426341",
                "node_type": "4",
                "metadata": {
                    "page_label": "24",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "6cd91a4db00ce0d1f350ab980954203536fa5677a3b99e2d352eea217d5ddf7d",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "a063ddc9-0efc-47d9-8929-59108bff1584",
                "node_type": "1",
                "metadata": {
                    "page_label": "24",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "32169a8b9b00d69fa2260c8d8f473c44eb95a3e0eebd2f8987e04344d6119e01",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "363 659 296 262101 42865 123 194 71 9033 15128 glore m1t3p1t3 orm 482 495 13 57189 sorm 482 516 34 597115 na direct 482 474 08 592110 vstar m64t1 star 280 461 181 verification 280 562 282 na vstar 280 632 352 table 6 comparing rise with other approaches selfrefine glore and vstar and other baseline approaches observe that rise attains the biggest performance improvements between 1turn and 5turn performance without the use of an oracle on both gsm8k and math this performance gap is even larger when oracle early termination is allowed 5turn w oracle selfrefine largely degrades performance across the board glore trains a separate refinement model but still performs worse than rise 24",
        "mimetype": "text/plain",
        "start_char_idx": 1817,
        "end_char_idx": 2506,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "5911f217-2195-46af-a001-349ad0014918",
        "embedding": null,
        "metadata": {
            "page_label": "25",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "93d1823a-ab0d-4997-bb26-1b6f89aa6fa9",
                "node_type": "4",
                "metadata": {
                    "page_label": "25",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "6676f8c82497c5d38ef76ee0e68d09b2efa4d79ce76ea10992c82abe7c1e8193",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "recursive introspection teaching language model agents howtoselfimprove comparison with selfrefine  31to build a selfrefine baseline  31 evaluation we slightly modified our evaluation pipeline following the selfrefine approach in this setup figure 11 the model generates an initial response and then the environment prompts the model to locate errors in the generated solution and refine its answer based on the initial response and the identified error selfrefine system you are an ai language model designed to assist with math problemsolving in this task i will provide you with math problems your goal is to solve the problem stepbystep showing your reasoning at each step after you have finished solving the problem present your final answer as boxedyour answer oneshot example 17  userquery  agentinitial answer  user there is an error in the solution above because of lack of understanding of the question what istheerror tofindtheerrorgothrougheachstepofthesolutionandcheckifeverythinglooksgood agentcritic  user now rewrite the solution in the required format agentrefined answer  figure11prompt for selfrefine  we follow the standard pipeline of the original paper prompt the llm to refine and correct its previous mistakes however our experiments show that without any oracle hint from the environment or human feedback the selfrefine approach leads to a degradation in performance across all models only when oracle feedback is available to assist with early termination does the selfrefine approach provide a slight performance boost this highlights the limitation of the selfrefine structure in effectively improving model performance without external guidance which is also observed in 22 in contrast the model trained with rise can attain consistent performance improvements without relying on an oracle by training the model to iteratively refine its responses our method enables the model to selfcorrect and improve its performance over multiple turns this showcases the effectiveness of our approach incomparison to the selfrefine baseline as it allows for more robust and consistent performance gains without the need for the oracle assistance comparison with glore  17glore is a multimodel system that relies on a student model to propose drafts an outcomebased reward model orm or stepwise orm to locate errors at different granularity levels and a global or local refinement model for adjusting these errors since no code was openly available for this approach in our experiments we compared to the numbers from the main paper havrilla et al 17 while the comparison against glore is already applestooranges since our 25",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 2642,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "67cbb0b4-72e4-4ce1-ab1d-9a4e445af14f",
        "embedding": null,
        "metadata": {
            "page_label": "26",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "dbf5cf06-be85-420e-b1aa-bd8bcc55d25a",
                "node_type": "4",
                "metadata": {
                    "page_label": "26",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "2c26fcb4c7f2bf598682d60295ab094546886ca65aa272de42063ae84855b534",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "recursive introspection teaching language model agents howtoselfimprove method only trains a single endtoend model while glore trains multiple models performancewise glores global and local refinement models show little to no improvement in overall accuracy without an oracle and even exhibit decreasing accuracy in some cases however when an oracle is used to guide the refinement process glore demonstrates a 10 improvement on the 7b model in the gsm8k dataset as anticipated since we run rise from a less advanced base model llama2 7b we observe a slightly lower absolute performance compared to glore however rise demonstrates its effectiveness in self improvement by sequentially enhancing its performance by an impressive 134 within just 3 turns without an oracle feedback and by a remarkable 234 with an oracle on gsm8k this showcase of rises capabilities is particularly noteworthy considering that glore utilizes 3 independent models  one for generating candidate solutions one reward model for locating errors and one refinement model for refinement comparison with vstar  19vstar requires training an additional verifier model to rank candidate answers generated by the targeted model but it does not make any sequential revisions or improvements to a response while comparing rise to using a verifier for reranking the top 5 responses at the first turn as a base comparison would have been informative we were unable to find this specific result in the original vstar paper the results presented in the official table 6 for vstar correspond to running 64 samples which improves the base models performance by 352 for each prompt during evaluation in contrast our method rise after the same amount of finetuning iterations 3 iterations and using only 5 samples improves upon the base model by 445 calculated as 550  105  445 this comparison highlights rises efficiency in achieving significant improvements with fewer samples and iterations compared to vstars approach of using a large number of samples without sequential refinement moreover vstars performance is inherently bounded by the candidate generators performance as discussed in section 5 if there is no correct response among the generated candidates the problem remains unsolved in contrast we show in figure 6 that rise can also solve problems that were not solved by majority voting with a much higher budget in the first turn furthermore we believe that combining vstar with rise could lead to even better performance as rise can generate better models and a verifier can be complementarily used for filtering comparison with other base models mistral7b  23 and eurus7bsft  58 are models that exhibit comparable performance to our method in terms of the absolute maj5 performance however it is crucial to note that these base models are finetuned using a vast amount of data including data specifically tuned for math reasoning performance  58 while our model is finetuned on a single domain that said we do show that finetuning with rise can still enhance the performance of mistral7b models to summarize our method offers several advantages over glore and vstar such as endtoend error correction with a single model superior performance with fewer samples and the ability to solve problems that cannot be solved by random sampling in the first turn although our maj1 performance is lower than glores base model ei which is an applestooranges comparison our ultimate 5turn performance surpasses their best absolute performance in both oracle and nonoracle scenarios compared to other base models like mistral7b and eurus7bsft our method achieves comparable performance while being finetuned on a single domain and it can be generalized to better base models 26",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 3738,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "82b345cd-7738-4c86-8c54-bae48e3d3bd0",
        "embedding": null,
        "metadata": {
            "page_label": "27",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "9fbb53b2-677f-45fe-9960-34b190fafda5",
                "node_type": "4",
                "metadata": {
                    "page_label": "27",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "ef0e26015a96a4c4bd72dff3ae048bfb79b618a982cbdead2db20d51115adb07",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "recursive introspection teaching language model agents howtoselfimprove b2 qualitative examples from rise in this section we provide some qualitative examples showing the nature of edits made by rise on various datasets that we train on we utilize the model from iteration 2 of rise 27",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 285,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "76c1de64-f38d-4ca8-bf8f-d7e48cd1f68d",
        "embedding": null,
        "metadata": {
            "page_label": "28",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "5f267b1a-77b2-4b0a-ace1-17847eff54ed",
                "node_type": "4",
                "metadata": {
                    "page_label": "28",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "793111e6b98fdfcdf8fa0b3af241ae89a42416758f64d7789e0a402dbe9a4a8a",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "recursive introspection teaching language model agents howtoselfimprove rise example small edits query mike plays ping pong for 40 minutes in the first 20 minutes he scores 4 points in the second 20 minutes he scores 25 more points how many total points did he score turn1 response  step 1 in the first 20 minutes mike scores 4 points step 2 in the second 20 minutes mike scores 25 more points than he did in the first 20 minutes somikescores448pointsinthesecond20minutes step 3 to find the total points we need to add the points scored in the first and second 20 minutes total_points  4  8  12 answer 12 turn2 response  i apologize for the mistake lets solve the problem step by step step 1 in the first 20 minutes mike scores 4 points step 2 in the second 20 minutes mike scores 25 more points than he did in the first 20 minutes thismeanshescores4425415pointsinthesecond20minutes step 3 to find the total points we add the points scored in the first and second 20 minutes 4  5  9 points answer 9 rise example big edits query in a candy machine there are 22 more than four times the number of pink gumballs as there are blue gumballs if there are 12 blue gumballs how many pink ones are there turn1 response  step 1 lets assume the number of blue gumballs as x step 2 according to the given information there are 22 more than four times the number of pink gumballs as there are blue gumballs so the number of pink gumballs can be expressed as 4x  22 step3wearegiventhatthereare12blue gumballssoletssubstitutexwith12intheequation answer 54 turn2 response  lets solve the problem step by step step 1 lets denote the number of blue gumballs as x step 2 we are given that the number of pink gumballs is 22 more than four times the number of blue gumballs so the number of pink gumballs can be expressed as 4x  22 step3wearealsogiven thatthereare12bluegumballssowecansubstitutex12intotheexpressionforthenumberof pinkgumballs41222482270thereforethereare boxed70 pinkgumballs answer 70 figure12examples of rise correct its previous behavior in different modes some only make changes to a small part small edits some may directly rewrite most of its previous answers big edits because the first step in the previous answer is wrong the mistaken steps of different turns are highlighted in red and the correct are highlighted in green this demonstrates shows how rise can correct its previous answers and finally get to a correct answer 28",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 2432,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "46458419-d65e-487f-8778-255b94bc2f4b",
        "embedding": null,
        "metadata": {
            "page_label": "29",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "bcb366fc-a8f1-47a0-8880-2e608e6dbfa1",
                "node_type": "4",
                "metadata": {
                    "page_label": "29",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "05f282d43b4e641c7f89589c5def43e8e692aeecccdb6f0c3706733c8645e8c7",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "603b23e6-a421-4fd5-9871-6962cbd52324",
                "node_type": "1",
                "metadata": {},
                "hash": "f9f76e549d9d68958db94a634454230f2905f9944afcc4ae2fac7aa7f7cf65c4",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "recursive introspection teaching language model agents howtoselfimprove rise example noise tolerance query ryan plants 2 flowers a day in his garden after 15 days how many flowers does he have if 5 did not grow turn1 response  step 1 ryan plants 2 flowers a day for 15 days so he plants a total of 2 flowersday  15 days  30 flowers in his garden step 2 however 5 flowers did not grow so we need to subtract these nongrowing flowers from the total count step 3 calculate the number of flowers that actually grew in ryans garden flowers_grew  30 flowers  5 flowers  25 flowers answer 25 turn2 response  apologies for the mistake lets correct the solution step 1 in 15 days ryan plants 2 flowers a day so he plants a total of 2 flowersday  15 days  30 flowers in his garden step 2 since 5 flowers did not grow we need to subtract these nongrowing flowers from the total count step 3 calculate the number of flowers that actually grew in ryans garden flowers_grew  30 flowers  5 flowers  25 flowers answer 25 turn3 response  lets reevaluate the solution step 1 ryan plants 2 flowers a day for 15 days so he plants a total of 2 flowersday  15 days  30 flowers in his garden step 2 however 5 flowers did not grow so we need to add these flowers to the total count as they were planted but did not grow step3calculatethetotalnumberofflowersinryansgardentotal_flowers 30flowers5flowers35flowers answer 35 turn4 response lets correct the solution step 1 in 15 days ryan plants 2 flowers a day so he plants a total of 2 flowersday  15 days  30 flowers in his garden step 2 since 5 flowers did not grow we need to subtract these nongrowing flowers from the total count step 3 calculate the total number of flowers in ryans garden after subtracting the nongrowing flowers total_flowers  total_planted_flowers  non_growing_flowers  30 flowers  5 flowers boxed25 flowers answer 25 turn5 response lets reevaluate the solution step 1 in 15 days ryan plants 2 flowers a day which is 2 flowersday  15 days  30 flowers in total step 2 however 5 flowers did not grow so we have to subtract these 5 flowers from the total step 3 therefore the total number of flowers ryan has is 30 flowers total planted  5 flowers did not grow  boxed25 flowers answer 25 figure13examples of rises tolerance of noisy feedback  in the evaluation where there is no oracle we use a verifier that always tells the model the answer is incorrect please try again heres the question query  we observe that from turn 2 to turn 5 the model is still able to output the correct answer in 3 out of 4 turns in the response at turn 4 the model performs half of the solution correctly and only the last step is wrong in addition in the turns where the model still outputs the correct answer it doesnt directly copy the answer from the previous turn but instead comes up with a new paraphrase this demonstrates that rise provides the model with tolerance to noisy feedback and does not randomly change its behavior upon receiving a revisiting request the mistaken steps of different",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 3028,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "603b23e6-a421-4fd5-9871-6962cbd52324",
        "embedding": null,
        "metadata": {
            "page_label": "29",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "bcb366fc-a8f1-47a0-8880-2e608e6dbfa1",
                "node_type": "4",
                "metadata": {
                    "page_label": "29",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "05f282d43b4e641c7f89589c5def43e8e692aeecccdb6f0c3706733c8645e8c7",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "46458419-d65e-487f-8778-255b94bc2f4b",
                "node_type": "1",
                "metadata": {
                    "page_label": "29",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "b07ea631079f14ee176e93e270e68c38b0c98e2ae7a84d4b9456d65d84d15534",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "answer it doesnt directly copy the answer from the previous turn but instead comes up with a new paraphrase this demonstrates that rise provides the model with tolerance to noisy feedback and does not randomly change its behavior upon receiving a revisiting request the mistaken steps of different turns are highlighted in red 29",
        "mimetype": "text/plain",
        "start_char_idx": 2731,
        "end_char_idx": 3060,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "9f06f4a5-206f-4fba-947b-bbfca5986cee",
        "embedding": null,
        "metadata": {
            "page_label": "30",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "8b487056-c8ed-45d7-bec5-5f6a897c2cc8",
                "node_type": "4",
                "metadata": {
                    "page_label": "30",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "00f862a3ea56c4c9b7366de1d7ba40ec549ef1b1e128a1a4a085407961c99f28",
                "class_name": "RelatedNodeInfo"
            },
            "3": {
                "node_id": "feda84ad-f051-49cc-b2fa-f7a40b477cef",
                "node_type": "1",
                "metadata": {},
                "hash": "fbee2ea3849dc3d339e5af298b407859044c842eb45fcee8f27cbeb29be93c1a",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "recursive introspection teaching language model agents howtoselfimprove rise example error localization query josh decides to try flipping a house he buys a house for 80000 and then puts in 50000 in repairs this increased the value of the house by 150 how much profit did he make turn1 response  step 1 josh buys a house for 80000 step 2 he puts in 50000 in repairs which increases the value of the house by 150 step 3 to calculate the increase in value we multiply the cost of the house by 150 and add it to the cost of the house increase_in_value  80000  150  120000 step4tocalculatetheprofitwesubtractthecostofthe housefromitsnewvalueprofitincrease_in_value 80000 120000 80000 40000 answer 40000 turn2 response  lets solve the problem stepbystep step 1 josh buys a house for 80000 step 2 he puts in 50000 in repairs and this increases the value of the house by 150 step 3 the percentage increase in value is 150 of 80000 which is 120000 80000  15  120000 step4tofindtheactualamount thatwouldbeaddedtothehousesvalueafter repairsweneedtosubtracttheamount hespentonrepairsfromtheincreased valuewhichis120000 50000  70000 step5theprofitjoshwouldmakeisthedifferencebetweenthecostofbuyingthehouseandtheincreased valueafterrepairswhichis70000 80000 10000 10000 lessthantheinitialcost answer 0 turn3 response  lets solve the problem stepbystep step 1 josh buys a house for 80000 step 2 he puts in 50000 in repairs step 3 this increases the value of the house by 150 step 4 to find the increase in value we calculate 150 of the original price of the house 150 of 80000  120000 step5theincreaseinvalueafterrepairsistheoriginal priceplus150oftheoriginalprice80000 120000 200000 step6joshsellsthehousefor200000 and madeaprofitof200000 80000 120000 answer 120000 turn4 response  lets solve the problem stepbystep step 1 josh buys a house for 80000 step 2 he puts in 50000 in repairs increasing the value of the house by 150 step 3 the increase in value is 150 of 80000 which is 120000 80000  15  120000 step4thetotalamount spentincludingthepurchaseofthehouseandthe repairsis80000 50000 130000 step5theprofitjoshmadeistheincreaseinvalueafterrepairsminusthe totalamount spentwhichis120000 130000 10000 thereforejoshmadea boxed0 profit answer 0 turn5 response  lets solve the problem stepbystep step 1 josh buys a house for 80000 step 2 he puts in 50000 in repairs step 3 the repairs increase the value of the house by 150 step 4 the increase in value is 50000 which is 150 of 33333 50000  15  33333 step 5",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 2493,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "feda84ad-f051-49cc-b2fa-f7a40b477cef",
        "embedding": null,
        "metadata": {
            "page_label": "30",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "8b487056-c8ed-45d7-bec5-5f6a897c2cc8",
                "node_type": "4",
                "metadata": {
                    "page_label": "30",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "00f862a3ea56c4c9b7366de1d7ba40ec549ef1b1e128a1a4a085407961c99f28",
                "class_name": "RelatedNodeInfo"
            },
            "2": {
                "node_id": "9f06f4a5-206f-4fba-947b-bbfca5986cee",
                "node_type": "1",
                "metadata": {
                    "page_label": "30",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "f5e489c5dbb8618414446c55369893ee508d5d30c8213e389896010d54cbf647",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "in repairs step 3 the repairs increase the value of the house by 150 step 4 the increase in value is 50000 which is 150 of 33333 50000  15  33333 step 5 the repairs cost 50000 and the increase in value is 33333 step 6 therefore joshs profit is 33333  50000  16667 therefore josh made a 16676 profit answer 16676  figure14examplesofrisenotbeingabletocorrectitserrorwithin5stepsbutdemonstratingmeaningful errorlocalization behavior  even in turn 2 it has already solved the problem at step 4 but mistakenly takes another step and reaches the wrong answer the following turns are unable to correct this small error though this problem remains unsolved we observe that 1 the model is able to stick to the correct steps where all responses reach an intermediate step of 12000 correctly except for the last response where the model tries to modify the answer from one step ahead 2 the model doesnt repeat its responses which is a behavior we notice when evaluating some offtheshelf models and 3 the model is making meaningful changes to the incorrect steps in summary although the final answer is still incorrect we observe that through rise the model is able to locate the error and perform local computation correctly the mistaken steps of different turns are highlighted in red and the correct steps in turn 2 is highlighted in green 30",
        "mimetype": "text/plain",
        "start_char_idx": 2341,
        "end_char_idx": 3674,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "f2fe8e50-9230-4ebf-bd1d-2d40a28770c8",
        "embedding": null,
        "metadata": {
            "page_label": "31",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "e67a7cfd-b9d4-4f72-a0d0-441622bda9c9",
                "node_type": "4",
                "metadata": {
                    "page_label": "31",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "b16f14039012121b4b5982848b93b6023c9dc895204d5fe9a034b9489f401760",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "recursive introspection teaching language model agents howtoselfimprove c pseudocode algorithm 1 data collection at iteration \ud835\udc47 1\ud835\udc9f \ud835\udc47\ud835\udc9f \ud835\udc471 2forindex \ud835\udc56in1    \ud835\udc9fdo 3 \ud835\udc601\ud835\udc65\ud835\udc56 4forstep\ud835\udc47in1     \ud835\udc471do 5 \ud835\udc66\ud835\udc56 \ud835\udc47arg max \ud835\udf0b\ud835\udf03\ud835\udc471\ud835\udc60\ud835\udc56 \ud835\udc61\ud835\udc66\ud835\udc56 \ud835\udc61\ud835\udc53\ud835\udc56\ud835\udc471 \ud835\udc611\ud835\udc60\ud835\udc47 6 \ud835\udc60\ud835\udc56 \ud835\udc471\ud835\udc5f\ud835\udc56 \ud835\udc47envstep \ud835\udc60\ud835\udc56 \ud835\udc47\ud835\udc66\ud835\udc56 \ud835\udc47 7 \ud835\udc53\ud835\udc56 \ud835\udc47retry message \ud835\udc65\ud835\udc56 8 if\ud835\udc5f\ud835\udc56 \ud835\udc47 1then 9 break 10 end if 11end for 12if\ud835\udc5f\ud835\udc56 \ud835\udc47 1then 13 \ud835\udc47\ud835\udc47 1 14 \ud835\udc66\ud835\udc56 \ud835\udc47arg max  \ud835\udf0b\ud835\udc60\ud835\udc56 \ud835\udc61\ud835\udc66\ud835\udc56 \ud835\udc61\ud835\udc53\ud835\udc56\ud835\udc471 \ud835\udc611\ud835\udc60\ud835\udc47 15 \ud835\udc60\ud835\udc56 \ud835\udc471\ud835\udc5f\ud835\udc56 \ud835\udc47envstep \ud835\udc60\ud835\udc56 \ud835\udc47\ud835\udc66\ud835\udc56 \ud835\udc47 16end if 17\ud835\udc9f \ud835\udc47\ud835\udc9f \ud835\udc47 \ud835\udc60\ud835\udc56 \ud835\udc61\ud835\udc66\ud835\udc56 \ud835\udc61\ud835\udc53\ud835\udc56 \ud835\udc61\ud835\udc5f\ud835\udc56 \ud835\udc61\ud835\udc47 \ud835\udc611 18end for algorithm 2 inference at iteration \ud835\udc47 1forindex \ud835\udc56in1    \ud835\udc9fdo 2 \ud835\udc601\ud835\udc65\ud835\udc56 3forstep\ud835\udc47in1     \ud835\udc41do 4 \ud835\udc66\ud835\udc56 \ud835\udc47arg max \ud835\udf0b\ud835\udf03\ud835\udc47\ud835\udc60\ud835\udc56 \ud835\udc61\ud835\udc66\ud835\udc56 \ud835\udc61\ud835\udc53\ud835\udc56\ud835\udc471 \ud835\udc61max1\ud835\udc47\ud835\udc47\ud835\udc60\ud835\udc47 5 \ud835\udc60\ud835\udc56 \ud835\udc471\ud835\udc5f\ud835\udc56 \ud835\udc47envstep \ud835\udc60\ud835\udc56 \ud835\udc47\ud835\udc66\ud835\udc56 \ud835\udc47 6 \ud835\udc53\ud835\udc56 \ud835\udc47retry message \ud835\udc65\ud835\udc56 7end for 8forstep\ud835\udc47in1     \ud835\udc41do 9 \ud835\udc66\ud835\udc56 \ud835\udc47majority voting\ud835\udc66\ud835\udc56 \ud835\udc61\ud835\udc47 \ud835\udc611 10end for 11end for 31",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 714,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "10d6d087-e08e-44f4-a2bb-ad1324b0eb79",
        "embedding": null,
        "metadata": {
            "page_label": "32",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "80e42364-0dcd-48f9-8407-004c337ffb51",
                "node_type": "4",
                "metadata": {
                    "page_label": "32",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "6f1a4fc6371a462437bad153faed6468cd02a72b601f0a34b47d6c63dfc1aa23",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "recursive introspection teaching language model agents howtoselfimprove d experimental details d1 hyperparameters for finetuning with rise for finetuning we utilize the fastchat codebase but we customize the loss function to be weighted by reward the base models are directly loaded from hugging face hrefhttpshuggingfacecometa llamallama27bhfllama27bchathf and mistral7binstructv02 the hyperparameters used for finetuning are specified in table 7 hyperparameter values bf16 true epochs 2 per device train batch size 1 gpus 4xa40 gradient accumulation steps 16 learning rate 1e5 weighted decay 0 warmup ratio 004 learning rate scheduler trype cosince tf32 true model max length 2048 table 7 hyperparameters used for rise d2 inference hyperparameters for apibased models such as gpt35 we directly query the official web api provided by openai in the case of opensource models we utilize fastchat to serve the model as a web api and interact with the environment through api calls serving a 7b model requires a single a100 or a40 gpu to control the randomness and length of answers generated by the llms we employ the hyperparameters specified in table 8 hyperparametersdescription opensource gpt temperature 10 07 top_p 10 1 max_new_tokens 1000 512 table 8 the hyperparameter settings used for generating responses from opensource and the gpt models d3 datasets the gsm8k dataset consists of 7473 problems in the training portion and 1319 problems in the testing portion similarly the math dataset is divided into 7500 problems for training and 1000 problems 32",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 1560,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "5fa0142b-a74c-48e6-9c8c-73a9e2158e63",
        "embedding": null,
        "metadata": {
            "page_label": "33",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "92475c36-b582-448e-8793-7c79ce7f8765",
                "node_type": "4",
                "metadata": {
                    "page_label": "33",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "bee91e674f1348caebdba47200507a684748957aeadf69bf56254c7daaa80e45",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "recursive introspection teaching language model agents howtoselfimprove for testing the training portions of both datasets are used to generate trajectories in each iteration of the rise method while the testing portions are held out for evaluating the performance of the models additionally the svamp dataset containing 1000 problems is used solely for evaluation purposes to demonstrate the generalizability of our method for generating training trajectories at iteration \ud835\udc56 the current model is rolled out for a maximum of \ud835\udc56 steps subsequently an expert model such as gpt35 is employed to take the conversation history between the current model and the environment and sample 5 responses among these responses the one with the highest reward is chosen with arbitrary tiebreaking in case of multiple responses with the same highest reward d4 prompts used for seeding rise on the gsm8k and math tasks here we show the prompt we used for data generation and model evaluation rise system you are an ai language model designed to assist with math problemsolving in this task i will provide you with math problems your goal is to solve the problem stepbystep showing your reasoning at each step after you have finished solving the problem present your final answer as boxedyour answer oneshot example 16  userquery  agentanswer  user the answer is incorrect please try again heres the question query  agentanswer   figure15prompt for rise  we follow the standard pipeline of math problem solving prompt the llm to solve the problem and retry untill exceeds the maximum number of turns 33",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 1583,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "d82b948a-97d8-46fd-98a9-1f5bfc56b110",
        "embedding": null,
        "metadata": {
            "page_label": "34",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "65ec0cff-1558-4ffc-9647-722354ac435c",
                "node_type": "4",
                "metadata": {
                    "page_label": "34",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "25827bf53f430cfb29f5813a5f657e03111e91d642106e46b9f815f44da41411",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "recursive introspection teaching language model agents howtoselfimprove d5 oneshot example rise oneshot example user of the 60 students in the drama club 36 take mathematics 27 take physics and 20 students take both mathematics and physics how many drama club students take neither mathematics nor physics agent step 1 to find the number of drama club students who take neither mathematics nor physics we first need to determine the number of students taking only math only physics and both math and physics step 2 out of the 60 students in the drama club 36 take mathematics and 27 take physics and 20 students take both mathematics and physics step 3 to calculate the number of students taking only math we subtract the number of students taking both from the total taking math 36  20  16 step 4 similarly to calculate the number of students taking only physics we subtract the number of students taking both from the total taking physics 27  20  7 step 5 now to find the number of students taking neither math nor physics we subtract the total number of students taking only math only physics and both from the total number of students in the drama club this gives us 60  16  7  20  boxed17 students taking neither answerboxed17 figure16oneshot example  demonstrates how to solve a math problem stepbystep and the expected answer format 34",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 1342,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    },
    {
        "id_": "bb35a621-5ccf-4249-a428-e3e30d4a3274",
        "embedding": null,
        "metadata": {
            "page_label": "35",
            "file_name": "Recursive Introspection.pdf",
            "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
            "file_type": "application/pdf",
            "file_size": 4684689,
            "creation_date": "2024-08-12",
            "last_modified_date": "2024-08-12"
        },
        "excluded_embed_metadata_keys": [],
        "excluded_llm_metadata_keys": [],
        "relationships": {
            "1": {
                "node_id": "683056e0-1a2d-4491-9175-9bdda16ca6cd",
                "node_type": "4",
                "metadata": {
                    "page_label": "35",
                    "file_name": "Recursive Introspection.pdf",
                    "file_path": "C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\Recursive Introspection.pdf",
                    "file_type": "application/pdf",
                    "file_size": 4684689,
                    "creation_date": "2024-08-12",
                    "last_modified_date": "2024-08-12"
                },
                "hash": "d9714dd09d74bda7f2d12eacfc17c4d052bb317c395687c5bb36ba8a475ec9fe",
                "class_name": "RelatedNodeInfo"
            }
        },
        "text": "recursive introspection teaching language model agents howtoselfimprove selfrefine oneshot example user of the 60 students in the drama club 36 take mathematics 27 take physics and 20 students take both mathematics and physics how many drama club students take neither mathematics nor physics agent step 1 to find the number of drama club students who take neither mathematics nor physics we first need to determine the number of students taking only math only physics and both math and physics step 2 out of the 60 students in the drama club 36 take mathematics and 27 take physics and 20 students take both mathematics and physics step 3 to calculate the number of students taking only math we subtract the number of students taking both from the total taking math 36  20  16 step 4 similarly to calculate the number of students taking only physics we subtract the number of students taking both from the total taking physics 27  20  7 step 5 now to find the number of students taking neither math nor physics we add the number of students taking only math and only physics then subtract this sum from the total number of students in the drama club this gives us 60  16  7  boxed37 students taking neither answerboxed37 user there is an error in the solution above because of lack of understanding of the question what istheerror tofindtheerrorgothrougheachstepofthesolutionandcheckifeverythinglooksgood agent step 1 correct we need to find the number of students taking neither math nor physics step 2 correct the given information is accurately stated step 3 correct the calculation of students taking only math is correct step 4 correct the calculation of students taking only physics is correct step 5 incorrect the solution adds the number of students taking only math and only physics but this does not account for the students taking both subjects by subtracting this sum from thetotalnumberofstudentsthesolutiondoublecountsthestudentswhotakebothmathandphysics user now rewrite the solution in the required format agentsame as 16  figure17oneshot example  demonstrates the process of selfcritique and error correction based on the selfcritique 35",
        "mimetype": "text/plain",
        "start_char_idx": 0,
        "end_char_idx": 2155,
        "text_template": "{metadata_str}\n\n{content}",
        "metadata_template": "{key}: {value}",
        "metadata_seperator": "\n",
        "class_name": "TextNode"
    }
]