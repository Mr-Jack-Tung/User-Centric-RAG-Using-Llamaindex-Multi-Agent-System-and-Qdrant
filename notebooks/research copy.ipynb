{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from llama_index.core.schema import Document\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core import SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def documents_transformation(input_dir: str):\n",
    "        print(f\"Input directory: {input_dir}\")\n",
    "        documents = SimpleDirectoryReader(input_dir=input_dir).load_data()\n",
    "        print(f\"Loaded {len(documents)} documents\")\n",
    "        transformed_documents = []\n",
    "        for doc in documents:\n",
    "            transformed_content = doc.get_content().lower()\n",
    "            transformed_content = re.sub(r'\\s+', ' ', transformed_content)\n",
    "            transformed_content = re.sub(r'[^\\w\\s]', '', transformed_content)\n",
    "            transformed_documents.append(Document(text=transformed_content, metadata=doc.metadata))\n",
    "        print(f\"Transformed {len(documents)} documents\")\n",
    "        return transformed_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_documents_into_nodes(documents, chunk_size, chunk_overlap):\n",
    "        try:\n",
    "            splitter = SentenceSplitter(\n",
    "                chunk_size=chunk_size,\n",
    "                chunk_overlap=chunk_overlap\n",
    "            )\n",
    "            nodes = splitter.get_nodes_from_documents(documents)\n",
    "            return nodes\n",
    "        except Exception as e:\n",
    "            print(f\"Error splitting documents into nodes: {e}\")\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_nodes(nodes):\n",
    "        try:\n",
    "            output_file = r\"C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\nodes.json\"\n",
    "            os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "            nodes_dict = [node.dict() for node in nodes]\n",
    "            with open(output_file, 'w') as file:\n",
    "                json.dump(nodes_dict, file, indent=4)\n",
    "            print(f\"Saved nodes to {output_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving nodes to file: {e}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document(input_dir: str, chunk_size: int, chunk_overlap: int) -> None:\n",
    "        input_dir = rf\"{input_dir}\"\n",
    "        documents = documents_transformation(input_dir)\n",
    "        print(\"Document Transformation is done\")\n",
    "        nodes = split_documents_into_nodes(documents, chunk_size, chunk_overlap)\n",
    "        print(\"Transformed into nodes\")\n",
    "        save_nodes(nodes)\n",
    "        print(\"saved the nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_documents(input_dir: str) -> None:\n",
    "        input_dir = rf\"{input_dir}\"\n",
    "        documents = documents_transformation(input_dir)\n",
    "        print(\"Document Transformation is done\")\n",
    "        \n",
    "        return documents\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = r'C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input directory: C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\n",
      "Loaded 67 documents\n",
      "Transformed 67 documents\n",
      "Document Transformation is done\n",
      "Transformed into nodes\n",
      "Saved nodes to C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\nodes.json\n",
      "saved the nodes\n"
     ]
    }
   ],
   "source": [
    "process_document(input_dir, 1500, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "from fastembed import SparseTextEmbedding, TextEmbedding\n",
    "from qdrant_client import QdrantClient, models\n",
    "from qdrant_client.http.models import PointStruct, SparseVector\n",
    "from tqdm import tqdm\n",
    "\n",
    "from typing import List\n",
    "import pprint\n",
    "from colorama import Fore, Back, Style\n",
    "\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environmental variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "Qdrant_API_KEY = os.getenv('Qdrant_API_KEY')\n",
    "Qdrant_URL = os.getenv('Qdrant_URL')\n",
    "Collection_Name = os.getenv('Collection_Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nodes():\n",
    "        metadata = []\n",
    "        documents = []\n",
    "        payload_file = r'C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\nodes.json'\n",
    "\n",
    "        try:\n",
    "            with open(payload_file, 'r') as file:\n",
    "                nodes = json.load(file)\n",
    "\n",
    "            for node in nodes:\n",
    "                metadata.append(node['metadata'])\n",
    "                documents.append(node['text'])\n",
    "\n",
    "            logging.info(f\"Loaded {len(nodes)} the nodes from JSON file\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error loading nodes from JSON file: {e}\")\n",
    "            raise\n",
    "\n",
    "        return documents, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_collection(embedding_model, documents, metadata):\n",
    "        qdrant_client = QdrantClient(\n",
    "            url=Qdrant_URL,\n",
    "            api_key=Qdrant_API_KEY)\n",
    "\n",
    "        embedding_model = TextEmbedding(model_name=embedding_model)\n",
    "        sparse_embedding_model = SparseTextEmbedding(model_name=\"prithivida/Splade_PP_en_v1\")\n",
    "        qdrant_client.set_model(embedding_model)\n",
    "        qdrant_client.set_sparse_model(sparse_embedding_model)\n",
    "\n",
    "        try:\n",
    "            qdrant_client.recreate_collection(\n",
    "                collection_name=\"Hybrid_RAG_Collection\",\n",
    "                vectors_config=qdrant_client.get_fastembed_vector_params(),\n",
    "                sparse_vectors_config=qdrant_client.get_fastembed_sparse_vector_params(),\n",
    "            )\n",
    "\n",
    "            ids = qdrant_client.add(\n",
    "                collection_name=\"Hybrid_RAG_Collection\",\n",
    "                documents=documents,\n",
    "                metadata=metadata,\n",
    "                ids=tqdm(range(len(documents))),\n",
    "            )\n",
    "\n",
    "            logging.info(f\"Inserted {len(ids)} vectors into Qdrant cluster\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error inserting vectors into Qdrant cluster: {e}\")\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexing(embedding_model):\n",
    "        documents, metadata = load_nodes()\n",
    "        logging.info(\"Loaded the nodes from json file\")\n",
    "        client_collection(embedding_model, documents, metadata)\n",
    "        logging.info(\"Inserted the documents into the Qdrant Cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_client = QdrantClient(\n",
    "            url=Qdrant_URL,\n",
    "            api_key=Qdrant_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4773e4ee11f54e4f89729f52cecabe90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0765679ff3740b880f546ec57d5de69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qdrant_client.set_model(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "# comment this line to use dense vectors only\n",
    "qdrant_client.set_sparse_model(\"prithivida/Splade_PP_en_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pavan\\AppData\\Local\\Temp\\ipykernel_18788\\4029956761.py:1: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  qdrant_client.recreate_collection(\n",
      "INFO:httpx:HTTP Request: DELETE https://c77ac75e-3a41-4acc-98d2-c9c3eb11b5ea.us-east4-0.gcp.cloud.qdrant.io:6333/collections/Hybrid_RAG_Collection \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT https://c77ac75e-3a41-4acc-98d2-c9c3eb11b5ea.us-east4-0.gcp.cloud.qdrant.io:6333/collections/Hybrid_RAG_Collection \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdrant_client.recreate_collection(\n",
    "    collection_name=\"Hybrid_RAG_Collection\",\n",
    "    vectors_config=qdrant_client.get_fastembed_vector_params(),\n",
    "    # comment this line to use dense vectors only\n",
    "    sparse_vectors_config=qdrant_client.get_fastembed_sparse_vector_params(),  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "input_file = r\"C:\\Users\\pavan\\Desktop\\Generative AI\\RAG-Automation-Using-Llamaindex-Agents-and-Qdrant\\data\\nodes.json\"\n",
    "metadata = []\n",
    "documents = []\n",
    "\n",
    "with open(input_file, 'r') as file:\n",
    "        nodes = json.load(file)\n",
    "\n",
    "for node in nodes:\n",
    "    metadata.append(node['metadata'])\n",
    "    documents.append(node['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/155 [00:00<?, ?it/s]INFO:httpx:HTTP Request: GET https://c77ac75e-3a41-4acc-98d2-c9c3eb11b5ea.us-east4-0.gcp.cloud.qdrant.io:6333/collections/Hybrid_RAG_Collection \"HTTP/1.1 200 OK\"\n",
      "  0%|          | 0/155 [01:44<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m----> 3\u001b[0m \u001b[43mqdrant_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHybrid_RAG_Collection\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\qdrant_client\\qdrant_fastembed.py:532\u001b[0m, in \u001b[0;36mQdrantFastembedMixin.add\u001b[1;34m(self, collection_name, documents, metadata, ids, batch_size, parallel, **kwargs)\u001b[0m\n\u001b[0;32m    522\u001b[0m inserted_ids: \u001b[38;5;28mlist\u001b[39m \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    524\u001b[0m points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_points_iterator(\n\u001b[0;32m    525\u001b[0m     ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[0;32m    526\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    529\u001b[0m     sparse_vectors\u001b[38;5;241m=\u001b[39mencoded_sparse_docs,\n\u001b[0;32m    530\u001b[0m )\n\u001b[1;32m--> 532\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload_points\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inserted_ids\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\qdrant_client\\qdrant_client.py:2110\u001b[0m, in \u001b[0;36mQdrantClient.upload_points\u001b[1;34m(self, collection_name, points, batch_size, parallel, method, max_retries, wait, shard_key_selector, **kwargs)\u001b[0m\n\u001b[0;32m   2085\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Upload points to the collection\u001b[39;00m\n\u001b[0;32m   2086\u001b[0m \n\u001b[0;32m   2087\u001b[0m \u001b[38;5;124;03mSimilar to `upload_collection` method, but operates with points, rather than vector and payload individually.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2106\u001b[0m \n\u001b[0;32m   2107\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown arguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 2110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload_points\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshard_key_selector\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshard_key_selector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2119\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\qdrant_client\\qdrant_remote.py:2591\u001b[0m, in \u001b[0;36mQdrantRemote.upload_points\u001b[1;34m(self, collection_name, points, batch_size, parallel, method, max_retries, wait, shard_key_selector, **kwargs)\u001b[0m\n\u001b[0;32m   2575\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupload_points\u001b[39m(\n\u001b[0;32m   2576\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2577\u001b[0m     collection_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2585\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   2586\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2587\u001b[0m     batches_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_updater_class\u001b[38;5;241m.\u001b[39miterate_records_batches(\n\u001b[0;32m   2588\u001b[0m         records\u001b[38;5;241m=\u001b[39mpoints, batch_size\u001b[38;5;241m=\u001b[39mbatch_size\n\u001b[0;32m   2589\u001b[0m     )\n\u001b[1;32m-> 2591\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_upload_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatches_iterator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatches_iterator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshard_key_selector\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshard_key_selector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2599\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\qdrant_client\\qdrant_remote.py:2543\u001b[0m, in \u001b[0;36mQdrantRemote._upload_collection\u001b[1;34m(self, batches_iterator, collection_name, max_retries, parallel, method, wait, shard_key_selector)\u001b[0m\n\u001b[0;32m   2541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parallel \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   2542\u001b[0m     updater \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_updater_class\u001b[38;5;241m.\u001b[39mstart(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mupdater_kwargs)\n\u001b[1;32m-> 2543\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m updater\u001b[38;5;241m.\u001b[39mprocess(batches_iterator):\n\u001b[0;32m   2544\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   2545\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\qdrant_client\\uploader\\rest_uploader.py:80\u001b[0m, in \u001b[0;36mRestBatchUploader.process\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, items: Iterable[Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Generator[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[1;32m---> 80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m items:\n\u001b[0;32m     81\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m upload_batch(\n\u001b[0;32m     82\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenapi_client,\n\u001b[0;32m     83\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollection_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     87\u001b[0m             wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait,\n\u001b[0;32m     88\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\qdrant_client\\uploader\\uploader.py:34\u001b[0m, in \u001b[0;36mBaseUploader.iterate_records_batches\u001b[1;34m(cls, records, batch_size)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miterate_records_batches\u001b[39m(\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m     30\u001b[0m     records: Iterable[Union[Record, types\u001b[38;5;241m.\u001b[39mPointStruct]],\n\u001b[0;32m     31\u001b[0m     batch_size: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m     32\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterable:\n\u001b[0;32m     33\u001b[0m     record_batches \u001b[38;5;241m=\u001b[39m iter_batch(records, batch_size)\n\u001b[1;32m---> 34\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m record_batch \u001b[38;5;129;01min\u001b[39;00m record_batches:\n\u001b[0;32m     35\u001b[0m         ids_batch, vectors_batch, payload_batch \u001b[38;5;241m=\u001b[39m [], [], []\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m record_batch:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\qdrant_client\\uploader\\uploader.py:20\u001b[0m, in \u001b[0;36miter_batch\u001b[1;34m(iterable, size)\u001b[0m\n\u001b[0;32m     18\u001b[0m source_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(iterable)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m source_iter:\n\u001b[1;32m---> 20\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(b) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\qdrant_client\\qdrant_fastembed.py:355\u001b[0m, in \u001b[0;36mQdrantFastembedMixin._points_iterator\u001b[1;34m(self, ids, metadata, encoded_docs, ids_accumulator, sparse_vectors)\u001b[0m\n\u001b[0;32m    352\u001b[0m vector_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_vector_field_name()\n\u001b[0;32m    353\u001b[0m sparse_vector_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_sparse_vector_field_name()\n\u001b[1;32m--> 355\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, meta, (doc, vector), sparse_vector \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[0;32m    356\u001b[0m     ids, metadata, encoded_docs, sparse_vectors\n\u001b[0;32m    357\u001b[0m ):\n\u001b[0;32m    358\u001b[0m     ids_accumulator\u001b[38;5;241m.\u001b[39mappend(idx)\n\u001b[0;32m    359\u001b[0m     payload \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocument\u001b[39m\u001b[38;5;124m\"\u001b[39m: doc, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmeta}\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\qdrant_client\\qdrant_fastembed.py:275\u001b[0m, in \u001b[0;36mQdrantFastembedMixin._sparse_embed_documents\u001b[1;34m(self, documents, embedding_model_name, batch_size, parallel)\u001b[0m\n\u001b[0;32m    269\u001b[0m sparse_embedding_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_or_init_sparse_model(model_name\u001b[38;5;241m=\u001b[39membedding_model_name)\n\u001b[0;32m    271\u001b[0m vectors_iter \u001b[38;5;241m=\u001b[39m sparse_embedding_model\u001b[38;5;241m.\u001b[39membed(\n\u001b[0;32m    272\u001b[0m     documents, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, parallel\u001b[38;5;241m=\u001b[39mparallel\n\u001b[0;32m    273\u001b[0m )\n\u001b[1;32m--> 275\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sparse_vector \u001b[38;5;129;01min\u001b[39;00m vectors_iter:\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m types\u001b[38;5;241m.\u001b[39mSparseVector(\n\u001b[0;32m    277\u001b[0m         indices\u001b[38;5;241m=\u001b[39msparse_vector\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[0;32m    278\u001b[0m         values\u001b[38;5;241m=\u001b[39msparse_vector\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[0;32m    279\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\fastembed\\sparse\\sparse_text_embedding.py:96\u001b[0m, in \u001b[0;36mSparseTextEmbedding.embed\u001b[1;34m(self, documents, batch_size, parallel, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21membed\u001b[39m(\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     76\u001b[0m     documents: Union[\u001b[38;5;28mstr\u001b[39m, Iterable[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     80\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterable[SparseEmbedding]:\n\u001b[0;32m     81\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03m    Encode a list of documents into list of embeddings.\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;124;03m    We use mean pooling with attention so that the model can handle variable-length inputs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;124;03m        List of embeddings, one per document\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39membed(documents, batch_size, parallel, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\fastembed\\sparse\\splade_pp.py:120\u001b[0m, in \u001b[0;36mSpladePP.embed\u001b[1;34m(self, documents, batch_size, parallel, **kwargs)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21membed\u001b[39m(\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    100\u001b[0m     documents: Union[\u001b[38;5;28mstr\u001b[39m, Iterable[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    104\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterable[SparseEmbedding]:\n\u001b[0;32m    105\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m    Encode a list of documents into list of embeddings.\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03m    We use mean pooling with attention so that the model can handle variable-length inputs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;124;03m        List of embeddings, one per document\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_documents(\n\u001b[0;32m    121\u001b[0m         model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name,\n\u001b[0;32m    122\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_dir),\n\u001b[0;32m    123\u001b[0m         documents\u001b[38;5;241m=\u001b[39mdocuments,\n\u001b[0;32m    124\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m    125\u001b[0m         parallel\u001b[38;5;241m=\u001b[39mparallel,\n\u001b[0;32m    126\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\fastembed\\text\\onnx_text_model.py:109\u001b[0m, in \u001b[0;36mOnnxTextModel._embed_documents\u001b[1;34m(self, model_name, cache_dir, documents, batch_size, parallel, **kwargs)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parallel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m is_small:\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m iter_batch(documents, batch_size):\n\u001b[1;32m--> 109\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_process_onnx_output(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39monnx_embed(batch))\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    111\u001b[0m     start_method \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforkserver\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforkserver\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m get_all_start_methods() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    113\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\fastembed\\sparse\\splade_pp.py:40\u001b[0m, in \u001b[0;36mSpladePP._post_process_onnx_output\u001b[1;34m(self, output)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_post_process_onnx_output\u001b[39m(\u001b[38;5;28mself\u001b[39m, output: OnnxOutputContext) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterable[SparseEmbedding]:\n\u001b[1;32m---> 40\u001b[0m     relu_log \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     42\u001b[0m     weighted_log \u001b[38;5;241m=\u001b[39m relu_log \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(output\u001b[38;5;241m.\u001b[39mattention_mask, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     44\u001b[0m     scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(weighted_log, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "qdrant_client.add(\n",
    "    collection_name=\"Hybrid_RAG_Collection\",\n",
    "    documents=documents,\n",
    "    metadata=metadata,\n",
    "    ids=tqdm(range(len(documents))),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexing(embedding_model = 'sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DocumentPreprocessingAgent(state: dict) -> OpenAIAgent:\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    def done() -> None:\n",
    "        \"\"\"When you inserted the vetors into the Qdrant Cluster, call this tool.\"\"\"\n",
    "        logging.info(\"Indexing of the nodes is complete\")\n",
    "        state[\"current_speaker\"] = None\n",
    "        state[\"just_finished\"] = True\n",
    "\n",
    "    tools = [\n",
    "        FunctionTool.from_defaults(fn=indexing),\n",
    "        FunctionTool.from_defaults(fn=done),\n",
    "    ]\n",
    "\n",
    "    system_prompt = (f\"\"\"\n",
    "    You are a helpful assistant that is indexing documents for a retrieval-augmented generation (RAG) system.\n",
    "    Your task is to index the documents into a Qdrant cluster.\n",
    "    To do this, you need to know the embedding model to use.\n",
    "    You can ask the user to supply this.\n",
    "    If the user supplies the embedding model, call the tool \"indexing\" with this parameter to index the documents into the Qdrant cluster.\n",
    "    The current user state is:\n",
    "    {pprint.pformat(state, indent=4)}\n",
    "    When you have indexed the documents into the Qdrant cluster, call the tool \"done\" to signal that you are done.\n",
    "    If the user asks to do anything other than index the documents, call the tool \"done\" to signal some other agent should help.\n",
    "    \"\"\")\n",
    "\n",
    "    return OpenAIAgent.from_tools(\n",
    "        tools,\n",
    "        llm=OpenAI(model=\"gpt-3.5-turbo\"),\n",
    "        system_prompt=system_prompt,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
